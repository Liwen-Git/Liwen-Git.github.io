<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker 导入 和 导出]]></title>
    <url>%2F2020%2F12%2F11%2Fdocker-import-export%2F</url>
    <content type="text"><![CDATA[容器导出容器如果要导出本地某个容器，可以使用 docker export 命令。 12345$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7691a814370e ubuntu:18.04 "/bin/bash" 36 hours ago Exited (0) 21 hours ago test$ docker export 7691a814370e &gt; ubuntu.tar 这样将导出容器快照到本地文件。 导入容器可以使用 docker import 从容器快照文件中再导入为镜像，例如： 12345$ cat ubuntu.tar | docker import - test/ubuntu:v1.0$ docker image lsREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEtest/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外，也可以通过指定 URL 或者某个目录来导入，例如： 1$ docker import http://example.com/exampleimage.tgz example/imagerepo 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[podman详解]]></title>
    <url>%2F2020%2F12%2F11%2Fpodman-and-docker%2F</url>
    <content type="text"><![CDATA[Podman介绍Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用。Podman 提供与 Docker 非常相似的功能。正如前面提到的那样，它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Podman 提供了一个与 Docker 兼容的命令行前端来管理 Docker 镜像。 Podman与docker区别 docker 需要在我们的系统上运行一个守护进程(docker daemon)，而podman 不需要 启动容器的方式不同： docker cli 命令通过API跟 Docker Engine(引擎)交互告诉它我想创建一个container，然后docker Engine才会调用OCI container runtime(runc)来启动一个container。这代表container的process(进程)不会是Docker CLI的child process(子进程)，而是Docker Engine的child process。 Podman是直接给OCI containner runtime(runc)进行交互来创建container的，所以container process直接是podman的child process。 因为docke有docker daemon，所以docker启动的容器支持--restart策略，但是podman不支持，如果在k8s中就不存在这个问题，我们可以设置pod的重启策略，在系统中我们可以采用编写systemd服务来完成自启动 docker需要使用root用户来创建容器，但是podman不需要 Podman安装 Centos、Fedora 1sudo yum -y install podman macOS 1brew cask install podman Podman CLI介绍Podman CLI 里面87%的指令都和DOcker CLI 相同，官方给出了这么个例子alias docker=podman,所以说经常使用DOcker CLI的人使用podman上手非常快 运行一个容器1podman run -dt -p 80:80 --name nginx -v /data:/data -e NGINX_VERSION=1.16 nginx:1.16.0 列出当前所有的容器123# podman ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES19f105d5dc1e docker.io/library/nginx:1.16.0 nginx -g daemon o... 2 minutes ago Up 2 minutes ago 0.0.0.0:80-&gt;80/tcp nginx 查看一个镜像信息123# podman inspect nginx | grep -i "ipaddress" "SecondaryIPAddresses": null, "IPAddress": "10.88.0.110", 查看容器运行的日志1podman logs nginx 查看运行中容器资源使用情况12345678# podman top nginxUSER PID PPID %CPU ELAPSED TTY TIME COMMANDroot 1 0 0.000 5m26.420969043s pts/0 0s nginx: master process nginx -g daemon off;nginx 6 1 0.000 5m26.421085502s pts/0 0s nginx: worker process# podman stats nginxID NAME CPU % MEM USAGE / LIMIT MEM % NET IO BLOCK IO PIDS19f105d5dc1e nginx -- 2.036MB / 1.893GB 0.11% 978B / 10.55kB -- / -- 2 迁移容器Podman 支持将容器从一台机器迁移到另一台机器。首先，在源机器上对容器设置检查点，并将容器打包到指定位置。 12$ sudo podman container checkpoint &lt;container_id&gt; -e /tmp/checkpoint.tar.gz$ scp /tmp/checkpoint.tar.gz &lt;destination_system&gt;:/tmp 其次，在目标机器上使用源机器上传输过来的打包文件对容器进行恢复。 1$ sudo podman container restore -i /tmp/checkpoint.tar.gz podman的程序如何设置自启动由于 Podman 不再使用守护进程管理服务，所以不能通过守护进程去实现自动重启容器的功能。那如果要实现开机自动重启容器，又该如何实现呢？其实方法很简单，现在大多数系统都已经采用 Systemd 作为守护进程管理工具。这里我们就可以使用 Systemd 来实现 Podman 开机重启容器，这里我们以刚才启动的nginx为例。建立一个 Systemd 服务配置文件。 123456789101112131415$ vim /etc/systemd/system/nginx_podman.service[Unit]Description=Podman Nginx ServiceAfter=network.targetAfter=network-online.target[Service]Type=simpleExecStart=/usr/bin/podman start -a nginxExecStop=/usr/bin/podman stop -t 10 nginxRestart=always[Install]WantedBy=multi-user.target 接下来，启用这个 Systemd 服务 123$ sudo systemctl daemon-reload$ sudo systemctl enable nginx_podman.service$ sudo systemctl start nginx_podman.service 之后每次系统重启后 Systemd 都会自动启动这个服务所对应的容器，容器死亡之后也会启动这个容器。 配置别名如果习惯了使用 Docker 命令，可以直接给 Podman 配置一个别名来实现无缝转移。你只需要在 .bashrc 下加入以下行内容即可： 12$ echo "alias docker=podman" &gt;&gt; .bashrc $ source .bashrc]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>podman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos服务器的内存不够？用虚拟内存扩展内存]]></title>
    <url>%2F2020%2F12%2F11%2Fadd-centos-memory%2F</url>
    <content type="text"><![CDATA[背景个人vps主机，物理内存小，虚拟内存0，理论上讲虚拟内存应该要有物理内存的2倍大小。导致yum安装的软件的时候报错 [Errno 5] [Errno 12] 无法分配内存 设置虚拟内存 打开终端，切换到root用户，输入：free -m查看内存状态12345[maker@LLM ~]$ free -m total used free shared buff/cache availableMem: 992 189 79 13 722 614Swap: 0 0 0Swap也就是虚拟内存为0 选择一个较大的分区，建立分区文件1234[root@LLM ~]# dd if=/dev/zero of=/opt/swap bs=1024 count=10240001024000+0 records in1024000+0 records out1048576000 bytes (1.0 GB) copied, 16.6877 s, 62.8 MB/s 该命令表示在opt分区建立名为swap，大小为1G的虚拟内存文件 将swap文件设置为swap分区文件 1234chmod 600 /opt/swap //注意更改swap文件的权限[root@LLM ~]# mkswap /opt/swapSetting up swapspace version 1, size = 1023996 KiBno label, UUID=fc47f29e-31af-401e-856d-0fec5262179e 激活swap,启用分区交换文件 1swapon /opt/swap 现在看下结果 1234[root@LLM ~]# free -m total used free shared buff/cache availableMem: 992 191 63 13 737 625Swap: 999 0 999 卸载虚拟内存 首先停止swap分区 12345[root@LLM ~]# swapoff /opt/swap[root@LLM ~]# free -m total used free shared buff/cache availableMem: 992 191 63 13 738 626Swap: 0 0 0 其次删除掉swap文件即可首先看一下磁盘大小 12345678910111213141516171819[root@LLM ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 3.9G 34G 11% /devtmpfs 487M 0 487M 0% /devtmpfs 497M 4.0K 497M 1% /dev/shmtmpfs 497M 420K 496M 1% /runtmpfs 497M 0 497M 0% /sys/fs/cgrouptmpfs 100M 0 100M 0% /run/user/0tmpfs 100M 0 100M 0% /run/user/1001[root@LLM ~]# rm -rf /opt/swap[root@LLM ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 3.0G 35G 8% /devtmpfs 487M 0 487M 0% /devtmpfs 497M 4.0K 497M 1% /dev/shmtmpfs 497M 420K 496M 1% /runtmpfs 497M 0 497M 0% /sys/fs/cgrouptmpfs 100M 0 100M 0% /run/user/0tmpfs 100M 0 100M 0% /run/user/1001 可以看出删除后多了1G的空间]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[computed 和 watch 的异同]]></title>
    <url>%2F2020%2F12%2F11%2Fvue-watch-and-computed%2F</url>
    <content type="text"><![CDATA[computed 和 watch 都可以观察页面的数据变化。当处理页面的数据变化时，我们有时候很容易滥用watch。而通常更好的办法是使用computed属性，而不是watch回调。这里我直接引用vue官网的例子来说明： html:我们要实现 第三个表单的值 是第一个和第二个的拼接，并且在前俩表单数值变化时，第三个表单数值也在变化. 12345&lt;div id="myDiv"&gt; &lt;input type="text" v-model="firstName"&gt; &lt;input type="text" v-model="lastName"&gt; &lt;input type="text" v-model="fullName"&gt;&lt;/div&gt; js: 用watch方法来实现 12345678910111213141516new Vue(&#123; el: '#myDiv', data: &#123; firstName: 'Foo', lastName: 'Bar', fullName: 'Foo Bar' &#125;, watch: &#123; firstName: function (val) &#123; this.fullName = val + ' ' + this.lastName &#125;, lastName: function (val) &#123; this.fullName = this.firstName + ' ' + val &#125; &#125;&#125;) js: 利用computed 来写 123456789101112new Vue(&#123; el:"#myDiv", data:&#123; firstName:"Den", lastName:"wang", &#125;, computed:&#123; fullName:function()&#123; return this.firstName + " " +this.lastName; &#125; &#125;&#125;) 很容易看出 computed 在实现上边的效果时，是更简单的。 详解 comouted 计算属性。在vue的模板内{ { } }是可以写一些简单的js表达式的 ，很便利。但是如果在页面中使用大量或是复杂的表达式去处理数据，对页面的维护会有很大的影响。这个时候就需要用到computed 计算属性来处理复杂的逻辑运算。 优点：在数据未发生变化时，优先读取缓存。computed 计算属性只有在相关的数据发生变化时才会改变要计算的属性，当相关数据没有变化是，它会读取缓存。而不必想 motheds方法 和 watch 方法是的每次都去执行函数。 setter 和 getter方法：（注意在vue中书写时用set 和 get）setter 方法在设置值是触发。getter 方法在获取值时触发。123456789101112computed:&#123; fullName:&#123; //这里用了es6书写方法 set()&#123; alert("set"); &#125;, get()&#123; alert("get"); return this.firstName + " " +this.lastName; &#125;, &#125;&#125; watch 方法虽然计算属性在大多数情况下是非常适合的，但是在有些情况下我们需要自定义一个watcher，在数据变化时来执行异步操作，这时watch是非常有用的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;template&gt; &lt;div class="container"&gt; &lt;template v-for='(data,index) of datas'&gt; &lt;p class="listTop"&gt;&lt;span class="col3"&gt;&#123;&#123;data.tit&#125;&#125;&lt;/span&gt;&lt;template v-if='data.num != 100'&gt;(还可输入&#123;&#123;data.num&#125;&#125;字)&lt;/template&gt;&lt;/p&gt; &lt;div class="feedBack"&gt; &lt;div class="feed-text feed-mini" :class='&#123; col5 : data.def!==data.txt &#125;'&gt; &lt;textarea class="limitFeed" @focus='textFocus(index)' @blur='textBlur(index)' v-model.tirm='data.txt'&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;/template&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data () &#123; return &#123; datas:[ &#123;tit:'我的简介', txt:'',num:100,def:'请简单介绍您的基本情况。例如：本人在浙江杭州上班，从事的行业是互联网行业。（字数100字以内）'&#125;, &#123;tit:'我的还款能力',txt:'',num:100,def:'请简单介绍您的还款能力。例如：本人在公司任职的岗位是java开发，月收入稳定，能按时归还借款。（字数100字以内）'&#125;, &#123;tit:'本次申请借款的用途',txt:'',num:100,def:'请介绍本次申请借款的用途。例如：本次申请借款主要是因为新家装修，急需用钱。（字数100字以内）'&#125;, ] &#125; &#125;, methods :&#123; textFocus(i)&#123;//获取焦点时 if(this.datas[i].txt == this.datas[i].def) this.datas[i].txt = ''; &#125;, textBlur(i)&#123;//失去焦点时 if(this.datas[i].txt == '') this.datas[i].txt = this.datas[i].def;; &#125;, changeText(i)&#123;//如果当前textarea值不等于默认值的话--&gt;限止字母在100字内 if(this.datas[i].txt.length &gt;100 )&#123; this.datas[i].txt = this.datas[i].txt.substring(0,100); &#125;else if(this.datas[i].txt == this.datas[i].def)&#123; this.datas[i].num = 100; &#125;else&#123; this.datas[i].num = (100-this.datas[i].txt.length); &#125; &#125; &#125;, computed:&#123; dataRest:function()&#123;//计算返回一组新数据格式--&gt;&#123;'0':'xxx','1':'xxx','2':'xxx'&#125;&lt;--[模拟索引号]] var obj = &#123;&#125;; for(var i = 0; i &lt; this.datas.length; i++) obj[i]=this.datas[i].txt; return obj; &#125; &#125;, watch:&#123; dataRest:&#123; handler:function(nowVal,oldVal)&#123;//观擦计算返回的新数据--&gt;对比新旧值返回差异的[“索引号”] for(var i = 0; i &lt; this.datas.length; i++)&#123; if(nowVal[i] != oldVal[i]) this.changeText(i); &#125; &#125;, deep:true &#125; &#125;, created:function()&#123; for(var i=0; i &lt; this.datas.length; i++) this.datas[i].txt = this.datas[i].def; //为textarea赋默认值 &#125; &#125;&lt;/script&gt;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 容器固定IP]]></title>
    <url>%2F2020%2F09%2F16%2Fdocker-static-ip%2F</url>
    <content type="text"><![CDATA[起因在项目中启用多个容器，有时候需要多个容器间进行通信，就需要绑定其他容器，但是docker每次重启后，容器的IP地址都会变化，所以需要固定容器IP。 docker默认网络Docker安装后，默认会创建下面三种网络类型： 12345$ docker network lsNETWORK ID NAME DRIVER SCOPE9781b1f585ae bridge bridge local1252da701e55 host host local237ea3d5cfbf none null local bridge：桥接网络默认情况下启动的Docker容器，都是使用bridge，Docker安装时创建的桥接网络，每次Docker容器重启时，会按照顺序获取对应的IP地址，这个就导致重启下，Docker的IP地址就变了 none：无指定网络使用 --network=none ，docker 容器就不会分配局域网的IP host： 主机网络使用 --network=host，此时，Docker 容器的网络会附属在主机上，两者是互通的。例如，在容器中运行一个Web服务，监听8080端口，则主机的8080端口就会自动映射到容器中。 启动 Docker的时候，用 --network 参数，可以指定网络类型，如： 1➜ ~ docker run -itd --name test1 --network bridge centos:latest /bin/bash docker创建自定义网络并固定IP首先，启动Docker容器的时候，使用默认的网络是不支持指派固定IP的，如下： 123➜ ~ docker run -itd --net bridge --ip 172.17.0.10 centos:latest /bin/bash6eb1f228cf308d1c60db30093c126acbfd0cb21d76cb448c678bab0f1a7c0df6docker: Error response from daemon: User specified IP address is supported on user defined networks only. 因此，需要创建自定义网络，下面是具体的步骤： 自定义网络1234567➜ ~ docker network create --subnet=172.72.0.0/16 mynetwork➜ ~ docker network lsNETWORK ID NAME DRIVER SCOPE9781b1f585ae bridge bridge local1252da701e55 host host local4f11ae9c85de mynetwork bridge local237ea3d5cfbf none null local 创建容器并固定IP1➜ ~ docker run -itd --name networkTest1 --network mynetwork --ip 172.72.0.2 centos:latest /bin/bash 进入容器查看IP 123456789101112131415161718[root@ec8e31938fe7 /]# ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:12:00:02 inet addr:172.72.0.2 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:acff:fe12:2/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:88 errors:0 dropped:0 overruns:0 frame:0 TX packets:14 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:4056 (3.9 KiB) TX bytes:1068 (1.0 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b)]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm --save-dev & --save 的区别]]></title>
    <url>%2F2020%2F07%2F07%2Fnpm-save-dev%2F</url>
    <content type="text"><![CDATA[npm install 在安装 npm 包时，有两种命令参数可以把它们的信息写入 package.json 文件，一个是npm install--save，另一个是 npm install –save-dev，他们表面上的区别是： --save 会把依赖包名称添加到 package.json 文件 dependencies 键下， --save-dev 则添加到 package.json 文件 devDependencies 键下， 譬如： 1234567891011121314151617&#123; &quot;dependencies&quot;: &#123; &quot;vue&quot;: &quot;^2.2.1&quot; &#125;, &quot;devDependencies&quot;: &#123; &quot;babel-core&quot;: &quot;^6.0.0&quot;, &quot;babel-loader&quot;: &quot;^6.0.0&quot;, &quot;babel-preset-latest&quot;: &quot;^6.0.0&quot;, &quot;cross-env&quot;: &quot;^3.0.0&quot;, &quot;css-loader&quot;: &quot;^0.25.0&quot;, &quot;file-loader&quot;: &quot;^0.9.0&quot;, &quot;vue-loader&quot;: &quot;^11.1.4&quot;, &quot;vue-template-compiler&quot;: &quot;^2.2.1&quot;, &quot;webpack&quot;: &quot;^2.2.0&quot;, &quot;webpack-dev-server&quot;: &quot;^2.2.0&quot; &#125;&#125; 不过这只是它们的表面区别。它们真正的区别是:npm自己的文档说dependencies是运行时依赖，devDependencies是开发时的依赖。即: devDependencies 下列出的模块，是我们开发时用的，比如 我们安装 js的压缩包gulp-uglify 时，我们采用的是 npm install –save-dev gulp-uglify命令安装，因为我们在发布后用不到它，而只是在我们开发才用到它。 dependencies 下的模块，则是我们发布后还需要依赖的模块，譬如像jQuery库或者Angular框架类似的，我们在开发完后后肯定还要依赖它们，否则就运行不了。 另外需要补充的是：正常使用npm install时，会下载dependencies和devDependencies中的模块，当使用npm install –production或者注明NODE_ENV变量值为production时，只会下载dependencies中的模块。]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue.use 和 Vue.prototype.$xx 的区别]]></title>
    <url>%2F2020%2F07%2F07%2Fvue-use-and-prototype%2F</url>
    <content type="text"><![CDATA[Vue.use举例：首先引入api 12import api from './api/index'Vue.use(api); 再看下api/index.js中的代码 123456789101112131415161718192021import request from '../utils/request'export default &#123; install(Vue, options) &#123; Vue.prototype.get = function(url, params) &#123; return request(&#123; url: url, method: 'get', params: params &#125;) &#125;; Vue.prototype.post = function(url, data) &#123; return request(&#123; url: url, method: 'post', data &#125;) &#125; &#125;&#125; 可以发现其中有一个install函数，它是本文的主角，Vue.use就是要运行这个install函数。 总结 Vue的插件是一个对象，就像Element 插件对象必须有install install字段是个函数 初始化插件对象需要Vue.use() Vue.use()调用必须在new Vue之前 同一个插件多次使用Vue.use()也只会被运行一次 Vue.prototype.$xx本质其实就是js中的函数原型的特性：函数原型上的属性/方法, 在函数实例化后, 可以在任意实例上读取。 1234567/** * moment 时间组件 * 使用 this.$moment() 调用 */import moment from 'moment'moment.locale('zh-cn');Vue.prototype.$moment = moment;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>vue-api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue Router 模式及其部署]]></title>
    <url>%2F2020%2F07%2F07%2Fvue-router%2F</url>
    <content type="text"><![CDATA[Vue Router是Vue.js官方的路由管理器，使用配置很简单： 12345678910// router/index.js// 此处省略一堆 importconst router = new Router(&#123; base:'/', mode:'history', //default--&gt;hash routes:[], scrollBehavior:()=&gt;&#123; return &#123;x:0,y:0&#125; &#125;&#125;) base浏览器url的前缀，默认为&#39;/&#39;，如果设置为&#39;/admin/&#39;,则运行项目，浏览器url都是&#39;/admin/...&#39;,不会对静态文件的引用产生影响，一般写网站都会有域名，都可以把域名指向某个服务器目录，所以默认&#39;/&#39;即可。 比如打包后的文件在111.22.33.44/admin，是在项目部署的子级目录，这个时候路由的配置匹配浏览器路径的时候，会从这个/admin开始算，如果base还是默认的/，那么路由配置的routes的path就要全部加上/admin/前缀，并且router-link和push方法也要加上这个/admin，很麻烦，但是只要设置base为&#39;/admin/&#39;，路由内部配置以及所有相关的方法都可以忽视服务器ip下的目录名。这种情况，同样也要配置webpack的publicPath也为/admin/，这个下面细说。 mode hash: 使用URL的hash值来作为路由。支持所有浏览器。浏览器会有‘#’符号，参考锚点效果，缺点很丑，但是兼容性棒棒。 history: 以来HTML5 History API 和服务器配置。参考官网中HTML5 History模式。去除‘#’符号，让url变好看，下面会讲服务端配置。 abstract： 支持所有javascript运行模式。如果发现没有浏览器的API，路由会自动强制进入这个模式，例如weex。 history模式nginx配置hisroty模式下需要配置的原因： 当你进入某个路由之后，再次刷新页面时（或者是浏览器直接输入某个路由路径时），浏览器就会重新dns解析，tcp协议，这个时候会根据浏览器的url去服务器找对应资源，当然我们vue-router是为单页面服务的，对应的url在服务端是肯定没有静态资源的，就会出现404； 当配置了以下url重写语句，注意是重写，不是重定向，不改变url的情况重写浏览器内容，重写到index.html，因为这个index.html使我们项目的入口，index.html里面会读取当时打包好的app.js，就可以读取到路由配置，以实现我们浏览器的url对应的路由页面。 hash模式不需要配置，因为浏览器会忽略 # 和 ？后面的参数 打包文件在根目录时： 12345678910server &#123; listen 80; server_name test.com; location / &#123; root /var/www/dist; ## 前端文件路径 index index.html; ## hash模式只配置访问html就可以了 try_files $uri $uri/ /index.html; ## history模式下 &#125;&#125; 打包文件在非根目录，即部署到子级目录时，还需要修改webpack的publicPath，生成一个子级目录下的绝对访问路劲，同时修改nginx相应的.conf文件： webpack： 1publicPath: process.env.NODE_ENV === 'production' ? '/admin/' : '/', nginx： 12345678910111213server &#123; listen 80; server_name test.com; location /admin &#123; ## 子级目录，打包的代码放在子级目录 alias /var/www/dist/admin; index index.html; try_files $uri $uri/ /admin/index.html; expires 30d; ##缓存30天，这个缓存是指你浏览器（客户端，非nginx）缓存，一般情况下，Ctrl+R强制刷新就会去掉缓存 &#125;&#125; try_files指令：语法：try_files file … uri 或 try_files file … = code默认值：无作用域：server location其作用是按顺序检查文件是否存在，返回第一个找到的文件或文件夹(结尾加斜线表示为文件夹)，如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。需要注意的是，只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误。命名的location也可以使用在最后一个参数中。与rewrite指令不同，如果回退URI不是命名的location，那么$args不会自动保留，如果你想保留$args，则必须明确声明。]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>vue-api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue事件总线（EventBus）]]></title>
    <url>%2F2020%2F07%2F07%2Fvue-event-bus%2F</url>
    <content type="text"><![CDATA[如果两个页面没有任何引入和被引入关系，该如何通信？如果咱们的应用程序不需要类似Vuex这样的库来处理组件之间的数据通信，就可以考虑Vue中的事件总线，即EventBus来通信。 简介EventBus 又称为事件总线。在Vue中可以使用 EventBus 来作为沟通桥梁的概念，就像是所有组件共用相同的事件中心，可以向该中心注册发送事件或接收事件，所以组件都可以上下平行地通知其他组件，但也就是太方便所以若使用不慎，就会造成难以维护的“灾难”，因此才需要更完善的Vuex作为状态管理中心，将通知的概念上升到共享状态层次。 使用初始化首先需要创建事件总线并将其导出，以便其它模块可以使用或者监听它。我们可以通过两种方式来处理。 先来看第一种，新创建一个 .js 文件，比如 event-bus.js 123// event-bus.jsimport Vue from 'vue'export const EventBus = new Vue() 实质上EventBus是一个不具备 DOM 的组件，它具有的仅仅只是它实例方法而已，因此它非常的轻便。 另外一种方式，可以直接在项目中的 main.js 初始化 EventBus : 12// main.jsVue.prototype.$EventBus = new Vue() 注意，这种方式初始化的EventBus是一个全局的事件总线。稍后再来聊一聊全局的事件总线。 现在我们已经创建了 EventBus ，接下来你需要做到的就是在你的组件中加载它，并且调用同一个方法，就如你在父子组件中互相传递消息一样。 发送事件假设你有两个Vue页面需要通信： A 和 B ，A页面 在按钮上面绑定了点击事件，发送一则消息，想去通知 B页面。 123456789101112131415&lt;!-- A.vue --&gt;&lt;template&gt; &lt;button @click="sendMsg()"&gt;-&lt;/button&gt;&lt;/template&gt;&lt;script&gt; import &#123; EventBus &#125; from "../event-bus.js";export default &#123; methods: &#123; sendMsg() &#123; EventBus.$emit("aMsg", '来自A页面的消息'); &#125; &#125;&#125;; &lt;/script&gt; 接下来，我们需要在 B页面 中接收这则消息。 接收事件1234567891011121314151617181920212223&lt;!-- B.vue --&gt;&lt;template&gt; &lt;p&gt;&#123;&#123;msg&#125;&#125;&lt;/p&gt;&lt;/template&gt;&lt;script&gt; import &#123; EventBus &#125; from "../event-bus.js";export default &#123; data()&#123; return &#123; msg: '' &#125; &#125;, mounted() &#123; EventBus.$on("aMsg", (msg) =&gt; &#123; // A发送来的消息 this.msg = msg; &#125;); &#125;&#125;;&lt;/script&gt; 所以，发送和接收消息，主要用到两个方法： 12345// 发送消息EventBus.$emit(channel: string, callback(payload1,…))// 监听接收消息EventBus.$on(channel: string, callback(payload1,…)) 前面提到过，如果使用不善，EventBus会是一种灾难，到底是什么样的“灾难”了？大家都知道vue是单页应用，如果你在某一个页面刷新了之后，与之相关的EventBus会被移除，这样就导致业务走不下去。还要就是如果业务有反复操作的页面，EventBus在监听的时候就会触发很多次，也是一个非常大的隐患。这时候我们就需要好好处理EventBus在项目中的关系。通常会用到，在vue页面销毁时，同时移除EventBus事件监听。 移除时间监听者如果想移除事件的监听，可以像下面这样操作： 1234import &#123; eventBus &#125; from './event-bus.js'EventBus.$off('aMsg', &#123;&#125;) 你也可以使用 EventBus.$off(&#39;aMsg&#39;) 来移除应用内所有对此某个事件的监听。或者直接调用 EventBus.$off() 来移除所有事件频道，不需要添加任何参数 。 上面的示例中我们也看到了，每次使用 EventBus 时都需要在各组件中引入 event-bus.js 。事实上，我们还可以通过别的方式，让事情变得简单一些。那就是创建一个全局的 EventBus 。 全局EventBus123456789var EventBus = new Vue();Object.defineProperties(Vue.prototype, &#123; $bus: &#123; get: function () &#123; return EventBus &#125; &#125;&#125;) 在这个特定的总线中使用两个方法$on和$emit。一个用于创建发出的事件，它就是$emit；另一个用于订阅$on： 1234567var EventBus = new Vue();this.$bus.$emit('nameOfEvent', &#123; ... pass some event data ...&#125;);this.$bus.$on('nameOfEvent',($event) =&gt; &#123; // ...&#125;) 然后我们可以在某个Vue页面使用this.$bus.$emit(&quot;sendMsg&quot;, &#39;我是web秀&#39;);，另一个Vue页面使用 123this.$bus.$on('sendMsg', function(value) &#123; console.log(value); // 我是web秀&#125;) 同时也可以使用this.$bus.$off(&#39;sendMsg&#39;)来移除事件监听。]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>vue-api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解async/await]]></title>
    <url>%2F2020%2F07%2F07%2Fvue-async-await%2F</url>
    <content type="text"><![CDATA[作用在async/await之前，我们有三种方式写异步代码： 嵌套回调 以Promise为主的链式回调 使用Generators 但是，这三种写起来都不够优雅，ES7做了优化改进，async/await应运而生。async/await相比较Promise 对象，then 函数的嵌套，与 Generator 执行的繁琐（需要借助co才能自动执行，否则得手动调用next() ）。 async/await 可以让你轻松写出同步风格的代码同时又拥有异步机制，更加简洁，逻辑更加清晰。 特点 async/await更加语义化，async 是“异步”的简写，async function 用于申明一个 function 是异步的； await，可以认为是async wait的简写， 用于等待一个异步方法执行完成； async/await是一个用同步思维解决异步问题的方案（等结果出来之后，代码才会继续往下执行） 可以通过多层 async function 的同步写法代替传统的callback嵌套。 async function语法 自动将常规函数转换成Promise，返回值也是一个Promise对象； 只有async函数内部的异步操作执行完，才会执行then方法指定的回调函数； 异步函数内部可以使用await。 await语法 await 放置在Promise调用之前，await 强制后面点代码等待，直到Promise对象resolve，得到resolve的值作为await表达式的运算结果； await只能在async函数内部使用，用在普通函数里就会报错。 具体使用 async和await要搭配Promise使用, 它进一步极大的改进了Promise的写法。 首先看一个简单场景： 1234567891011121314//假设有4个异步方法要按顺序调用new Promise(function(resolve)&#123; ajaxA("xxxx", ()=&gt; &#123; resolve(); &#125;) &#125;).then(function()&#123; return new Promise(function(resolve)&#123; ajaxB("xxxx", ()=&gt; &#123; resolve(); &#125;) &#125;)&#125;).then(function()&#123; return new Promise(function(resolve)&#123; ajaxC("xxxx", ()=&gt; &#123; resolve(); &#125;) &#125;)&#125;).then(function()&#123; ajaxD("xxxx");&#125;); 语法上不够简洁, 我们可以稍微改造一下 12345678910//将请求改造成一个通用函数function request(options) &#123; //..... return new Promise(....); //使用Promise执行请求,并返回Promise对象&#125;//于是我们就可以来发送请求了request("http://xxxxxx").then((data)=&gt;&#123; //处理data&#125;) 然后我们再来重新改造开头的代码 12345678910111213request("ajaxA").then((data)=&gt;&#123; //处理data return request("ajaxB")&#125;).then((data)=&gt;&#123; //处理data return request("ajaxC")&#125;).then((data)=&gt;&#123; //处理data return request("ajaxD")&#125;) 比起之前有了不小的进步, 但是看上去依然不够简洁 如果我能像使用同步代码那样, 使用Promise就好了 于是, async\await出现了 12345678910async function load()&#123; await request("ajaxA"); await request("ajaxB"); await request("ajaxC"); await request("ajaxD");&#125;await关键字使用的要求非常简单, 后面调用的函数要返回一个Promise对象；load()这个函数已经不再是普通函数, 它出现了await这样"阻塞式"的操作；因此async关键字在这是不能省略的。 到这你已经学会了async和await基本使用方式。 下面来简单解释一下它的工作流程： 1234567//wait这个单词是等待的意思async function load()&#123; await request("ajaxA"); //那么这里就是在等待ajaxA请求的完成 await request("ajaxB"); await request("ajaxC"); await request("ajaxD");&#125; 如果后一个请求需要前一个请求的结果怎么办呢? 传统的写法是这样的： 12345678910request("ajaxA").then((data1)=&gt;&#123; return request("ajaxB", data1);&#125;).then((data2)=&gt;&#123; return request("ajaxC", data2)&#125;).then((data3)=&gt;&#123; return request("ajaxD", data3)&#125;) 而使用async/await是这样的： 1234567async function load()&#123; let data1 = await request("ajaxA"); let data2 = await request("ajaxB", data1); let data3 = await request("ajaxC", data2); let data4 = await request("ajaxD", data3); //await不仅等待Promise完成, 而且还拿到了resolve方法的参数&#125; 注意当一个函数被async修饰以后, 它的返回值会被自动处理成Promise对象 关于异常处理 12345678910async function load()&#123; //请求失败后的处理, 可以使用try-catch来进行 try&#123; let data1 = await request("ajaxA"); let data2 = await request("ajaxB", data1); let data3 = await request("ajaxC", data2); &#125; catch(e)&#123; //...... &#125;&#125;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>vue-api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nextTick使用]]></title>
    <url>%2F2020%2F07%2F07%2Fvue-nexttick%2F</url>
    <content type="text"><![CDATA[Vue.nextTick( [callback, context] )文档中的解释： 参数： {Function} [callback] {Object} [context] 用法：在下次 DOM 更新循环结束之后执行延迟回调。在修改数据之后立即使用这个方法，获取更新后的 DOM。 1234567891011121314// 修改数据vm.msg = 'Hello'// DOM 还没有更新console.log(vm.$el.textContent) // 并不会得到'Hello'Vue.nextTick(function () &#123; // DOM 更新了 console.log(vm.$el.textContent) //可以得到'Hello'&#125;)// 作为一个 Promise 使用 (2.1.0 起新增，详见接下来的提示)Vue.nextTick() .then(function () &#123; // DOM 更新了 &#125;) 异步说明 Vue 实现响应式并不是数据发生变化之后 DOM 立即变化，而是按一定的策略进行 DOM 的更新。Vue是异步执行DOM更新的。 应用 在Vue生命周期的created()钩子函数进行的DOM操作一定要放在Vue.nextTick()的回调函数中在created()钩子函数执行的时候DOM 其实并未进行任何渲染，而此时进行DOM操作无异于徒劳，所以此处一定要将DOM操作的js代码放进Vue.nextTick()的回调函数中。与之对应的就是mounted()钩子函数，因为该钩子函数执行时所有的DOM挂载和渲染都已完成，此时在该钩子函数中进行任何DOM操作都不会有问题 。 在数据变化后要执行的某个操作，而这个操作需要使用随数据改变而改变的DOM结构的时候，这个操作都应该放进Vue.nextTick()的回调函数中。]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>vue-api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解Promise]]></title>
    <url>%2F2020%2F07%2F07%2Fvue-promise%2F</url>
    <content type="text"><![CDATA[异步定义 当一个操作开始执行后，主程序无需等待它的完成，可以继续向下执行。此时该操作可以跟主程序同时（并发）执行。这种操作我们就称之为异步操作。 通常当操作完成时，会执行一个我们事先设定好的回调函数来做后续的处理。 我们常见的异步操作例如： 添加定时器 setTimeout/setInterval 执行某个动画 animate 发起网络请求 request 问题如果有很多异步操作需要顺序执行，就会产生所谓的“回调地狱”： 123456789ajaxA(function( )&#123; ajaxB(function( )&#123; ajaxC(function( )&#123; ajaxD(function( )&#123; ...... &#125;); &#125;); &#125;); &#125;) 这种代码不管是写起来还是读起来都比较烦人。 我们来看下经过Promise改造后的样子（伪代码）： 1234new Promise(ajaxA) .then(ajaxB) .then(ajaxC) .then(ajaxD); 使用示例感受下： 1234567new Promise(resolve=&gt;&#123; ajax("/pay/post", data =&gt; resolve() );&#125;).then(resolve=&gt;&#123; ajax("/order/fix", data =&gt; &#123; //处理数据 &#125;)&#125;) 上面的代码使用了ES6的箭头函数,虽然大大简化了代码的写法，但对于初级程序猿来讲极不友好； 我们把代码还原成ES5的样子： 123456789new Promise(function(resolve)&#123; ajax("/pay/post",function(data)&#123; resolve(); &#125;)&#125;).then(function()&#123; ajax("/order/fix",function(data)&#123; &#125;)&#125;) 原理 Promise是怎么知道第一个函数什么时候结束的？ 然后再开始执行下一个？ Promise并没有那么神奇，它并不能知道我们的函数什么时候结束，在ajax请求结束执行回调的时候，我们调用了一个resolve()函数，这句代码非常的关键.这其实就是在通知Promise，当前这个函数结束啦，你可以开始执行下一个。 这时Promise就会去执行then里面的函数了。 如果我不调用resolve()这个方法，Promise就不知道这个函数有没有结束，那么then里面的函数就不会执行，也就是说我的第二个请求就永远不会发送了 Promise基本结构 12345678910new Promise(函数1).then(函数2);我们把函数1和函数2都以参数形式传给了一个Promise对象，所以接下来函数1和2都会由这个Promise对象控制， 简单的说，函数1和函数2都会由Promise对象来执行。 所以在函数1执行时，参数也当然是由Promise对象传递进去的。new Promise(function(resolve)&#123; //resolve是Promise对象在调用函数时传入的参数&#125;).then(函数2); resolve函数作用 12345678910以参数传进来的resolve函数， 就好像一个对讲机，当我们的异步任务要结束时，通过对讲机 来通知Promise对象。也就是调用resolve方法：new Promise(function(resolve)&#123; ajax("/pay/post",function(data)&#123; //当请求结束时，通过调用resolve方法，通知Promise对象，该任务已完成 resolve(); //收到通知后，Promise会立刻开始函数2的执行 &#125;)&#125;).then(函数2); 如果我有ajaxA、ajaxB、ajaxC三个异步任务，想按照先A后B再C的顺序执行，像这样写行吗？ 1234567891011new Promise(function(resolve)&#123; ajax("/AAA", function()&#123; resolve(); //通知Promise该任务结束 &#125;) &#125;).then(function(resolve)&#123; ajax("/BBB", function()&#123; resolve();//通知Promise该任务结束 &#125;)&#125;).then(function()&#123; ajax("/CCC", function()&#123; //.... &#125;)&#125;) 上面的这种写法是不对的。Promise的中文含义是“承诺”，则意味着，每一个Pormise对象，代表一次承诺而每一次承诺，只能保证一个任务的顺序，也就是说new Promise(A).then(B); 这句话表示， 只能保证A和B的顺序 一旦A执行完，B开始后，这次承诺也就兑现了，Promise对象也就失效了那如果还有C呢？ 我们就必须在函数B中，重新创建新的Promise对象，来完成下一个承诺，具体的写法就像这样： 1234567891011121314151617new Promise(函数1(resolve)&#123; ajaxA("xxxx", function()&#123; resolve();//通知Promise该任务结束 &#125;) &#125;).then(函数2()&#123; //在函数2开始运行后，第一次创建的Promise对象完成使命，已经不能再继续工作。 //此时，我们创建并返回了新的Promise对象 return new Promise(function(resolve)&#123; ajaxB("xxxx", function()&#123; resolve();//通知新的Promise对象该任务结束 &#125;) &#125;)&#125;).then(函数3()&#123; //尽管这里使用了链式调用，但负责执行函数3的，已经是新的Promise对象了 // 如果，我们还有ajaxD需要顺序调用 // 那就必须在这里重新new Promise()对象了 ajaxC("xxx", function()&#123; &#125;)&#125;) 其他功能123456789101112131415例如： 如果我有 A,B,C 三个异步任务，ABC同时开始执行当A,B,C三个任务全部都结束时，执任务D，传统方法实现起来就比较复杂，Promise就非常简单，就像这样：Promise.all([new Promise(A), new Promise(B), new Promise(C)]).then(function()&#123; D();&#125;);如果我希望A,B,C 其中任意一个任务完成，就马上开始任务D，该怎么做？Promise.race([new Promise(A), new Promise(B), new Promise(C)]).then(function()&#123; D();&#125;);]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>promise</tag>
        <tag>vue-api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx和php-fpm用户权限说明]]></title>
    <url>%2F2020%2F06%2F28%2Fnginx-php-fpm-authority%2F</url>
    <content type="text"><![CDATA[Nginx权限我们知道，Nginx本身不能解析PHP的语法，所以Nginx对于静态文件(如HTML等)会直接解析返回结果，但是对于PHP的文件，Nginx会转交给PHP的解释器php-fpm进行处理，此时则需要php-fpm用户对文件具有有读权限或者读写权限。处理完后再返回响应给客户端浏览器。 因此，我们代码目录下需要统一Nginx和php的服务所需权限。 最好的办法就是统一归类到一个新的用户组里面，通过给该用户组分配Nginx和php运行必要的权限，来实现对web应用的权限目录管理。 通常情况下，许多团队都会把这个用户组取名www，由www用户来统一管理代码目录权限。 我们可以看到Nginx的配置文件nginix.conf里面划分的运行权限就是配置到了www用户下，因此Nginx的子进程也是由www用户执行，可以通过ps aux | grep nginx来查看 php-fpm权限同样的，php的运行方式也是由主进程root运行，在子进程池(pool)里面配置由www用户执行，具体配置在php根目录下的etc\php-fpm.conf下，添加两行： 12user = wwwgroup = www 即可，同样用ps aux | grep php可以查看进程使用的用户身份 总结 一般情况下，nginx运行用户、php-fpm运行用户和web的根目录的所有者和所属组，应该保持一致。 上传目录 644 runtime目录 744]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XSS 和 CSRF]]></title>
    <url>%2F2020%2F06%2F28%2Fxss-and-csrf%2F</url>
    <content type="text"><![CDATA[XSS攻击跨站脚本攻击（Cross Site Scripting）本来的缩写为CSS，为了与层叠样式表（Cascading Style Sheets，CSS）的缩写进行区分，将跨站脚本攻击缩写为XSS。因此XSS是跨站脚本的意思。 XSS跨站脚本攻击（Cross Site Scripting），的本质是攻击者在web页面插入恶意的script代码（这个代码可以是JS脚本、CSS样式或者其他意料之外的代码），当用户浏览该页面之时，嵌入其中的script代码会被执行，从而达到恶意攻击用户的目的。比如读取cookie，session，tokens，或者网站其他敏感的网站信息，对用户进行钓鱼欺诈等。比较经典的事故有： 2011年6月28日，新浪微博被XSS攻击，大量用户自动转发微博、私信。自动关注用户，大量用户被莫名其妙地控制。因为可以使用JS代码代替用户单击按钮发送请求，所以损坏非常大。 XSS攻击的危害 通过 document.cookie 盗取 cookie中的信息 使用 js或 css破坏页面正常的结构与样式 流量劫持（通过访问某段具有 window.location.href 定位到其他页面） dos攻击：利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器响应。并且通过携带过程的 cookie信息可以使服务端返回400开头的状态码，从而拒绝合理的请求服务。 利用 iframe、frame、XMLHttpRequest或上述 Flash等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作，并且攻击者还可以利用 iframe，frame进一步的进行 CSRF 攻击。 控制企业数据，包括读取、篡改、添加、删除企业敏感数据的能力。 XSS攻击的类型反射型XSS攻击反射型XSS漏洞常见于通过URL传递参数的功能，如网站搜索，跳转等。由于需要用户主动打开恶意的URL才能生效，攻击者往往会结合多种手段诱导用户点击。比如下面的URL： 12345http://x.x.x.x:8080/dosomething?message="&lt;script src="http://www.hacktest.com:8002/xss/hacker.js"&gt;&lt;/script&gt;"或者http://localhost/test.php?param=&lt;script&gt;alert(/xss/)&lt;/script&gt; POST的内容也可以触发反射型XSS，只不过它的触发条件比较苛刻（构建表单提交页面，并引导用户点击），所以非常少见。 攻击步骤： 1.攻击者构造出特殊的URL，其中包含恶意代码.2.用户打开有恶意代码的URL时，网站服务器端将恶意代码从URL取出，拼接在HTML返回给浏览器.3.用户浏览器接收到响应后解析执行，混在其中的恶意代码也会被执行。4.恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户行为，调用目标网站接口执行攻击者指定的操作。 防御： 对输入检查对请求参数进行检查，一旦发现可疑的特殊字符就拒绝请求。需要注意的是用户可以绕过浏览器的检查，直接通过Postman等工具进行请求，所以这个检查最好前后端都做。 对输出进行转义再显示通过上面的介绍可以看出，反射型XSS攻击要进行攻击的话需要在前端页面进行显示。所以在输出数据之前对潜在的威胁的字符进行编码、转义也是防御XSS攻击十分有效的措施。 存储型XSS攻击恶意脚本永久存储在目标服务器上。当浏览器请求数据时，脚本从服务器传回并执行，影响范围比反射型和DOM型XSS更大。存储型XSS攻击的原因仍然是没有做好数据过滤：前端提交数据至服务器端时，没有做好过滤;服务端在按受到数据时，在存储之前，没有做过滤;前端从服务器端请求到数据，没有过滤输出。 比较常见的场景是，黑客写下一篇包含有恶意JavaScript代码的博客文章，文章发表后，所有访问该博客的用户，都会在他们的浏览器中执行这段恶意js代码。 攻击步骤： 1.攻击者将恶意代码提交到目标网站的数据库中。2.用户打开目标网站时，网站服务端将恶意代码从数据库中取出，拼接在HTML中返回给浏览器。3.用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行。4.恶意代码窃取用户数据并发送到攻击者的网站，或冒充用户行为，凋用目标网站接口执行攻击者指定的操作. 这种攻击常见于带有用户保存数据的网站功能，如论坛发帖，商品评论，用户私信等。 防御：预防存储型XSS攻击也是从输入和输出两个方面来考虑。 服务器接收到数据，在存储到数据库之前，进行转义和过滤危险字符; 前端接收到服务器传递过来的数据，在展示到页面前，先进行转义/过滤; 不论是反射型攻击还是存储型，攻击者总需要找到两个要点，即“输入点”与”输出点”，也只有这两者都满足，XSS攻击才会生效。“输入点”用于向 web页面注入所需的攻击代码，而“输出点”就是攻击代码被执行的地方。 DOM型XSSDOM型XSS攻击，实际上就是前端javascript代码不够严谨，把不可信的内容插入到了页面，在使用.innerHTML、.outerHTML、.appendChild、document.write()等API时要特别小心，不要把不可信的数据作为HTML插入到页面上，尽量使用.innerText、.textContent、.setAttribut()等. 攻击步骤： 1.攻击者构造出特殊数据，其中包含恶意代码。2.用户浏览器执行了恶意代码3.恶意窃取用户数据并发送到攻击者的网站，或冒充用户行为，调用目标网站接口执行攻击者指定的操作. DOM型XSS攻击中，取出和执行恶意代码由浏览器端完成，属于前端javascript自身的安全漏洞. 总结 XSS类型 存储型 反射型 DOM型 触发过程 1.黑客构造XSS脚本 2.正常用户访问携带XSS脚本的页面 正常用户访问携带XSS脚本的URL 正常用户访问携带XSS脚本的URL 数据存储 数据库 URL URL 谁来输出 后端web应用程序 后端web应用程序 前端js 输出位置 HTTP响应中 HTTP响应中 动态构造的DOM节点 一些其他的防范策略 HTTP-only Cookie:禁止JavaScript读取某些敏感Cookie，攻击者完成XSS注入后也无法窃取此Cookie属性：防止脚本冒充用户提交危险操作 在服务端使用HTTP的Content-Security-Policy头部来指定策略，或者在前端设置meta标答。 应对XSS攻击的主要手段还是编码与过滤两种，编码用于将特殊的符号 “&lt;、&gt;、&amp;、’、””进行html转义，而过滤则是阻止特定的标记、属性、事件。如果你不愿意为了严格的安全而限制产品本身的灵活，那么我更建议采用“编码”的方案。 CSRF攻击CSRF，即 Cross Site Request Forgery，中译是跨站请求伪造，是一种劫持受信任用户向服务器发送非预期请求的攻击方式。 通常情况下，CSRF 攻击是攻击者借助受害者的 Cookie 骗取服务器的信任，可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击服务器，从而在并未授权的情况下执行在权限保护之下的操作。 CSRF 情景示例：银行网站 A，它以 GET 请求来完成银行转账的操作，如： 1http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000 危险网站 B，它里面有一段 HTML 的代码如下: 1&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; 首先，你登录了银行网站 A ，然后访问危险网站 B ，噢，这时你会发现你的银行账户少了 1000 块… CSRF 攻击防范验证码验证码被认为是对抗 CSRF 攻击最简洁而有效的防御方法。 从上述示例中可以看出，CSRF 攻击往往是在用户不知情的情况下构造了网络请求。而验证码会强制用户必须与应用进行交互，才能完成最终请求。因为通常情况下，验证码能够很好地遏制 CSRF 攻击。 但验证码并不是万能的，因为出于用户考虑，不能给网站所有的操作都加上验证码。因此，验证码只能作为防御 CSRF 的一种辅助手段，而不能作为最主要的解决方案。 Referer Check根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。通过 Referer Check，可以检查请求是否来自合法的”源”。 比如，如果用户要删除自己的帖子，那么先要登录 www.c.com，然后找到对应的页面，发起删除帖子的请求。此时，Referer 的值是 http://www.c.com；当请求是从 www.a.com 发起时，Referer 的值是 http://www.a.com 了。因此，要防御 CSRF 攻击，只需要对于每一个删帖请求验证其 Referer 值，如果是以 www.c.com 开头的域名，则说明该请求是来自网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是 CSRF 攻击，可以拒绝该请求。 添加 token 验证CSRF 攻击之所以能够成功，是因为攻击者可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 Cookie 中，因此攻击者可以在不知道这些验证信息的情况下直接利用用户自己的 Cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 的root和alias的区别]]></title>
    <url>%2F2020%2F06%2F28%2Fnginx-root-alias%2F</url>
    <content type="text"><![CDATA[作用域nginx指定文件路径有两种方式root和alias，指令的使用方法和作用域： root语法：root path默认值：root html配置段：http、server、location、if alias语法：alias path配置段：location 区别root与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上。 root的处理结果是：root路径＋location路径 alias的处理结果是：使用alias路径替换location路径 alias是一个目录别名的定义；root则是最上层目录的定义。 还有一个重要的区别是alias后面必须要用“/”结束，否则会找不到文件的；而root则可有可无。 示例root实例： 123location ^~ /t/ &#123; root /www/root/html/;&#125; 如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/t/a.html的文件。 alias实例： 123location ^~ /t/ &#123; alias /www/root/html/new_t/;&#125; 如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/new_t/a.html的文件。注意这里是new_t，因为alias会把location后面配置的路径丢弃掉，把当前匹配到的目录指向到指定的目录。 注意 使用alias时，目录名后面一定要加”/“。 alias在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。 alias只能位于location块中。（root可以不放在location中）]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域总结]]></title>
    <url>%2F2020%2F05%2F15%2Fcross-origin-resource-summary%2F</url>
    <content type="text"><![CDATA[什么是跨域 什么是Cross-origin_resource_sharing? 跨域请求存在的原因：由于浏览器的同源策略，即属于不同域的页面之间不能相互访问各自的页面内容。 跨域场景 域名不同 www.jiuyescm.com和www.jiuye.com即为不同的域名 二级域名相同，子域名不同 a.jiuyescm.com和b.jiuyescm.com为子域不同 端口不同，协议不同 http://www.jiuyescm.com和https://www.jiuyescm.com www.jiuyescm.com:8888和www.jiuyescm.com:8080 解决跨域的方式 jsonp 安全性差，已经不推荐 CORS（W3C标准，跨域资源共享 - Cross-origin resource sharing） 服务端设置，安全性高，推荐使用 websocke 特殊场景时使用，不属于常规跨域操作 代理服务（nginx） 可作为服务端cors配置的一种方式，推荐使用 如何处理跨域（CORS处理方式）常见错误 No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource，并且The response had HTTP status code 404 1XMLHttpRequest cannot load http://b.domain.com, Response to preflinght request doesn&apos;t pass access control check: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://a.domain.com&apos; is therefore not allowed access. The Response had HTTP status code 404. 问题原因：服务器端后台没有允许OPTIONS请求 No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource，并且The response had HTTP status code 405 1XMLHttpRequest cannot load http://b.domain.com, Response to preflinght request doesn&apos;t pass access control check: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://a.domain.com&apos; is therefore not allowed access. The Response had HTTP status code 405. 问题原因：服务器端后台允许了OPTIONS请求，但是某些安全配置阻止了OPTIONS请求 No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource，并且The response had HTTP status code 200 1XMLHttpRequest cannot load http://b.domain.com, Response to preflinght request doesn&apos;t pass access control check: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos;http://a.domain.com&apos; is therefore not allowed access. 问题原因：服务器端后台允许了OPTIONS请求，并且OPTIONS请求没有被阻止，但是头部不匹配。 heade contains multiple values &#39;*,*&#39;，并且The response had HTTP status code 200 1XMLHttpRequestcannot load http://b.domain.com. The &apos;Access-Control-Allow-Origin&apos; header contains multiple values&apos;*, *&apos;, but only one is allowed. Origin &apos;http://a.domain.com&apos; is therefore notallowed access. 问题原因：设置多次Access-Control-Allow-Origin=*，可能是配置的人对CORS实现原理和机制不了解导致。 OPTIONS请求?有时你会发现明明请求的是POST、GET、PUT、DELETE，但是浏览器中看到的确实OPTION，，为什么会变成OPTION？ 原因：因为本次Ajax请求是“非简单请求”,所以请求前会发送一次预检请求(OPTIONS)，这个操作由浏览器自己进行。如果服务器端后台接口没有允许OPTIONS请求,将会导致无法找到对应接口地址，因此需要服务端提供相应的信息到response header中，继续往下看。 后端需要返回的Header12345678910# 服务端允许访问的域名Access-Control-Allow-Origin=https://idss-uat.jiuyescm.com# 服务端允许访问Http MethodAccess-Control-Allow-Methods=GET, POST, PUT, DELETE, PATCH, OPTIONS# 服务端接受跨域带过来的Cookie,当为true时,origin必须是明确的域名不能使用*Access-Control-Allow-Credentials=true# Access-Control-Allow-Headers 表明它允许跨域请求包含content-type头，我们这里不设置，有需要的可以设置#Access-Control-Allow-Headers=Content-Type,Accept# 跨域请求中预检请求(Http Method为Option)的有效期,20天,单位秒Access-Control-Max-Age=1728000 如果跨域需要携带cookie去请求，Access-Control-Allow-Credentials必须为true，但是需要注意当Access-Control-Allow-Credentials=true时，Access-Control-Allow-Origin就不能为” * “ ，必须是明确的域名，当然可以多个域名使用 “,” 分割]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁 悲观锁 共享锁 排他锁]]></title>
    <url>%2F2020%2F05%2F15%2Fmysql-database-lock%2F</url>
    <content type="text"><![CDATA[乐观锁概念乐观锁是逻辑概念上的锁，不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库（更新操作）时，想法很乐观，认为这次操作不会导致冲突，在操作数据库时，并不进行任何其他特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突。 实现在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等。如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。 例，下单操作包括3步骤： 查询出商品信息 1select (status,version) from t_goods where id=#&#123;id&#125;; 根据商品信息生成订单 修改商品status为2 1update t_goods set status=2, version=version+1 where id=#&#123;id&#125; and version=#&#123;version&#125;; 悲观锁概念悲观锁就是在操作数据时，默认此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中的synchronized很相似，所以悲观锁需要耗费较多的时间。悲观锁的实现，依靠数据库提供的锁机制，使用的时候直接调用数据库的相关语句就可以了。 数据库上的操作可以归纳为两种：读和写。多个事务同时读取一个对象的时候，是不会有冲突的；同时读和写，或者同时写才会产生冲突。 MyIsam引擎会为查询和更新等操作自动添加表级锁，因此它的情况比较简单。InnoDB引擎情况比较复杂，它通常会定义两种锁：共享锁和排它锁。 共享锁概念共享锁(Shared Lock，也叫S锁)表示对数据进行读操作，加锁后其他事务可以读，但不能写。多个事务可以同时为一个对象加共享锁。 实现1SELECT ... LOCK IN SHARE MODE 这是IS锁(意向共享锁)，即在符合条件的rows上都加了共享锁，这样的话，其他人可以读取这些记录，也可以继续添加IS锁，但是无法修改这些记录直到你这个加锁的过程执行完成【完成的情况有：事务的提交，事务的回滚，否则直接锁等待超时】。 SELECT ... LOCK IN SHARE MODE的应用场景适合于两张表存在关系时的写操作，拿mysql官方文档的例子来说：一个表是child表，一个是parent表，假设child表的某一列child_id映射到parent表的c_child_id列，那么从业务角度讲，此时我直接insert一条child_id=100记录到child表是存在风险的，因为刚insert的时候可能在parent表里删除了这条c_child_id=100的记录，那么业务数据就存在不一致的风险。正确的方法是再插入时执行select * from parent where c_child_id=100 lock in share mode,锁定了parent表的这条记录，然后执行insert into child(child_id) values (100)就不会存在这种问题了。 排他锁概念排他锁(Exclusive Lock，也叫X锁)也叫写锁。加锁后，其他事务不能读取，也不能写。如果一个事务对对象加了排他锁，其他事务就不能再给它加任何锁了。 实现产生排他锁的sql： 1SELECT ... FOR UPDATE 总结 要记住锁机制一定要在事务中才能生效，事务也就要基于MySQL InnoDB 引擎。 访问量不大，不会造成压力时使用悲观锁，面对高并发的情况下，我们应该使用乐观锁。 读取频繁时使用乐观锁，写入频繁时则使用悲观锁。还有一点：乐观锁不能解决脏读的问题。 共享锁适用于两张表存在业务关系时的一致性要求，排它锁适用于操作同一张表时的一致性要求。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Myisam和InnoDB解析]]></title>
    <url>%2F2020%2F04%2F27%2Fdatabase-myisam-innodb%2F</url>
    <content type="text"><![CDATA[数据库文件两种不同引擎创建后生成的文件如下，说明这两个引擎数据和索引的组织方式是不一样的。 Innodb 创建表后生成的文件有： frm:创建表的语句 idb:表里面的数据+索引文件 Myisam 创建表后生成的文件有 frm:创建表的语句 MYD:表里面的数据文件（myisam data） MYI:表里面的索引文件（myisam index） 从生成的文件看来，这两个引擎底层数据和索引的组织方式并不一样，MyISAM 引擎把数据和索引分开了，一人一个文件，这叫做非聚集索引方式；Innodb 引擎把数据和索引放在同一个文件里了，这叫做聚集索引方式。 下面将从底层实现角度分析这两个引擎是怎么依靠 B+树这个数据结构来组织引擎实现的。 MyISAM 引擎的底层实现（非聚集索引方式）MyISAM 用的是非聚集索引方式，即数据和索引落在不同的两个文件上。MyISAM 在建表时以主键作为 KEY 来建立主索引 B+树，树的叶子节点存的是对应数据的物理地址。我们拿到这个物理地址后，就可以到 MyISAM 数据文件中直接定位到具体的数据记录了。 当我们为某个字段添加索引时，我们同样会生成对应字段的索引树，该字段的索引树的叶子节点同样是记录了对应数据的物理地址，然后也是拿着这个物理地址去数据文件里定位到具体的数据记录。 Innodb 引擎的底层实现（聚集索引方式）InnoDB 是聚集索引方式，因此数据和索引都存储在同一个文件里。首先 InnoDB 会根据主键 ID 作为 KEY 建立索引 B+树，如左下图所示，而 B+树的叶子节点存储的是主键 ID 对应的数据，比如在执行 select * from user_info where id=15 这个语句时，InnoDB 就会查询这颗主键 ID 索引 B+树，找到对应的 user_name=&#39;Bob&#39;。 这是建表的时候 InnoDB 就会自动建立好主键 ID 索引树，这也是为什么 Mysql 在建表时要求必须指定主键的原因。当我们为表里某个字段加索引时 InnoDB 会怎么建立索引树呢？比如我们要给 user_name 这个字段加索引，那么 InnoDB 就会建立 user_name 索引 B+树，节点里存的是 user_name 这个 KEY，叶子节点存储的数据的是主键 KEY。注意，叶子存储的是主键 KEY！拿到主键 KEY 后，InnoDB 才会去主键索引树里根据刚在 user_name 索引树找到的主键 KEY 查找到对应的数据。 问题来了，为什么 InnoDB 只在主键索引树的叶子节点存储了具体数据，但是其他索引树却不存具体数据呢，而要多此一举先找到主键，再在主键索引树找到对应的数据呢? 其实很简单，因为 InnoDB 需要节省存储空间。一个表里可能有很多个索引，InnoDB 都会给每个加了索引的字段生成索引树，如果每个字段的索引树都存储了具体数据，那么这个表的索引数据文件就变得非常巨大（数据极度冗余了）。从节约磁盘空间的角度来说，真的没有必要每个字段索引树都存具体数据，通过这种看似“多此一举”的步骤，在牺牲较少查询的性能下节省了巨大的磁盘空间，这是非常有值得的。 总结在进行 InnoDB 和 MyISAM 特点对比时谈到，MyISAM 查询性能更好，从上面索引文件数据文件的设计来看也可以看出原因：MyISAM 直接找到物理地址后就可以直接定位到数据记录，但是 InnoDB 查询到叶子节点后，还需要再查询一次主键索引树，才可以定位到具体数据。等于 MyISAM 一步就查到了数据，但是 InnoDB 要两步，那当然 MyISAM 查询性能更高。 最后再总结一下什么时候需要给你的表里的字段加索引吧： 较频繁的作为查询条件的字段应该创建索引； 唯一性太差的字段不适合单独创建索引，即使该字段频繁作为查询条件； 更新非常频繁的字段不适合创建索引。 区别 Myisam InnoDB 不支持事务 支持事务 支持表级锁 支持行级锁 适合执行大量select操作 适合执行大量insert或update操作 保存行数，count操作快 不保存行数，count操作要扫表 适合频繁查询和count操作 适合更新和查询都频繁的操作 行级锁中的 共享锁 和 排他锁 ： 共享锁：也叫 读锁 或 S锁，就是多个事物对于同一数据可以共享一把锁，都能访问到数据，但是只能读，不能修改。 排他锁：也叫 写锁 或 X锁，就是不能与其他锁共存，如果一个事务获取了一行数据的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁。但是获取排他锁的事务是可以对数据进行读取和修改的。 普通select查询没有任何锁机制。 update、insert、delete操作会自动加上排他锁。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树、AVL树、B树 和 B+树]]></title>
    <url>%2F2020%2F04%2F27%2Fdatabase-index-tree%2F</url>
    <content type="text"><![CDATA[我们知道，索引的作用是做数据的快速检索，而快速检索的实现本质是数据结构。通过不同数据结构的选择，实现各种数据的快速检索。下面介绍几种MySQL索引底层数据结构选型： 红黑树特征： 他是一棵BST树 节点是红色或黑色 根是黑色 所有叶子都是黑色 每个红色节点必须有两个黑色的子节点 从任一节点到每个叶子节点的所有简单路径都包含相同数目的黑色节点 示例： 红黑树插入情况总结： 当前节点是根节点：把根节点改为黑色 当前节点的父节点是黑节点：保持不变 当前节点的父节点是红节点，并且当前节点的叔叔节点是红节点：把交节点和叔叔节点改为黑色把祖父节点改为红色，把祖父节点作为当前节点，向上判断 当前节点的父节点是红节点，并且当前节点的叔叔节点不是红节点：四种情况 祖父节点一＞父节点一＞当前节点，是一直向右：做左旋操作，再把父节点改为黑色，之前的祖父节点改为红色 祖父节点一＞父节点一＞当前节点，是一直向左：做右旋操作，再把父节点改为黑色，之前的祖父节点改为红色 祖父节点一＞父节点一＞当前节点，是先向左再向右：先对当前节点做左旋操作，再对当前节点做右旋操作，然后把当前节点改为黑色，之前的祖父节点改为红色 祖父节点一＞父节点一＞当前节点，是先向右再向左：先对当前节点做右旋操作，再对当前节点做左旋操作，然后把当前节点改为黑色，之前的祖父节点改为红色 总结： 红黑树是一颗会自动调整树形态的树结构，比如当二叉树处于一个不平衡状态时，红黑树就会自动左旋右旋节点以及节点变色，调整树的形态，使其保持基本的平衡状态（时间复杂度为 $O(log n)$），也就保证了查找效率不会明显减低。 但是红黑树也存在一些问题，红黑树并没有完全解决二叉查找树，虽然这个“右倾”趋势远没有二叉查找树退化为线性链表那么夸张，但是数据库中的基本主键自增操作，主键一般都是数百万数千万的，如果红黑树存在这种问题，对于查找性能而言也是巨大的消耗，我们数据库不可能忍受这种无意义的等待的。 AVL树AVL树是另一种更为严格的自平衡二叉树。因为 AVL 树是个绝对平衡的二叉树，因此他在调整二叉树的形态上消耗的性能会更多。特征： 它是一棵BST树 它每个节点的左右子树高度之差不超过1 从树的形态看来，AVL 树不存在红黑树的“右倾”问题。也就是说，大量的顺序插入不会导致查询性能的降低，这从根本上解决了红黑树的问题。 总结： 不错的查找性能$O(log n)$，不存在极端的低效查找的情况。 可以实现范围查找、数据排序。 看起来 AVL 树作为数据查找的数据结构确实很不错，但是 AVL 树并不适合做 Mysql 数据库的索引数据结构，因为考虑一下这个问题： 数据库查询数据的瓶颈在于磁盘 IO，如果使用的是 AVL 树，我们每一个树节点只存储了一个数据，我们一次磁盘 IO 只能取出来一个节点上的数据加载到内存里，那比如查询 id=0007 这个数据我们就要进行磁盘 IO 四次，这是多么消耗时间的。所以我们设计数据库索引时需要首先考虑怎么尽可能减少磁盘 IO 的次数。 磁盘 IO 有个有个特点，就是从磁盘读取 1B 数据和 1KB 数据所消耗的时间是基本一样的，我们就可以根据这个思路，我们可以在一个树节点上尽可能多地存储数据，一次磁盘 IO 就多加载点数据到内存，这就是 B 树，B+树的的设计原理了。 B树B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个）。 B树的组成： 关键字（可以理解为数据） 指向孩子节点的指针 B 树的节点如下图所示，每个节点可以有不只一个数据，同时拥有数据数加一个子树，同时每个节点左子树的数据比当前节点都小、右子树的数据都比当前节点的数据大： 一棵B树必须满足以下条件： 若根结点不是终端结点，则至少有2棵子树 除根节点以外的所有非叶结点至少有 ceil(M/2) 棵子树，至多有 M 个子树（关键字数为子树减1, M 阶 B 树表示该树每个节点最多有 M 个子树） 所有的叶子结点都位于同一层 B树优点： 优秀检索速度，时间复杂度：B 树的查找性能等于 $O(hlogn)$，其中 h 为树高，n 为每个节点关键词的个数； B 树的每个节点可以表示的信息更多，因此整个树更加“矮胖”，这在从磁盘中查找数据（先读取到内存、后查找）的过程中，可以减少磁盘 IO 的次数，从而提升查找速度； 可以支持范围查找。 使用场景：文件系统和数据库系统中常用的B/B+ 树，他通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少IO操作。他广泛用于文件系统及数据库中，如： Windows：HPFS 文件系统 Mac：HFS，HFS+ 文件系统 Linux：ResiserFS，XFS，Ext3FS，JFS 文件系统 数据库：ORACLE，MYSQL，SQLSERVER 等中 B+树B树的升级版B+树：它比B树的查询性能更高。 一棵 B+ 树需要满足以下条件： 节点的子树数和关键字数相同（B 树是关键字数比子树数少一） 节点的关键字表示的是子树中的最大数，在子树中同样含有这个数据 叶子节点包含了全部数据，同时符合左小右大的顺序 简单概括下 B+ 树的三个特点： 关键字数和子树相同 非叶子节点仅用作索引，它的关键字和子节点有重复元素 叶子节点用指针连在一起 B 树和 B+树 的不同点： B 树一个节点里存的是数据，而 B+树存储的是索引（地址），所以 B 树里一个节点存不了很多个数据，但是 B+树一个节点能存很多索引，B+树叶子节点存所有的数据。 B+树的叶子节点是数据阶段用了一个链表串联起来，便于范围查找。 分析：通过 B 树和 B+树的对比我们看出，B+树节点存储的是索引，在单个节点存储容量有限的情况下，单节点也能存储大量索引，使得整个 B+树高度降低，减少了磁盘 IO。其次，B+树的叶子节点是真正数据存储的地方，叶子节点用了链表连接起来，这个链表本身就是有序的，在数据范围查找时，更具备效率。因此 Mysql 的索引用的就是 B+树，B+树在查找效率、范围查找中都有着非常不错的性能。 总结B+ 树的三个优点： 层级更低，IO 次数更少 每次都需要查询到叶子节点，查询性能稳定 叶子节点形成有序链表，范围查询方便]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-矩阵]]></title>
    <url>%2F2020%2F04%2F16%2Falgorithm-matrix%2F</url>
    <content type="text"><![CDATA[01矩阵 LeetCode-542给定一个由 0 和 1 组成的矩阵，找出每个元素到最近的 0 的距离。 两个相邻元素间的距离为 1 。 Example 1: 123456789Input:[[0,0,0], [0,1,0], [0,0,0]]Output:[[0,0,0], [0,1,0], [0,0,0]] Example 2: 123456789Input:[[0,0,0], [0,1,0], [1,1,1]]Output:[[0,0,0], [0,1,0], [1,2,1]] 注意: 给定矩阵的元素个数不超过 10000。 给定矩阵中至少有一个元素是 0。 矩阵中的元素只在四个方向上相邻: 上、下、左、右。 解法：使用广度优先搜索， 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; /** * @param Integer[][] $matrix * @return Integer[][] */ function updateMatrix($matrix) &#123; $res = []; //返回结果数组 $queue = new SplQueue(); // 初始化队列，用来存储每层上的点 foreach ($matrix as $i =&gt; $item) &#123; foreach ($item as $j =&gt; $v) &#123; if ($v === 0) &#123; // 将题目转化为 0到其他点的距离 $res[$i][$j] = 0; // 0到自身的距离为0 $queue-&gt;enqueue([$i, $j]); // 将找到的0的坐标放在队列中 &#125; &#125; &#125; // BFS经典模板 while (!$queue-&gt;isEmpty()) &#123; // 取出某层上的点 list($x, $y) = $queue-&gt;dequeue(); // 加上四个方向的偏移量 foreach ([[0, 1], [0, -1], [1, 0], [-1, 0]] as list($x_bias, $y_bias)) &#123; $new_x = $x + $x_bias; $new_y = $y + $y_bias; // 判断扩展点的有效性 if (0 &lt;= $new_x &amp;&amp; $new_x &lt; count($matrix) &amp;&amp; 0 &lt;= $new_y &amp;&amp; $new_y &lt; count($matrix[0]) &amp;&amp; !isset($res[$new_x][$new_y])) &#123; // 将新点的坐标和距离写入结果数组 $res[$new_x][$new_y] = $res[$x][$y] + 1; // 将新扩展点加入队列 $queue-&gt;enqueue([$new_x, $new_y]); &#125; &#125; &#125; // 二位结果集数组，按照key排序 ksort($res); foreach ($res as &amp;$item) &#123; ksort($item); &#125; return $res; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-链表]]></title>
    <url>%2F2020%2F04%2F16%2Falgorithm-link-list%2F</url>
    <content type="text"><![CDATA[两数相加 LeetCode-2给出两个非空的链表用来表示两个非负的整数。其中，它们各自的位数是按照逆序的方式存储的，并且它们的每个节点只能存储一位数字。 如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。 您可以假设除了数字 0 之外，这两个数都不会以 0 开头。 示例： 123输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)输出：7 -&gt; 0 -&gt; 8原因：342 + 465 = 807 code： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * Definition for a singly-linked list. * class ListNode &#123; * public $val = 0; * public $next = null; * function __construct($val) &#123; $this-&gt;val = $val; &#125; * &#125; */class Solution &#123; /** * @param ListNode $l1 * @param ListNode $l2 * @return ListNode */ function addTwoNumbers($l1, $l2) &#123; $t = $l1; $k = 0; do &#123; $val = $t-&gt;val + $l2-&gt;val + $k; $t-&gt;val = $val % 10; $k = $val &gt;= 10 ? 1 : 0; if (!$t-&gt;next &amp;&amp; !$l2-&gt;next &amp;&amp; $k) &#123; $t-&gt;next = new ListNode(1); break; &#125; if($t-&gt;next &amp;&amp; !$l2-&gt;next) &#123; $l2-&gt;next = new ListNode(0); &#125; if($l2-&gt;next &amp;&amp; !$t-&gt;next) &#123; $t-&gt;next = new ListNode(0); &#125; $t = $t-&gt;next; $l2 = $l2-&gt;next; &#125; while ($t); return $l1; &#125;&#125; 两数相加II LeetCode-445给你两个非空链表来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储一位数字。将这两数相加会返回一个新的链表。 你可以假设除了数字 0 之外，这两个数字都不会以零开头。 进阶： 如果输入链表不能修改该如何处理？换句话说，你不能对列表中的节点进行翻转。 示例： 12输入：(7 -&gt; 2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)输出：7 -&gt; 8 -&gt; 0 -&gt; 7 1234567class ListNode &#123; public $val = 0; public $next = null; function __construct($val) &#123; $this-&gt;val = $val; &#125; &#125; 解法1：栈 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; /** * 对于逆序处理，用栈处理 * @param ListNode $l1 * @param ListNode $l2 * @return ListNode */ function addTwoNumbersII($l1, $l2) &#123; if ($l1 === null) &#123; return $l2; &#125; if ($l2 === null) &#123; return $l1; &#125; // 初始化栈 $stack1 = new SplStack(); $stack2 = new SplStack(); // 入栈 while ($l1 !== null) &#123; $stack1-&gt;push($l1-&gt;val); $l1 = $l1-&gt;next; &#125; while ($l2 !== null) &#123; $stack2-&gt;push($l2-&gt;val); $l2 = $l2-&gt;next; &#125; $k = 0; $head = null; while (!$stack1-&gt;isEmpty() || !$stack2-&gt;isEmpty() || $k &gt; 0) &#123; $sum = $k; $sum += $stack1-&gt;isEmpty() ? 0 : $stack1-&gt;pop(); $sum += $stack2-&gt;isEmpty() ? 0 : $stack2-&gt;pop(); $node = new ListNode($sum % 10); $node-&gt;next = $head; $head = $node; $k = floor($sum / 10); &#125; return $head; &#125;&#125; 解法2：翻转链表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123; /** * @param ListNode $l1 * @param ListNode $l2 * @return ListNode */ function addTwoNumbersII($l1, $l2) &#123; // 翻转链表 $list_rev = function ($listNode) &#123; $prev = null; $cur = $listNode; while ($cur) &#123; $next = $cur-&gt;next; // 新链表从后往前生成 $cur-&gt;next = $prev; $prev = $cur; $cur = $next; &#125; return $prev; &#125;; $l1 = $list_rev($l1); $l2 = $list_rev($l2); $res = null; $add = false; while ($l1 || $l2 || $add) &#123; $sum = $add ? 1 : 0; if ($l1) &#123; $sum += $l1-&gt;val; $l1 = $l1-&gt;next; &#125; if ($l2) &#123; $sum += $l2-&gt;val; $l2 = $l2-&gt;next; &#125; if ($sum &gt;= 10) &#123; $sum -= 10; $add = true; &#125; else &#123; $add = false; &#125; // 返回链表也是从后往前生成 $node = new ListNode($sum); $node-&gt;next = $res; $res = $node; &#125; return $res; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 部署到GitHub时categories中的大小写问题]]></title>
    <url>%2F2020%2F04%2F16%2Fhexo-categories-case-error%2F</url>
    <content type="text"><![CDATA[起因使用Hexo添加新文章后，部署到GitHub上，有时候新增或者修改了tag或者categories，比如新增categories为Mac，然后再本地.deploy_git/categories中，Mac目录显示正常，本地预览正常，但是推送到GitHub后，categories目录中显示为mac，从而导致点击Mac分类时显示404。 原因这个问题是由于git命令默认的配置中忽略了文件名的大小写，因此即便文件夹的大小写发生了变更，git也会表现出置之不理。 解决1cd blog 修改git配置，进入.deploy_git，修改.git/config文件，将ignorecase = true修改为ignorecase = false 12cd .deploy_gitsudo vim .git/config 接着删除.deploy_git文件夹中git仓库的所有文件，并push到GitHub，清空你的github.io项目 123sudo git rm -rf *sudo git commit -m &quot;clean all file&quot;sudo git push 返回blog目录，重新编译并上传 123sudo hexo cleansudo hexo gsudo hexo d 重新刷新页面，大小写问题解决。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 插入数学公式]]></title>
    <url>%2F2020%2F04%2F16%2Fhexo-math%2F</url>
    <content type="text"><![CDATA[安装配置hexo-mathhexo 中已经对mathjax、katex 进行了集成，这里使用的是mathjax，需要先下载 hexo-math 1npm install hexo-math --save 然后在站点目录下_config.yml 中配置 123math: engine: &apos;mathjax&apos; # or &apos;katex&apos; mathjax: 然后在主题目录下_config.yml 中配置，我这里使用的 Next主题，默认就有配置，只需要将 math 下enable 改为true 即可： 1234567891011121314math: enable: true # Default (true) will load mathjax / katex script on demand. # That is it only render those page which has `mathjax: true` in Front-matter. # If you set it to false, it will load mathjax / katex srcipt EVERY PAGE. per_page: true engine: mathjax #engine: katex # hexo-renderer-pandoc (or hexo-renderer-kramed) needed to full MathJax support. mathjax: cdn: //cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML 其中 per_page 根据提示，表示默认不加载 mathjax/katex 脚本，如果设置为 false，则是每篇文章都会去加载 mathjax 脚本，这里我设置为 true，然后在需要加载的文章抬头添加 mathjax: true 即可，例如： 123456---title: hexo 插入数学公式date: 2020-04-14 16:35:11mathjax: truetags: --- 简单语法行内公式 行内的公式用$公式内容$ 包裹起来，在公式中右键即可查看公式 $\TeX$ 代码 显示在行内的公式：$g(x)=8 \times ln \ x$，另外一个公式：$f(x)=ax^2+bx+c$ 多行公式 多行公式用$$公式内容$$包裹起来，独占一行，同样右键可查看公式代码 矩阵$$\left[ \begin{array}{lll}{1} &amp; {2} &amp; {3} \\ {4} &amp; {5} &amp; {6} \\ {7} &amp; {8} &amp; {9}\end{array}\right]$$ 指数与平方根$$\sqrt{x^{2a}+\sqrt{y}}$$ 分数$$\frac{x^{2}}{k + 1}$$ 常用符号$$+ - \times \div$$$$\pm \cdot \times \div \cup \cap \star \leq \ll \geq \gg$$$$\sim \simeq \approx$$ $\LaTeX$语法参考链接：一份不太简短的 $\LaTeX$ 2ε 介绍]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置HTTPS]]></title>
    <url>%2F2020%2F04%2F14%2Fnetwork-nginx-https%2F</url>
    <content type="text"><![CDATA[由于自己是阿里云的域名，所以在阿里云的 SSL证书 中申请的ssl证书。 证书申请流程： 下载的Nginx证书压缩文件解压后包含： .pem：证书文件。PEM文件的扩展名为CRT格式。 .key：证书的密钥文件。申请证书时如果未选择自动创建CRS，则下载的证书文件压缩包中不会包含.key文件，需要您将自己手动常见的私钥文件拷贝到cert目录下。 在阿里云下载证书之后，复制到nginx中，配置nginx，主要代码块如下： 1234567891011121314151617# For httpsserver &#123; listen 443 ssl default_server; listen [::]:443 ssl default_server ipv6only=on; ssl_certificate /var/www/laradock/nginx/ssl/2908009.pem; ssl_certificate_key /var/www/laradock/nginx/ssl/2908009.key; server_name xxx.com www.xxx.com; root /var/www/public; index index.php index.html index.htm;&#125;# http 跳转到 httpsserver &#123; listen 80; server_name www.xxx.com; return 301 https://$server_name$request_uri;&#125; 重启nginx服务。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS详解]]></title>
    <url>%2F2020%2F04%2F14%2Fnetwork-https%2F</url>
    <content type="text"><![CDATA[1.什么是httpsHTTP 协议（HyperText Transfer Protocol，超文本传输协议）：是客户端浏览器或其他程序与Web服务器之间的应用层通信协议 。 HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：可以理解为 HTTP+SSL/TLS， 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL，用于安全的 HTTP 数据传输。 2.https和http的区别 https的服务器需要到CA申请证书，以证明自己服务器的用途。 http信息是明文传输，https信息是密文传输。 http与https的端口不同，一个是80端口，一个是443端口。 3.https通讯步骤对称加密和非对称加密的结合 客户端请求服务器，发送握手消息 获取公钥：服务器发送了一个SSL证书给客户端，SSL 证书中包含的具体内容有： （1）证书的发布机构CA （2）证书的有效期 （3）公钥 （4）证书所有者 （5）签名 客户端在接受到服务端发来的SSL证书时，会对证书的真伪进行校验，以浏览器为例说明如下： （1）首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验 （2）浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发 （3）如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。 （4）如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密 （5）浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比 （6）对比结果一致，则证明服务器发来的证书合法，没有被冒充，此时浏览器会采用自身的随机数算法产生一个随机数作为对称秘钥 （7）此时浏览器就可以读取证书中的公钥，用于后续加密了 浏览器通过公钥加密（加密算法和对称秘钥），传递给服务器 服务器收到信息后，用私钥解密，提取出对称加密算法和对称秘钥，并用此对称密钥采用对称加密算法加密一段握手消息发送给浏览器 浏览器收到消息后解密成功，则握手结束，后续的信息都通过此对称密钥加密传输。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序]]></title>
    <url>%2F2020%2F04%2F14%2Falgorithm-sort%2F</url>
    <content type="text"><![CDATA[冒泡排序对数组按照从小到大进行排序，从前往后对相邻的两个数依次进行比较和调整，让较大的往后移动，每轮将最大的数移动到最后。 123456789101112131415161718function blbble_sort($arr) &#123; $count = count($arr); if($count == 0) &#123; return false; &#125; for($i = 0; $i &lt; $count; $i++) &#123; // 循环控制每轮，将该轮最大的数字移动到最后 for($j = 0; $j &lt; $count - $i; $j++) &#123; if($arr[$j] &gt; $arr[$j + 1]) &#123; $temp = $arr[$j]; $arr[$j] = $arr[$j + 1]; $arr[$j + 1] = $temp; &#125; &#125; &#125; return $arr;&#125; 选择排序在数组中，选出最小的一个数与第一个位置的数交换，然后再在剩下的数中找出最小的数与第二个位置的数进行交换，如此循环到倒数第二个数与最后一个数比较为止。 1234567891011121314151617181920212223242526public function selectSort($arr)&#123; $len = count($arr); // 双层循环，外层控制轮数，内层控制比较次数 for ($i = 0; $i &lt; $len-1; $i++) &#123; // 先假设最小值的位置 $p = $i; for ($j = $i + 1; $j &lt; $len; $j++) &#123; // $arr[$p]是当前已知的最小值 // 比较，发现更小的，记录下最小值的位置；并且在下次比较的时候采用已知的最小值进行比较 if ($arr[$p] &gt; $arr[$j]) &#123; $p = $j; &#125; &#125; // 最小值的位置为$p，如果发现最小值的位置和当前假设的位置$i不同，则位置互换即可 if ($p != $i) &#123; $tmp = $arr[$p]; $arr[$p] = $arr[$i]; $arr[$i] = $tmp; &#125; &#125; return $arr;&#125; 插入排序在需要排序的数组中，假设前面的数已经是排序好的，现在要把第n个数插入到前面的有序数组中，使得这n个数也是排序好的。如此反复循环，直到全部排好顺序。 12345678910111213141516171819202122public function insertSort($arr)&#123; $len = count($arr); for ($i = 1; $i &lt; $len; $i++) &#123; // 要插入的元素 $tmp = $arr[$i]; // 内层是在外层之前的数组 for ($j = $i - 1; $j &gt;= 0; $j--) &#123; // 发现插入的元素要小，交换位置，将后边的元素与前面的元素互换 if ($tmp &lt; $arr[$j]) &#123; $arr[$j + 1] = $arr[$j]; $arr[$j] = $tmp; &#125; else &#123; // 如果碰到不需要移动的元素，由于是已经排序好是数组，则前面的就不需要再次比较了,跳出内层循环 break; &#125; &#125; &#125; return $arr;&#125; 快速排序选择一个基准元素，通过一趟扫描，将数组分成两部分，一部分比基准元素小，一部分大于等于基准元素，此时基准元素在其排好序后的中间位置，然后再用同样的方法递归地排序划分的两部分。 12345678910111213141516171819202122function quick_sort(array $list) &#123; $len = count($list); if($len &lt;= 1) &#123; return $list; &#125; // 选择第一个元素作为基准元素 $pivotValue = $list[0]; $left = array(); $right = array(); // 遍历除了基准元素以外的所有元素，按照大小关系放入两个数组中 for ($i = 1; $i &lt; $lenght; $i++) &#123; if ($list[$i] &lt; $pivotValue) &#123; $left[] = $list[$i]; &#125; else &#123; $right[] = $list[$i]; &#125; &#125; // 再分别对左边和右边的数组进行相同的排序处理 $left = quick_sort($left); $right = quick_sort($right); return array_merge($left, array($pivotValue), $right);&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-搜索]]></title>
    <url>%2F2020%2F04%2F14%2Falgorithm-search%2F</url>
    <content type="text"><![CDATA[二分搜索如果数组中的项按顺序排列，就可以不必进行线性搜索，而可以使用二分搜索。查找时，先从中间数据开始，检查中间的项是否比我们要寻找的项大或小，并决定保留哪一半，并继续重复前面的搜索，直到找到需要搜索的值。搜索长度呈指数递减，所以，最坏和平均时间复杂度为$O(logn)$，空间复杂度为$O(1)$。 12345678910111213141516function binSearch($arr, $search) &#123; // 搜索数组的最大和最小下标 $height = count($arr) - 1; $low = 0; while($low &lt;= $height) &#123; $mid = floor(($low + $height) / 2); if($arr[$mid] == $search) &#123; return $mid; &#125; elseif ($arr[$mid] &lt; $search) &#123; $low = $mid + 1; &#125; elseif($arr[$mid] &gt; $search) &#123; $height = $mid -1; &#125; &#125; return '查找失败';&#125; 递归版本： 1234567891011121314function binarySearchRecursion(array $arr, int $needle, int $low, int $high)&#123; if ($high &lt; $low) return false; $middle = (int)(($high + $low) / 2); if ($arr[$middle] &lt; $needle) &#123; return binarySearchRecursion($arr, $needle, $middle + 1, $high); &#125; elseif ($arr[$middle] &gt; $needle) &#123; return binarySearchRecursion($arr, $needle, $low, $middle - 1); &#125; else &#123; return true; &#125;&#125; 重复二分搜索假设我们有一个含有重复数据的数组，如果我们想从数组中找到某个数的第一次出现的位置，就可以修改上面的二分搜索。需要修改的地方是找到搜索值时，将下标赋值给firstIndex，并不返回，并重复查找，直到$low &gt; $high。 12345678910111213141516171819202122public function repetitiveBinarySearch($arr, $search)&#123; $low = 0; $high = count($arr); $firstIndex = -1; while ($low &lt;= $high) &#123; // 右移一位，即是：除二取整 $middle = ($low + $high) &gt;&gt; 1; if ($arr[$middle] === $search) &#123; $firstIndex = $middle; $high = $middle - 1; &#125; elseif ($arr[$middle] &gt; $search) &#123; $high = $middle - 1; &#125; else &#123; $low = $middle + 1; &#125; &#125; return $firstIndex;&#125; 插值搜索如果一个数组是均匀分布的，并且我们正在寻找的数据可能接近数组的末尾，那么从中间搜索可能不是一个好选择。 在这种情况下，插值搜索可能非常有用。插值搜索是对二分搜索算法的改进，插值搜索可以基于搜索的值选择到达不同的位置。例如，如果我们正在搜索靠近数组开头的值，它将直接定位到到数组的第一部分而不是中间。使用公式计算位置，如下所示： $middle = low + [(key - arr[low]) * (high - low) / (arr[high] - arr[low])]$ 1234567891011121314151617181920212223public function interpolationSearch($arr, $search)&#123; $low = 0; $high = count($arr) - 1; while ($arr[$low] != $arr[$high] &amp;&amp; $search &gt;= $arr[$low] &amp;&amp; $search &lt;= $arr[$high]) &#123; $middle = intval($low + ($search - $arr[$low]) * ($high - $low) / ($arr[$high] - $arr[$low])); if ($arr[$middle] &lt; $search) &#123; $low = $middle + 1; &#125; elseif ($arr[$middle] &gt; $search) &#123; $high = $middle - 1; &#125; else &#123; return $middle; &#125; &#125; if ($search == $arr[$low]) &#123; return $low; &#125; return -1;&#125; 指数搜索在二分搜索中，我们在整个列表中搜索给定的数据。指数搜索通过决定搜索的下界和上界来改进二分搜索，这样我们就不会搜索整个列表。 我们通过查找第一个指数k来确定边界大小，其中值2^k的值大于搜索项。 现在，$2^k$和$2^{(k-1)}$分别成为上限和下限。 使用以上的边界来进行二分搜索。123456789101112function exponentialSearch($arr, $search) &#123; $length = count($arr); if ($length == 0) return -1; $bound = 1; while ($bound &lt; $length &amp;&amp; $arr[$bound] &lt; $search) &#123; $bound *= 2; &#125; return binarySearchRecursion($arr, $search, $bound &gt;&gt; 1, min($bound, $length));&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-二叉树]]></title>
    <url>%2F2020%2F04%2F14%2Falgorithm-binary-tree%2F</url>
    <content type="text"><![CDATA[遍历二叉树深度优先遍历 DFS二叉树的深度优先遍历可以细分为：先序遍历、中序遍历、后续遍历。 前序遍历：根节点 -&gt; 左子树 -&gt; 右子树 中序遍历：左子树 -&gt; 根节点 -&gt; 右子树 后续遍历：左子树 -&gt; 右子树 -&gt; 根节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;?php class BTreeNode &#123; public $data; //数据域 public $LeftHand = NULL; //左指针 public $RightHand = NULL ; //右指针 public function __construct($data) &#123; if(!empty($data)) &#123; $this-&gt;data = $data; &#125; &#125; //先序遍历（根，左，右）递归实现 public function PreTraverseBTree($BTree)&#123; if (NULL !== $BTree)&#123; var_dump($BTree-&gt;data);//根 if (NULL !== $BTree-&gt;LeftHand)&#123; $this-&gt;PreTraverseBTree($BTree-&gt;LeftHand); //递归遍历左树 &#125; if (NULL !== $BTree-&gt;RightHand)&#123; $this-&gt;PreTraverseBTree($BTree-&gt;RightHand); //递归遍历右树 &#125; &#125; &#125; //中序遍历(左，根，右)递归实现 public function InTraverseBTree($BTree)&#123; if (NULL !== $BTree)&#123; if (NULL !== $BTree-&gt;LeftHand)&#123; $this-&gt;InTraverseBTree($BTree-&gt;LeftHand); //递归遍历左树 &#125; var_dump($BTree-&gt;data); //根 if (NULL !== $BTree-&gt;RightHand)&#123; $this-&gt;InTraverseBTree($BTree-&gt;RightHand); //递归遍历右树 &#125; &#125; &#125; //后序遍历(左，右，根)递归实现 public function FexTarverseBTree($BTree)&#123; if (NULL !== $BTree)&#123; if (NULL !== $BTree-&gt;LeftHand)&#123; $this-&gt;FexTarverseBTree($BTree-&gt;LeftHand); //递归遍历左树 &#125; if (NULL !== $BTree-&gt;RightHand)&#123; $this-&gt;FexTarverseBTree($BTree-&gt;RightHand); //递归遍历右树 &#125; var_dump($BTree-&gt;data); //根 &#125; &#125; &#125; header("Content-Type:text/html;charset=utf-8"); echo '先的内存为'.var_dump(memory_get_usage()); echo '&lt;hr/&gt;'; //创建五个节点 $A = new BTreeNode('A'); $B = new BTreeNode('B'); $C = new BTreeNode('C'); $D = new BTreeNode('D'); $E = new BTreeNode('E'); //连接形成一个二叉树 $A-&gt;LeftHand = $B; $A-&gt;RightHand = $C; $C-&gt;LeftHand = $D; $D-&gt;RightHand = $E; //先序遍历 echo '先序遍历的结果'.'&lt;br&gt;'; $A-&gt;PreTraverseBTree($A); echo '&lt;br/&gt;中序遍历的结果'.'&lt;br&gt;'; $A-&gt;InTraverseBTree($A); echo '&lt;br/&gt;后序列遍历的结果'.'&lt;br/&gt;'; $A-&gt;FexTarverseBTree($A); echo '&lt;hr/&gt;'; echo '后的内存为'.var_dump(memory_get_usage()); 广度优先遍历 BFS广度优先遍历：又叫层次遍历，从上往下对每一层依次访问，在每一层中，从左往右（也可以从右往左）访问结点，访问完一层就进入下一层，直到没有结点可以访问为止。 1234567891011// Definition for a binary tree nodeclass TreeNode &#123; public $val = null; public $left = null; public $right = null; public function __construct($value) &#123; $this-&gt;val = $value; &#125;&#125; 版本1：数组模拟队列，先入先出 12345678910111213141516171819202122232425class Solution &#123; /** * @param TreeNode $root * @return array */ public function levelOrder(TreeNode $root) &#123; $res = $arr = []; if ($root == null) &#123; return $res; &#125; array_push($arr, $root); $level = 0; while ($count = count($arr)) &#123; for ($i = $count; $i &gt; 0; $i--) &#123; $node = array_shift($arr); // 先入先出 $res[$level][] = $node-&gt;val; if ($node-&gt;left != null) array_push($arr, $node-&gt;left); if ($node-&gt;right != null) array_push($arr, $node-&gt;right); &#125; $level++; &#125; return $res; &#125;&#125; 版本2：使用PHP SplQueue SplQueue 类通过使用一个双向链表来提供队列的主要功能。 1234567891011121314151617181920212223242526class Solution &#123; /** * @param TreeNode $root * @return array */ public function levelOrder(TreeNode $root) &#123; $res = []; $arr = new SplQueue(); if ($root == null) &#123; return $res; &#125; $arr-&gt;enqueue($root); $level = 0; while ($count = count($arr)) &#123; for ($i = $count; $i &gt; 0; $i--) &#123; $node = $arr-&gt;dequeue(); // 删除第一位 $res[$level][] = $node-&gt;val; if ($node-&gt;left != null) $arr-&gt;enqueue($node-&gt;left); if ($node-&gt;right != null) $arr-&gt;enqueue($node-&gt;right); &#125; $level++; &#125; return $res; &#125;&#125; 版本3：递归 123456789101112131415161718192021222324252627class Solution &#123; /** * @param TreeNode $root * @return array */ public function levelOrder(TreeNode $root) &#123; $res = []; $this-&gt;level($root, 0, $res); return $res; &#125; public function level($root, $level, &amp;$res) &#123; if ($root == null) &#123; return null; &#125; $res[$level][] = $root-&gt;val; $level++; if ($root-&gt;left != null) &#123; $this-&gt;level($root-&gt;left, $level, $res); &#125; if ($root-&gt;right != null) &#123; $this-&gt;level($root-&gt;right, $level, $res); &#125; &#125;&#125; 判断是否是二叉搜索树判断一颗树是否是二叉搜索树，一棵树是BST需要满足 一个节点的值大于它左子树所有节点的值 一个节点的值小于它右子树所有节点的值 左右子树也必须是二叉搜索树 所以只需要遍历每个节点，判断 该节点值是否大于左子树的最大值 该节点值是否小于右子树的最小值 123456789101112131415161718192021222324252627282930313233343536/** * Definition for a binary tree node. * class TreeNode &#123; * public $val; * public $left; * public $right; * &#125;; */class Solution &#123; public function isValidBST(TreeNode $root) &#123; if(!$root) return true; //大于左子树的最大值 $leftNode = $root-&gt;left; while($leftNode) &#123; if($root-&gt;val &lt;= $leftNode-&gt;val)&#123; return false; &#125; $leftNode = $leftNode-&gt;right; &#125; //小于右子树的最小值 $rightNode = $root-&gt;right; while($rightNode) &#123; if($root-&gt;val &gt;= $rightNode-&gt;val)&#123; return false; &#125; $rightNode = $rightNode-&gt;left; &#125; if(isValidBST($root-&gt;left) &amp;&amp; isValidBST($root-&gt;right))&#123; return true; &#125;else &#123; return false; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间复杂度 和 空间复杂度]]></title>
    <url>%2F2020%2F04%2F14%2Falgorithm-time-space%2F</url>
    <content type="text"><![CDATA[概念时间复杂度和空间复杂度是用来评价算法效率高低的两个标准。 时间复杂度：就是执行算法需要消耗的时间长短，越快越好。 空间复杂度：就是执行当前算法需要消耗的存储空间大小，也是越小越好。 时间复杂度计算表示方法我们一般用“大O符号表示法”来表示时间复杂度：$T(n) = O(f(n))$ $n$是影响复杂度变化的因子 $f(n)$是复杂度具体的算法。 常见时间复杂度 常数阶 $O(1)$ 线性阶 $O(n)$ 对数阶 $O(logN)$ 线性对数阶 $O(nlogN)$ 平方阶 $O(n^2)$ 立方阶 $O(n^3)$ K次方阶 $O(n^k)$ 指数阶 $O(2^n)$ 常数阶$O(1)$123$a = 1;$b = 2;$c = 3; 我们假定每执行一行代码所需要消耗的时间为1个时间单位，那么以上3行代码就消耗了3个时间单位。那是不是这段代码的时间复杂度表示为$O(n)$呢 ？其实不是的，因为大$O$符号表示法并不是用于来真实代表算法的执行时间的，它是用来表示代码执行时间的增长变化趋势的。上面的算法并没有随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用$O(1)$来表示它的时间复杂度。 线性阶$O(n)$1234for($i = 1; $i &lt;= n; $i++) &#123; $j = $i; $j++;&#125; 看这段代码会执行多少次呢？第1行会执行1次，第2行和第3行会分别执行$n$次，总的执行时间也就是$2n+1$次，那它的时间复杂度表示是 $O(2n + 1)$ 吗？ No !还是那句话：“大$O$符号表示法并不是用于来真实代表算法的执行时间的，它是用来表示代码执行时间的增长变化趋势的”。所以它的时间复杂度其实是$O(n)$。 对数阶$O(logN)$1234$i = 1;while($i &lt; n) &#123; $i = $i * 2;&#125; 可以看到每次循环的时候 i 都会乘2，那么总共循环的次数就是$log_{2}n$，因此这个代码的时间复杂度为$O(logn)$。这儿有个问题，为什么明明应该是$O(log_{2}n)$,却要写成$O(logn)$呢？其实这里的底数对于研究程序运行效率不重要，写代码时要考虑的是数据规模$n$对程序运行效率的影响，常数部分则忽略，同样的，如果不同时间复杂度的倍数关系为常数，那也可以近似认为两者为同一量级的时间复杂度。 线性对数阶$O(nlogN)$123456for($m = 1; $m &lt; $n; $m++) &#123; $i = 1; while($i &lt; $n) &#123; $i = $i * 2; &#125;&#125; 线性对数阶$O(nlogN)$其实非常容易理解，将时间复杂度为$O(logn)$的代码循环$N$遍的话，那么它的时间复杂度就是 $n * O(logN)$，也就是了$O(nlogN)$。 平方阶$O(n^2)$123456for($x=1; $i &lt;= $n; $x++)&#123; for($i = $1; $i &lt;= $n; $i++) &#123; $j = $i; $j++; &#125;&#125; 把 $O(n)$ 的代码再嵌套循环一遍，它的时间复杂度就是 $O(n^2)$ 了。 立方阶$O(n^3)$、K次方阶$O(n^k)$参考上面的$O(n^2)$去理解就好了，$O(n^3)$相当于三层n循环，其它的类似。 空间复杂度计算空间复杂度$O(1)$如果算法执行所需要的临时空间不随着某个变量$n$的大小而变化，即此算法空间复杂度为一个常量，可表示为 $O(1)$。 12345$i = 1;$j = 2;++$i;$j++;$m = $i + $j; 代码中的 i、j、m 所分配的空间都不随着处理数据量变化，因此它的空间复杂度 $S(n) = O(1)$。 空间复杂度$O(n)$12345$m = array(1,2,3,.....,n);for($i=1; $i &lt;= $n; ++$i) &#123; $j = $i; $j++;&#125; 这段代码中，第一行初始化一个数组出来，这个数据占用的大小为$n$，后面虽然有循环，但没有再分配新的空间，因此，这段代码的空间复杂度主要看第一行即可，即 $S(n) = O(n)$。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[压测工具—ab、webbench、siege]]></title>
    <url>%2F2020%2F03%2F20%2Fpressure-test-tools%2F</url>
    <content type="text"><![CDATA[相关概念吞吐率（Requests per second） 概念：服务并发处理能力的量化描述，单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。 计算公式：总请求数 / 处理完成这些请求数所花费的时间，即：Request per second = Complete requests / Time taken for tests 并发连接数（The number of concurrent connections） 概念：某个时刻服务器所接受的请求数目，简单的将，就是一个会话。 并发用户数（The number of concurrent users，Concurrency Level） 概念：要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。 用户平均请求等待时间（Time per request） 计算公式：处理完成所有请求数所花费的时间/ （总请求数 / 并发用户数），即：Time per request = Time taken for tests /（ Complete requests / Concurrency Level） 服务器平均请求等待时间（Time per request: across all concurrent requests） 计算公式：处理完成所有请求数所花费的时间 / 总请求数，即：Time taken for / testsComplete requests可以看到，它是吞吐率的倒数。同时，它也=用户平均请求等待时间/并发用户数，即Time per request / Concurrency Level Apache Bench ab是Apache的超文本传输协议（HTTP）的性能测试工具，可以测试apache、IIs、tomcat、nginx 等服务器。但是 ab 没有 Jmeter、Loadrunner 那样有各种场景设计、各种图形报告和监控，只需一个命令即可，有输出描述，可以简单的进行一些压力测试。 查看Apache版本Mac系统下自带 Apache，可以使用apachectl -v命令查看 Apache 版本： 123$ apachectl -vServer version: Apache/2.4.41 (Unix)Server built: Dec 13 2019 19:06:00 查看ab版本1234$ ab -VThis is ApacheBench, Version 2.3 &lt;$Revision: 1843412 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/ 查看当前系统的默认文件打开数在压测开始前，你需要确保你的open files足够大，否则会报TOO MANY FILES OPEN错误，可以通过ulimit -a查看 123456789101112$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedfile size (blocks, -f) unlimitedmax locked memory (kbytes, -l) unlimitedmax memory size (kbytes, -m) unlimitedopen files (-n) 256pipe size (512 bytes, -p) 1stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 1392virtual memory (kbytes, -v) unlimited 设置打开文件数限制为 2560： 1ulimit -n 2560 这只是临时修改，关闭终端会话后会复原。 命令 命令参数 说明 -n 请求次数 -c 并发数 -r 当接收到错误时，不要退出套接字（socket） 关于登陆的问题有时候进行压力测试需要用户登录，怎么办？请参考以下步骤： 先用账户和密码登录后，用开发者工具找到标识这个会话的 Cookie 值（Session ID）记下来 如果只用到一个 Cookie，那么只需键入命令：ab －n 100 －C key＝value http://test.com/ 如果需要多个 Cookie，就直接设 Header：ab -n 100 -H “Cookie: Key1=Value1; Key2=Value2” http://test.com/ webbenchwebbench是一枚强大得可以的压力测试工具，它最多可以模拟3万个并发连接去测试网站的负载能力，个人感觉要比Apache自带的ab压力测试工具好，安装使用也特别方便。 安装123456789brew install ctags # 依赖安装wget http://blog.zyan.cc/soft/linux/webbench/webbench-1.5.tar.gztar -zxvf webbench-1.5.tar.gzcd webbench-1.5mkdir -pv /usr/local/man/man1 # 必须sudo make &amp;&amp; sudo make install 命令12# 10 秒内向 http://127.0.0.1:3001/admin 发送 500 次请求webbench -c 500 -t 10 http://127.0.0.1:3001/admin siegesiege是我解决ab该死的apr_socket_recv: Connection reset by peer (54)错误时发现的一个好工具，不得不说这工具真心好，用法和webbench一样，但是信息全面很多。 安装1brew install siege 命令 压测参数 说明 -C 在屏幕上打印显示出当前的配置,配置是包括在他的配置文件$HOME/.siegerc中,可以编辑里面的参数,这样每次siege 都会按照它运行 -v 运行时能看到详细的运行信息 -c 模拟有n个用户在同时访问,n不要设得太大,因为越大,siege消耗本地机器的资源越多 -r 重复运行测试n次,不能与-t同时存在 -t 持续运行siege ‘n’秒(如10S),分钟(10M),小时(10H) -d 每个url之间的延迟,在0-n之间 -b 请求无需等待 delay=0 -i 随机访问urls.txt中的url列表项 -f 指定用特定的urls文件运行 ,默认为urls.txt,位于siege安装目录下的etc/urls.txt -R 指定用特定的siege 配置文件来运行,默认的为$HOME/.siegerc -l 运行结束,将统计数据保存到日志文件中siege.log,一般位于/usr/local/var/siege.log中,也可在.siegerc中自定义 压测结果123456789101112131415//并发10个,发生5次,共50个请求siege -c 10 -r 5 http://www.jd.comTransactions: 350 hits //总共测试次数Availability: 100.00 % //成功次数百分比Elapsed time: 4.27 secs //总共耗时多少秒Data transferred: 7.08 MB //总共数据传输Response time: 0.07 secs //等到响应耗时Transaction rate: 81.97 trans/sec //平均每秒处理请求数Throughput: 1.66 MB/sec //吞吐率Concurrency: 6.06 //最高并发Successful transactions: 350 //成功的请求数Failed transactions: 0 //失败的请求数Longest transaction: 0.24 //每次传输所花最长时间Shortest transaction: 0.01 //每次传输所花最短时间 常用命令1234567891011121314# 200个并发对http://www.google.com发送请求100次siege -c 200 -r 100 http://www.google.com# 在urls.txt中列出所有的网址siege -c 200 -r 100 -f urls.txt# 随机选取urls.txt中列出所有的网址siege -c 200 -r 100 -f urls.txt -i# delay=0，更准确的压力测试，而不是功能测试siege -c 200 -r 100 -f urls.txt -i -b# 指定http请求头 文档类型siege -H &quot;Content-Type:application/json&quot; -c 200 -r 100 -f urls.txt -i -b 注意事项 发送post请求时，url格式为http://www.xxxx.com/ POST p1=v1&amp;p2=v2 如果url中含有空格和中文，要先进行url编码，否则siege发送的请求url不准确。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome 80+版本，samesite cookie验证跨域问题]]></title>
    <url>%2F2020%2F03%2F20%2Fchrome-samesite-cookie%2F</url>
    <content type="text"><![CDATA[起因网站登录时，本地前端代码请求线上后台不能正常登录，检查跨域不存在问题；且网站线上登录正常，其他人本地登录也正常。 检查 console中发现： 1A cookie associated with a cross-site resource at http://192.168.5.23/ was set without the `SameSite` attribute. A future release of Chrome will only deliver cookies with cross-site requests if they are set with `SameSite=None` and `Secure`. You can review cookies in developer tools under Application&gt;Storage&gt;Cookies and see more details at https://www.chromestatus.com/feature/5088147346030592 and https://www.chromestatus.com/feature/5633521622188032. network请求中，Set-Cookie中发现黄色感叹号，提示： 1this set-cookie didn&apos;t specify a &quot;SameSite&quot; attribute ...... 原因Chrome 80 版本升级后，提升了Cookie SameSite的默认安全等级，强推SameSite Cookie chrome版本 默认值 cookie &lt;80 SameSite=None 请求带Cookie &gt;=80 SameSite=Lax 请求限制带Cookie 什么是SameSiteSameSite 是 Chrome 51 版本为浏览器的 Cookie 新增的了一个属性， SameSite 阻止浏览器将此 Cookie 与跨站点请求一起发送。其主要目标是降低跨源信息泄漏的风险。同时也在一定程度上阻止了 CSRF（Cross-site request forgery 跨站请求伪造）。 Cookie 的SameSite属性用来限制第三方 Cookie，从而减少安全风险。 它可以设置三个值： Strict Lax None StrictStrict最为严格，完全禁止第三方 Cookie，跨站点时，任何情况下都不会发送 Cookie。换言之，只有当前网页的 URL 与请求目标一致，才会带上 Cookie。 1Set-Cookie: username=xxxxx; SameSite=Strict; LaxLax规则稍稍放宽，大多数情况也是不发送第三方 Cookie，但是导航到目标网址的 Get 请求除外。 1Set-Cookie: username=xxxxx; SameSite=Lax; 设置了Strict或Lax以后，基本就杜绝了 CSRF 攻击。当然，前提是用户浏览器支持 SameSite 属性。 None网站可以选择显式关闭SameSite属性，将其设为None。不过，前提是必须同时设置Secure属性（Cookie 只能通过 HTTPS 协议发送），否则无效。下面的设置无效： 1Set-Cookie: widget_session=xxxxx; SameSite=None 下面的设置有效： 1Set-Cookie: widget_session=xxxxx; SameSite=None; Secure 本地调试解决办法将如下两项设置为Disabled，并重启浏览器： chrome://flags/#same-site-by-default-cookies chrome://flags/#cookies-without-same-site-must-be-secure]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>chrome</tag>
        <tag>cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vps 搭建ss]]></title>
    <url>%2F2020%2F03%2F12%2Fvps-shadowsocks%2F</url>
    <content type="text"><![CDATA[购买vps首先购买一台境外的vps服务器，搬瓦工、vultr等都还可以。 搭建ssssh连接服务器之后： 1yum install wget 下载shadowsocks: 1wget –no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh 获取shadowsocks.sh权限： 1chmod +x shadowsocks.sh 执行安装shadowsocks： 1./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 之后按照提示输入 密码、端口号，选择加密方式aes-256-cfb，等待完成安装即可。 使用Google BBR加速上网下载： 1wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh 获取读写权限： 1chmod +x bbr.sh 安装: 1./bbr.sh 接着按任意键，开始安装，坐等一会。安装完成一会之后它会提示我们是否重新启动vps，我们输入 y 确定重启服务器。 重新启动之后，输入 lsmod | grep bbr 如果看到 tcp_bbr 就说明 BBR 已经启动了。 ps:貌似shadowsocks.sh已经安装了BBR，不用单独安装BBR了。 相关命令1234567启动：/etc/init.d/shadowsocks start停止：/etc/init.d/shadowsocks stop重启：/etc/init.d/shadowsocks restart状态：/etc/init.d/shadowsocks status配置文件路径：/etc/shadowsocks.json日志文件路径：/var/log/shadowsocks.log安装路径：/usr/local/shadowsocks/shadowsoks]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>GFW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MQTT简介]]></title>
    <url>%2F2020%2F03%2F12%2Fmqtt-introduction%2F</url>
    <content type="text"><![CDATA[简述MQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议），是一个基于客户端-服务器的消息发布/订阅传输协议。 安装检查epel源 12345## 如下已存在epel源，则不需要安装➜ yum repolist | grep epel## 如果不存在，则需要安装 epel➜ yum -y install epel-release 安装 Mac：brew install mosquitto CentOS：yum install mosquitto 启动mosquitto12345678910## 启动➜ systemctl start mosquitto## 停止➜ systemctl stop mosquitto## 重新启动➜ systemctl restart mosquitto## 查看运行状态 ➜ systemctl status mosquitto## 设为开机启动➜ systemctl enable mosquitto 设置账号密码 1234567## username1 为你的用户名➜ mosquitto_passwd -c /etc/mosquitto/passwd username1## 输入密码，确认密码## 如果要添加多个用户使用 -b 参数 ## 必须在控制台输入明文的密码，且文件不会覆盖之前的➜ mosquitto_passwd -b /etc/mosquitto/passwd username2 password2 备份配置文件 12cd /etc/mosquitto/cp mosquitto.conf mosquitto.conf.bak 修改配置文件 123456# 禁止匿名访问allow_anonymous false# 用户及密码存储文件password_file /etc/mosquitto/passwd# 端口号port 1883 重启MQTT TIPS: 防火墙状态：firewall-cmd --state 防火墙停止：systemctl stop firewalld.service 查看防火墙zone：firewall-cmd --get-active-zones 防火墙永久开放端口：firewall-cmd --zone=public --add-port=1888/tcp --permanent 防火墙重启：firewall-cmd --reload 查看所有打开的端口：firewall-cmd --zone=public --list-ports iptables状态：systemctl status iptables iptables影响mqtt远程连接，直接关闭了：systemctl stop iptables 订阅主题123456[root@c7-ehotel-liudf-201 ~]# mosquitto_sub -d -h 192.168.5.201 -p 1883 -u tcl -P tcl801 -t tv/marquee/0440001/103/520012518815Client mosqsub|30292-c7-ehotel sending CONNECTClient mosqsub|30292-c7-ehotel received CONNACKClient mosqsub|30292-c7-ehotel sending SUBSCRIBE (Mid: 1, Topic: tv/marquee/0440001/103/520012518815, QoS: 0)Client mosqsub|30292-c7-ehotel received SUBACKSubscribed (mid: 1): 0 解析： -d: debug模式，输出详细的连接以及数据收发过程 -h: host -p: port 端口 -u: user 用户名 -P: possword 密码 -t: topic 订阅主题 sending SUBSCRIBE (Mid: 1, Topic: tv/marquee/0440001/103/520012518815, QoS: 0)表示发送订阅请求: Mid是Message Id，从1开始计算，当一个连接发送多条消息时，Mid是递增的。 Topic 表示要订阅的主题时topic1。 QoS：0指定了QoS等级，默认是0。 发布消息12345$ mosquitto_pub -d -h 192.168.5.201 -p 1883 -u tcl -P tcl801 -t tv/0440001/marquee -m &quot;Hello MQTT&quot;Client mosqpub|12796-SCNWCL012 sending CONNECTClient mosqpub|12796-SCNWCL012 received CONNACK (0)Client mosqpub|12796-SCNWCL012 sending PUBLISH (d0, q0, r0, m1, &apos;tv/0440001/marquee&apos;, ... (10 bytes))Client mosqpub|12796-SCNWCL012 sending DISCONNECT 解析： -m 发送消息的内容 d0表示DUP为0，DUP是是否重复标记，如果是第一次发送消息，则设置为0。如果是重复投递，比如QoS设置为1，客户端发送消息超时后服务器还没有回复，客户端为确保消息能发出去，于是再发一次，这是DUP就设置为1，表明这个消息是重复发送的。 q0表示QoS为0。 r0表示RETAIN为0。RETAIN意思是是否要求Broker帮我保留这条消息，如果设置为1，则服务器会保留当前消息。当下一次有新的客户端连接并订阅topic1时，服务器自动发送这条保留的消息给客户端。 m1表示消息序号，默认从1开始。 接收消息发布完消息后，再回到之前订阅的终端，会显示接收到的消息。 12Client mosqsub|30443-c7-ehotel received PUBLISH (d0, q0, r0, m0, &apos;tv/0440001/marquee&apos;, ... (10 bytes))Hello MQTT 第一行显示收到PUBLISH数据包，第二行打印出接收到的数据。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>mqtt</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[控制反转 和 依赖注入]]></title>
    <url>%2F2020%2F03%2F12%2Fioc-and-di%2F</url>
    <content type="text"><![CDATA[概念控制反转（IOC Inversion Of Control）：是一种思想，是一种是面向对象编程中的一种设计原则，用来减低计算机代码之间的耦合度。其基本思想是：借助于“第三方”实现具有依赖关系的对象之间的解耦。我们一般称这个“第三方”为IOC容器 依赖注入（DI Dependency Injection）：是控制反转最典型的实现方式。 原理示例如果一个类A 的功能实现需要借助于类B，那么就称类B是类A的依赖，如果在类A的内部去实例化类B，那么两者之间会出现较高的耦合，一旦类B出现了问题，类A也需要进行改造，如果这样的情况较多，每个类之间都有很多依赖，那么就会出现牵一发而动全身的情况，程序会极难维护，并且很容易出现问题。要解决这个问题，就要把A类对B类的控制权抽离出来，交给一个第三方去做，把控制权反转给第三方，就称作控制反转（IOC Inversion Of Control）。控制反转是一种思想，是能够解决问题的一种可能的结果，而依赖注入（Dependency Injection）就是其最典型的实现方法。由第三方（我们称作IOC容器）来控制依赖，把他通过构造函数、属性或者工厂模式等方法，注入到类A内，这样就极大程度的对类A和类B进行了解耦。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[v2ray + CDN + Nginx 拯救被墙IP]]></title>
    <url>%2F2020%2F03%2F12%2Fv2ray-cdn-nginx-GFW%2F</url>
    <content type="text"><![CDATA[由于GFW的原因，IP被封，所以只能另辟蹊径： v2ray是一个集成了各种科学上网协议的软件，包括socks（目前接触到的是本机到本机）、http、SS（目前接触到的是本机到远程）、vmess等，传输载体可以是tcp、mkcp、websocket等 使用websocket：因为cdn可以转发ws流量 使用https（tls）伪装网站，请求流量数据 使用cdn转发流量，同时作为连接vps的跳板，使vps复活和隐藏 使用nginx代理v2ray 准备工作 一台vps (IP被墙，IP假设为：99.99.99.99) 域名：www.xyz.com 免费cdn：cloudfare 相关知识：nginx配置，ssl配置，域名配置等 安装nginx添加yum源： 1rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装： 1yum install nginx 相关服务命令： 1234567891011设置开机启动systemctl enable nginx 启动服务systemctl start nginx重启服务systemctl restart nginx重载服务systemctl reload nginx 编辑配置文件：相关配置文件位置/etc/nginx/下，替换server_name为 1xyz.com www.xyz.com; 然后启动nginx服务。 申请证书申请免费https证书（Let’s Encrypt），先在域名注册商那里（GoDaddy）修改dns，添加两个a记录，解析到vps的ip 99.99.99.99，修改的原因是要向let‘s encrypt要发起挑战，证明你拥有这个域名。下载certbot： 12git clone https://github.com/certbot/certbotcd certbot 生成免费证书： 123./certbot-auto certonly --webroot --agree-tos -v -t --email 邮箱地址 -w 网站根目录 -d 网站域名例如：./certbot-auto certonly --webroot --agree-tos -v -t --email liwen@163.com -w /usr/share/nginx/html -d www.xyz.com 注：生成过程中会自动生成 /网站根目录/.well0known/acme-challenge，然后脚本会挑战这个路径，所以需要保证这个地址能被访问，才能正常生成免费的证书。为了保证能访问，需要开启nginx，同时，需要关闭dns（箭头不穿过小云朵）。 生成的证书地址： 12/etc/letsencrypt/live/www.xyz.com/fullchain.pem......等等 配置nginx证书： 12345listen 443ssl on;ssl_certificate /etc/letsencrypt/live/网站域名/fullchain.pem;ssl_certificate_key /etc/letsencrypt/live/网站域名/privkey.pem; cdn设置设置完证书后，就可以设置cdn 注册cloudfare账号，选择一个免费站点 更换godaddy处的nameserver为cloudfare的nameserver，把解析工作转移给cloudfare 等待cloudfare网站变为active状态 安装v2rayvps安装配置v2ray 安装v2ray： 123# 官方一键安装脚本bash &lt;(curl -l -s https://install.direct/go.sh)安装好后，会有v2ray运行的端口，和一个client的uuid port:26075 uuid:563a2749-ccfe-4754-959d-b8343faafeac （记住上述信息，并使用实际的更换） 编辑配置文件： 1vi /etc/v2ray/config.json 在inbound的最后（settings之后）追加如下配置，记住path路径： 12345678&quot;listen&quot;: &quot;0.0.0.0&quot;,&quot;streamsettings&quot;: &#123; &quot;network&quot;: &quot;ws&quot;, &quot;wssettings&quot;: &#123; &quot;path&quot;: &quot;/gotowork&quot; &#125;&#125; 重启v2ray： 1systemctl restart v2ray 继续设置nginx：继续设置nginx，反向代理到v2ray 编辑nginx配置文件 123456789# 添加类似如下设置location /gotowork &#123; # 路径为上面的路径proxy_redirect off;proxy_pass http://127.0.0.1:26075; # 端口要变成v2ray运行的端口proxy_http_version 1.1;proxy_set_header upgrade $http_upgrade;proxy_set_header connection &quot;upgrade&quot;;proxy_set_header host $http_host;&#125; 重启nginx： 1systemctl restart nginx 客户端配置macos客户端选择v2rayx:https://github.com/cenmrev/v2rayx最终配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116&#123; &quot;routing&quot;: &#123; &quot;name&quot;: &quot;all_to_main&quot;, &quot;domainStrategy&quot;: &quot;AsIs&quot;, &quot;rules&quot;: [ &#123; &quot;type&quot;: &quot;field&quot;, &quot;outboundTag&quot;: &quot;cdnv2ray&quot;, &quot;port&quot;: &quot;0-65535&quot; &#125; ] &#125;, &quot;inbounds&quot;: [ &#123; &quot;listen&quot;: &quot;127.0.0.1&quot;, &quot;protocol&quot;: &quot;socks&quot;, &quot;settings&quot;: &#123; &quot;ip&quot;: &quot;127.0.0.1&quot;, &quot;auth&quot;: &quot;noauth&quot;, &quot;udp&quot;: true &#125;, &quot;tag&quot;: &quot;socksinbound&quot;, &quot;port&quot;: 1081 &#125;, &#123; &quot;listen&quot;: &quot;127.0.0.1&quot;, &quot;protocol&quot;: &quot;http&quot;, &quot;settings&quot;: &#123; &quot;timeout&quot;: 0 &#125;, &quot;tag&quot;: &quot;httpinbound&quot;, &quot;port&quot;: 8001 &#125; ], &quot;dns&quot;: &#123; &quot;servers&quot;: [ &quot;8.8.8.8&quot;, &quot;8.8.4.4&quot; ] &#125;, &quot;log&quot;: &#123; &quot;error&quot;: &quot;/var/folders/95/q73tyvts04s_g3pddf07tfjw0000gn/T/cenmrev.v2rayx.log/error.log&quot;, &quot;loglevel&quot;: &quot;warning&quot;, &quot;access&quot;: &quot;/var/folders/95/q73tyvts04s_g3pddf07tfjw0000gn/T/cenmrev.v2rayx.log/access.log&quot; &#125;, &quot;outbounds&quot;: [ &#123; &quot;sendThrough&quot;: &quot;0.0.0.0&quot;, &quot;mux&quot;: &#123; &quot;enabled&quot;: false, &quot;concurrency&quot;: 8 &#125;, &quot;protocol&quot;: &quot;vmess&quot;, &quot;settings&quot;: &#123; &quot;vnext&quot;: [ &#123; &quot;address&quot;: &quot;www.xyz.com&quot;, # 注意 &quot;users&quot;: [ &#123; &quot;id&quot;: &quot;e4sdf75b-349b-43c6-hj98-9228f5fdfdsf3&quot;, # 注意 &quot;alterId&quot;: 64, &quot;security&quot;: &quot;auto&quot;, &quot;level&quot;: 1 &#125; ], &quot;port&quot;: 443 &#125; ] &#125;, &quot;tag&quot;: &quot;cdnv2ray&quot;, &quot;streamSettings&quot;: &#123; &quot;wsSettings&quot;: &#123; &quot;path&quot;: &quot;/gotowork&quot;, # 注意 &quot;headers&quot;: &#123;&#125; &#125;, &quot;quicSettings&quot;: &#123; &quot;key&quot;: &quot;&quot;, &quot;security&quot;: &quot;none&quot;, &quot;header&quot;: &#123; &quot;type&quot;: &quot;none&quot; &#125; &#125;, &quot;tlsSettings&quot;: &#123; &quot;allowInsecure&quot;: false, &quot;alpn&quot;: [ &quot;http/1.1&quot; ], &quot;serverName&quot;: &quot;www.xyz.com&quot;, # 注意 &quot;allowInsecureCiphers&quot;: false &#125;, &quot;httpSettings&quot;: &#123; &quot;path&quot;: &quot;&quot; &#125;, &quot;kcpSettings&quot;: &#123; &quot;header&quot;: &#123; &quot;type&quot;: &quot;none&quot; &#125;, &quot;mtu&quot;: 1350, &quot;congestion&quot;: false, &quot;tti&quot;: 20, &quot;uplinkCapacity&quot;: 5, &quot;writeBufferSize&quot;: 1, &quot;readBufferSize&quot;: 1, &quot;downlinkCapacity&quot;: 20 &#125;, &quot;tcpSettings&quot;: &#123; &quot;header&quot;: &#123; &quot;type&quot;: &quot;none&quot; &#125; &#125;, &quot;security&quot;: &quot;tls&quot;, # 注意 &quot;network&quot;: &quot;ws&quot; # 注意 &#125; &#125; ]&#125; 相关链接https://blog.sprov.xyz/2019/03/11/cdn-v2ray-safe-proxy/#i-9https://www.dazhuanlan.com/2019/10/04/5d962810eb6c8/]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>v2ray</tag>
        <tag>GFW</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阻塞和非阻塞，同步和异步，并发和并行]]></title>
    <url>%2F2020%2F03%2F12%2Fio-concurrency-block%2F</url>
    <content type="text"><![CDATA[阻塞和非阻塞阻塞和非阻塞，是针对用户进程（线程）的转态来说的。 阻塞意味着用户进程（线程）被挂起，即让出CPU时间片，一直等待内核把数据准备好。 非阻塞意味着用户进程(线程)不会挂起，用户进程可以不断地主动去看数据是否准备好，仍可以占用CPU时间片执行其他工作。 阻塞IO和非阻塞IO，都是同步IO；都是用户进程（线程）从内核中把数据取走。 同步和异步同步和异步，是针对指令的执行顺序来说的。 同步意味着发起调用后，没有得到结果之前，就不返回，自然也不能执行其他指令。 异步意味着调用发出后，调用方立刻返回，通过回调等措施拿到结果，这样调用方还可以执行其他指令。 同步和异步、阻塞和非阻塞，是针对不同主体而言的。 并发和并行并发和并行是两个非常容易混淆的概念。它们都可以表示两个或多个任务一起执行，但是偏重点有点不同。并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的。并发是逻辑上的同时发生（simultaneous），而并行是物理上的同时发生。然而并行的偏重点在于”同时执行”。 并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。就好像两个人各拿一把铁锨在挖坑，一小时后，每人一个大坑。所以无论从微观还是从宏观来看，二者都是一起执行的。 并发(concurrency)：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。这就好像两个人用同一把铁锨，轮流挖坑，一小时后，两个人各挖一个小一点的坑，要想挖两个大一点得坑，一定会用两个小时。 严格意义上来说，并行的多个任务是真实的同时执行，而对于并发来说，这个过程只是交替的，一会运行任务一,一会儿又运行任务二，系统会不停地在两者间切换。但对于外部观察者来说，即使多个任务是串行并发的，也会造成是多个任务并行执行的错觉。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker内部访问宿主机]]></title>
    <url>%2F2020%2F03%2F12%2Fdocker-commit-out-host%2F</url>
    <content type="text"><![CDATA[有时候需要在docker容器里访问宿主机提供的某些服务。如：容器里的应用需要访问宿主机的MySQL服务。 方法介绍1Use your internal IP address or connect to the special DNS name host.docker.internal which will resolve to the internal IP address used by the host. 方法1：宿主机执行ifconfig，找到docker0网卡对应的IP，可以使用这个IP来访问宿主机。 方法2：docker 18.03加入了一个feature，在容器中可以通过 host.docker.internal来访问主机。 Docker For Mac没有docker0网桥的问题在使用 Docker 时，要注意平台之间实现的差异性，如 Docker For Mac 的实现和标准 Docker 规范有区别，Docker For Mac 的 Docker Daemon 是运行于虚拟机 (xhyve) 中的，而不是像 Linux 上那样作为进程运行于宿主机，因此 Docker For Mac 没有 docker0 网桥，不能实现 host 网络模式，host 模式会使 Container 复用 Daemon 的网络栈 (在 xhyve 虚拟机中)，而不是与 Host &gt;主机网络栈，这样虽然其它容器仍然可通过 xhyve 网络栈进行交互，但却不是用的 Host 上的端口 (在 Host 上无法访问)。bridge 网络模式 -p 参数不受此影响，它能正常打开 Host 上的端口并映射到 Container 的对应 Port。文档在这一点上并没有充分说&gt;明，容易踩坑。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CGI、FastCGI和PHP-FPM]]></title>
    <url>%2F2020%2F01%2F19%2Fphp-base-knowledge%2F</url>
    <content type="text"><![CDATA[基础知识静态请求在整个网站架构中，Web Server（如Apache）只是内容的分发者。举个栗子，如果客户端请求的是 index.html，那么Web Server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。 动态请求如果请求的是 index.php，根据配置文件，Web Server知道这个不是静态文件，需要去找 PHP 解析器来处理，那么他会把这个请求简单处理，然后交给PHP解析器。 当Web Server收到 index.php 这个请求后，会启动对应的 CGI 程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程，Web server再把结果返回给浏览器。这就是一个完整的动态PHP Web访问流程。 接下来再引出这些概念，就好理解多了： CGI：是 Web Server 与 Web Application 之间数据交换的一种协议。 FastCGI：同 CGI，是一种通信协议，但比 CGI 在效率上做了一些优化。同样，SCGI 协议与 FastCGI 类似。 PHP-CGI：是 PHP （Web Application）对 Web Server 提供的 CGI 协议的接口程序。 PHP-FPM：是 PHP（Web Application）对 Web Server 提供的 FastCGI 协议的接口程序，额外还提供了相对智能一些任务管理。 Web Server：一般指Apache、Nginx、IIS、Lighttpd、Tomcat等服务器，Web Application 一般指PHP、Java、Asp.net等应用程序。 交互方式Module方式在了解 CGI 之前，我们先了解一下Web server 传递数据的另外一种方法：PHP Module加载方式。以 Apache 为例，在PHP Module方式中，是不是在 Apache 的配置文件 httpd.conf 中加上这样几句： 1234567# 加入以下2句LoadModule php5_module D:/php/php5apache2_2.dllAddType application/x-httpd-php .php# 修改如下内容&lt;IfModule dir_module&gt; DirectoryIndex index.php index.html&lt;/IfModule&gt; 上面是 Windows 下安装php和apache环境后手动配置，在linux下源码安装大致是这样配置的： 1# ./configure --with-mysql=/usr/local --with-apache=/usr/local/apache --enable-track-vars 所以，这种方式，他们的共同本质都是用 LoadModule 来加载 php5_module，就是把php作为apache的一个子模块来运行。当通过web访问php文件时，apache就会调用php5_module来解析php代码。 那么php5_module是怎么来将数据传给php解析器来解析php代码的呢？答案是通过sapi。 我们再来看一张图，详细的说说apache 与 php 与 sapi的关系： 从上面图中，我们看出了sapi就是这样的一个中间过程，SAPI提供了一个和外部通信的接口，有点类似于socket，使得PHP可以和其他应用进行交互数据（apache，nginx等）。php默认提供了很多种SAPI，常见的提供给apache和nginx的php5_module、CGI、FastCGI，给IIS的ISAPI，以及Shell的CLI。 所以，以上的apache调用php执行的过程如下： 1apache -&gt; httpd -&gt; php5_module -&gt; sapi -&gt; php 好了。apache与php通过php5_module的方式就搞清楚了吧！ 这种模式将php模块安装到apache中，所以每一次apache结束请求，都会产生一条进程，这个进程就完整的包括php的各种运算计算等操作。在上图中，我们很清晰的可以看到，apache每接收一个请求，都会产生一个进程来连接php通过sapi来完成请求，可想而知，如果一旦用户过多，并发数过多，服务器就会承受不住了。 而且，把mod_php编进apache时，出问题时很难定位是php的问题还是apache的问题。 CGICGI（Common Gateway Interface）全称是“通用网关接口”，WEB 服务器与PHP应用进行“交谈”的一种工具，其程序须运行在网络服务器上。CGI可以用任何一种语言编写，只要这种语言具有标准输入、输出和环境变量。如php、perl、tcl等。 WEB服务器会传哪些数据给PHP解析器呢？URL、查询字符串、POST数据、HTTP header都会有。所以，CGI就是规定要传哪些数据，以什么样的格式传递给后方处理这个请求的协议。仔细想想，你在PHP代码中使用的用户从哪里来的。 也就是说，CGI就是专门用来和 web 服务器打交道的。web服务器收到用户请求，就会把请求提交给cgi程序（如php-cgi），cgi程序根据请求提交的参数作应处理（解析php），然后输出标准的html语句，返回给web服服务器，WEB服务器再返回给客户端，这就是普通cgi的工作原理。 CGI的好处就是完全独立于任何服务器，仅仅是做为中间分子。提供接口给apache和php。他们通过cgi搭线来完成数据传递。这样做的好处了尽量减少2个的关联，使他们2变得更独立。 但是CGI有个蛋疼的地方，就是每一次web请求都会有启动和退出过程，也就是最为人诟病的fork-and-execute模式，这样一在大规模并发下，就死翘翘了。 FastCGI从根本上来说，FastCGI是用来提高CGI程序性能的。类似于CGI，FastCGI也可以说是一种协议。 FastCGI像是一个常驻(long-live)型的CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次。它还支持分布式的运算, 即 FastCGI 程序可以在网站服务器以外的主机上执行，并且接受来自其它网站服务器来的请求。 FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求，或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。Web Server启动时载入FastCGI进程管理器（Apache Module或IIS ISAPI等) FastCGI进程管理器自身初始化，启动多个CGI解释器进程(可建多个php-cgi)，并等待来自Web Server的连接。 当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。 FastCGI子进程完成处理后，将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待，并处理来自FastCGI进程管理器(运行在Web Server中)的下一个连接。在CGI模式中，php-cgi在此便退出了。 PHP-FPM介绍要了解PHP-FPM，就得先说说PHP-CGI。PHP-CGI就是PHP实现的自带的FastCGI管理器。虽然是php官方出品，但是这丫的却一点也不给力，性能太差，而且也很麻烦不人性化，主要体现在： php-cgi变更php.ini配置后，需重启php-cgi才能让新的php-ini生效，不可以平滑重启。 直接杀死php-cgi进程，php就不能运行了。 上面2个问题，一直让很多人病垢了很久，所以很多人一直还是在用 Module 方式。直到 2004年一个叫 Andrei Nigmatulin的屌丝发明了PHP-FPM ，这神器的出现就彻底打破了这种局面，这是一个PHP专用的 fastcgi 管理器，它很爽的克服了上面2个问题，而且，还表现在其他方面更表现强劲。 也就是说，PHP-FPM 是对于 FastCGI 协议的具体实现，他负责管理一个进程池，来处理来自Web服务器的请求。目前，PHP5.3版本之后，PHP-FPM是内置于PHP的。 因为PHP-CGI只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理。所以就出现了一些能够调度 php-cgi 进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。同样，PHP-FPM也是用于调度管理PHP解析器php-cgi的管理程序。 PHP-FPM通过生成新的子进程可以实现php.ini修改后的平滑重启。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>php-fpm</tag>
        <tag>fast-cgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL各存储引擎]]></title>
    <url>%2F2020%2F01%2F19%2Fmysql-engines%2F</url>
    <content type="text"><![CDATA[查看MySQL支持的引擎：1mysql&gt; show engines; MyISAM存储引擎 提供高速存储和检索，以及全文搜索能力 不支持事物。表级锁。不能再表损坏后恢复数据 适合查询频繁的情况 InnoDB 具有提交、回滚和崩溃恢复能力的事务安全（ACID兼容）存储引擎。 基于聚簇索引建立，聚簇索引对主键查询有很高的性能。 支持事务和外键。行级锁。 适合在以下几种情况下使用： 1.更新和查询都相当的频繁，多重并发2.要求事务，或者可靠性要求比较高3.外键约束，MySQL支持外键的存储引擎只有InnoDB 一般来说，如果需要事务支持，并且有较高的并发读取频率，InnoDB是不错的选择 MEMORY（HEAP）引擎 数据保存在内存中，拥有极高的插入、更新和查询效率。但是不稳定，重启以后数据都会丢失。 不支持事务。支持表级锁，因此并发写入的性能较低。 支持长度不变的数据类型，不支持BLOB或TEXT长度可变的数据类型。 支持HASH索引和B-Tree索引，擎默认使用HASH索引。 在内存中存放数据，所以会造成内存的使用，可以通过参数max_heap_table_size控制MEMORY表的大小。 ARCHIVE引擎 拥有很好的压缩机制，它使用zlib压缩库，在记录被请求时会实时压缩。 支持最基本的插入和查询两种功能。在MySQL 5.5开始支持索引。 不支持事务。支持行级锁和专用的缓存区，所以可以实现高并发的插入。 适合存储大量日志、历史数据 BLACKHOLE引擎 接受但不存储数据，但是如果MySQL启用了二进制日志，SQL语句被写入日志（并被复制到从服务器）。 用于做日志记录或同步归档的中继存储。但这种应用方式会碰到很多问题，因此并不推荐。 支持事务，而且支持mvcc的行级锁。 CSV引擎 每个表会生成一个.CSV文件，将CSV类型的文件当做表进行处理。 把数据以逗号分隔的格式存储在文本文件中，这种文件是一种普通文本文件，每个数据行占用一个文本行。 不支持索引，即使用该种类型的表没有主键列，也不允许表中的字段为null。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laradock 搭建 swoole + nginx 环境]]></title>
    <url>%2F2020%2F01%2F19%2Flaradock-swoole%2F</url>
    <content type="text"><![CDATA[安装docker和docker-compose相关安装步骤在此不再赘述，参考之前的笔记：laradock搭建php环境。 安装配置laravel-s简介：LaravelS是一个胶水项目，用于快速集成Swoole到Laravel或Lumen，然后赋予它们更好的性能、更多可能性。项目地址：https://github.com/hhxsv5/laravel-s 相关安装要求请移步项目地址查看。 安装 通过composer安装 1composer require &quot;hhxsv5/laravel-s:~3.6.0&quot; -vvv 注册ServiceProviderLaravel: 修改文件config/app.php，Laravel 5.5+支持包自动发现，你应该跳过这步 1234&apos;providers&apos; =&gt; [ //... Hhxsv5\LaravelS\Illuminate\LaravelSServiceProvider::class,], 发布配置和二进制文件 每次升级LaravelS后，需重新publish。 123php artisan laravels publish# 配置文件：config/laravels.php# 二进制文件：bin/laravels; bin/fswatch; bin/inotify 修改配置config/laravels.php：监听的IP、端口等，请参考配置项。 相关运行命令介绍操作命令： 1php bin/laravels &#123;start|stop|restart|reload|info|help&#125; 命令 说明 start 启动LaravelS，展示已启动的进程列表 `ps -ef stop 停止LaravelS restart 重启LaravelS，支持选项 `-d reload 平滑重启所有Task/Worker/Timer进程(这些进程内包含了你的业务代码)，并触发自定义进程的onReload方法，不会重启Master/Manger进程；修改config/laravels.php后，你只能调用restart来实现重启 info 显示组件的版本信息 help 显示帮助信息 安装配置laradocklaradock采用多项目配置，让laradock和项目在同级目录，需要配置hosts。 拉取laradock至代码同级目录1git clone https://github.com/laradock/laradock.git like this: 123+ laradock+ project-1+ project-2 复制env-example 为 .env1cp env-example .env 配置修改.env12345678910111213141516171819202122232425262728293031323334# 修改docker源为aliyun# If you need to change the sources (i.e. to China), set CHANGE_SOURCE to trueCHANGE_SOURCE=true# 修改composer源WORKSPACE_COMPOSER_REPO_PACKAGIST=https://packagist.phpcomposer.com# 修改node镜像地址WORKSPACE_NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node# 修改npm源WORKSPACE_NPM_REGISTRY=https://registry.npm.taobao.org# 不下载yarn，因为墙的原因，下载超时，yarn和npm一样。WORKSPACE_INSTALL_YARN=false# php-fpm 安装swooleWORKSPACE_INSTALL_SWOOLE=true# 修改时区WORKSPACE_TIMEZONE=Asia/Shanghai# cli 安装swoole的PHP扩展PHP_FPM_INSTALL_SWOOLE=true# php-worker 安装swoole，supervisor守护进程在php-worker中，需要swoolePHP_WORKER_INSTALL_SWOOLE=true# 修改MySQL的版本为5.7，减少麻烦，并配置数据库相关配置，并同步配置到项目.env中MYSQL_VERSION=5.7MYSQL_DATABASE=xxxxxMYSQL_USER=laravelsMYSQL_PASSWORD=xxxxxMYSQL_PORT=3306MYSQL_ROOT_PASSWORD=xxxxxx 配置redis参考：laradock搭建php环境 配置nginx在/xxx/www/laradock/nginx/sites中新建xxx.conf文件： 1234567891011121314151617181920212223242526272829303132upstream laravels &#123; # Connect IP:Port server php-worker:5200 weight=5 max_fails=3 fail_timeout=30s; keepalive 16;&#125;server &#123; listen 80; server_name laravels.com; root /var/www/laravue/public; index index.php index.html index.htm; # Nginx 处理静态资源，LaravelS 处理动态资源 location / &#123; try_files $uri @laravels; &#125; location @laravels &#123; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-PORT $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header Scheme $scheme; proxy_set_header Server-Protocol $server_protocol; proxy_set_header Server-Name $server_name; proxy_set_header Server-Addr $server_addr; proxy_set_header Server-Port $server_port; proxy_pass http://laravels; &#125;&#125; ps: php-worker:5200 是因为LaravelS的进程守护是在php-worker中，并监听5200端口。 配置php-worker在php-worker 中添加supervisor守护进程路径：/xxxxx/www/laradock/php-worker/supervisord.d/新建laravel-s.conf，配置启动命令、用户、日志等。 123456789[program:laravel-s]command=php /var/www/laravue/bin/laravels start -inumprocs=1autostart=trueautorestart=truestartretries=3user=rootredirect_stderr=truestdout_logfile=/var/www/laravue/storage/logs/supervisord-stdout.log ps: 建议通过Supervisord监管主进程，前提是不能加-d选项并且设置swoole.daemonize为false。 项目.env配置在.env中配置 123456789101112DB_CONNECTION=mysql DB_HOST=mysql # 注意DB_PORT=3306DB_DATABASE=xxxDB_USERNAME=laravelsDB_PASSWORD=xxxREDIS_HOST=redis # 注意REDIS_PASSWORD=xxxREDIS_PORT=6379LARAVELS_LISTEN_IP=php-worker #LaravelS守护进程在php-worker中 构建并启动 Laradock 相关服务在laradock目录中 1docker-compose up -d nginx mysql redis php-worker ps：php-fpm 是 nginx 的 depends_on 依赖项，workspace 是 php-fpm 的依赖项，所以这两个容器会自动创建并启动，不需要写出来。ps：启动后，可以通过ps查看进程运行情况，通过docker logs查看相关进程日志。 项目配置通过docker-compose exec workspace bash进入容器，配置项目，具体步骤见项目README.md。一般如：composer install， npm install 等。 配置hosts在服务器中配置： 1127.0.0.1 laravels.com 本机中配置： 1xx.xx.xx.xx laravels.com ps：多项目必须配置hosts ab压测1ab -n 100 -c 100 http://laravels.com/ab_test 自测为php-fpm的5到6倍。 常见问题 workspace 和 php-fpm 的区别环境配置文件 .env 里包含相似的两块配置：workspace 和 php-fpm，它们对应两个不同的容器，一个是 FPM，一个是 CLI。不管是安装插件还是修改配置，都要分开修改。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>laravel</tag>
        <tag>laradock</tag>
        <tag>swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 安装 php、nginx、MySQL8]]></title>
    <url>%2F2020%2F01%2F06%2Fdocker-lnmp%2F</url>
    <content type="text"><![CDATA[1. 安装php拉取官方镜像 1docker pull php:7.2-fpm 2. 安装nginx拉取官方镜像 1docker pull nginx:1.17.1 3. 部署nginx+php启动php： 1docker run --name myphp-fpm -v ~/nginx/www:/usr/share/nginx/html -d php:7.2-fpm 说明： –name myphp-fpm : 将容器命名为 myphp-fpm。 -v ~/nginx/www:/usr/share/nginx/html : 将主机中项目的目录 www 挂载到容器的 /usr/share/nginx/html 创建 ~/nginx/conf/conf.d 目录： 1mkdir ~/nginx/conf/conf.d 在该目录下添加 ~/nginx/conf/conf.d/xxxxx.conf 文件，内容如下： 123456789101112131415161718192021server &#123; listen 80; server_name xxxxx.com.cn www.xxxxx.com.cn; location / &#123; root /usr/share/nginx/html; index index.html index.htm index.php; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; location ~ \.php$ &#123; fastcgi_pass php:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html/$fastcgi_script_name; include fastcgi_params; &#125;&#125; 配置文件说明： php:9000: 表示 php-fpm 服务的 URL，下面我们会具体说明。 /usr/share/nginx/html/: 是 myphp-fpm 中 php 文件的存储路径，映射到本地的 ~/nginx/www 目录。 启动nginx： 12345docker run --name php-nginx -p 80:80 -d \ -v ~/nginx/www:/usr/share/nginx/html:ro \ -v ~/nginx/conf/conf.d:/etc/nginx/conf.d:ro \ --link myphp-fpm:php \nginx -p 80:80: 端口映射，把 nginx 中的 80 映射到本地的 80 端口。 ~/nginx/www: 是本地 html 文件的存储目录，/usr/share/nginx/html 是容器内 html 文件的存储目录。 ~/nginx/conf/conf.d: 是本地 nginx 配置文件的存储目录，/etc/nginx/conf.d 是容器内 nginx 配置文件的存储目录。 –link myphp-fpm:php: 把 myphp-fpm 的网络并入 nginx，并通过修改 nginx 的 /etc/hosts，把域名 php 映射成 127.0.0.1，让 nginx 通过 php:9000 访问 php-fpm。 接下来就可以在~/nginx/www目录下创建php项目来访问 4. 安装MySQL拉取官方镜像： 1docker pull mysql:8.0.16 创建MySQL相关目录： 1mkdir -p ~/mysql/data ~/mysql/log ~/mysql/conf 创建~/mysql/conf/my.cnf配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041# Copyright (c) 2017, Oracle and/or its affiliates. All rights reserved.## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License as published by# the Free Software Foundation; version 2 of the License.## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the# GNU General Public License for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA## The MySQL Server configuration file.## For explanations see# http://dev.mysql.com/doc/mysql/en/server-system-variables.html[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysqlsecure-file-priv= NULL# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0lower_case_table_names=1character-set-server=utf8default_authentication_plugin=mysql_native_password[client]default-character-set=utf8[mysql]default-character-set=utf8# Custom config should go here!includedir /etc/mysql/conf.d/ 创建mysql8容器： 1234567891011docker run \-p 3306:3306 \--restart=always \--privileged=true \--name mysql8 \-e MYSQL_ROOT_PASSWORD=&quot;TRlmRw8xGqYM&quot; \-v /root/mysql/data:/var/lib/mysql:rw \-v /root/mysql/log:/var/log/mysql:rw \-v /root/mysql/conf/my.cnf:/etc/mysql/my.cnf:rw \-v /etc/localtime:/etc/localtime:ro \-d mysql:8.0.16 相关命令： 进入镜像： 1docker run -it mysql:8.0.16 /bin/bash 进入容器： 1docker exec -it mysql8 /bin/sh]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 搭建 jenkins]]></title>
    <url>%2F2020%2F01%2F06%2Fdocker-jenkins%2F</url>
    <content type="text"><![CDATA[几个可用的Jenkins Docker镜像建议使用的Docker映像是enkinsci/blueocean image该镜像包含当前的长期支持 (LTS) 的Jenkins版本 （可以投入使用） ，捆绑了所有Blue Ocean插件和功能。这意味着你不需要单独安装Blue Ocean插件。 jenkinsci/blueocean每次发布Blue Ocean新版本时，都会发布新镜像。您可以在 标签page页上看到以前发布的镜像版本列表 。 您还可以使用其他Jenkins Docker镜像（在Docker Hub上可通过enkins/jenkins。 但是，这些不会随Blue Ocean的发布而提供，需要通过 Jenkins中的anage Jenkins &gt; Manage Plugins页面进行安装。 安装 打开一个终端窗口 下载 jenkinsci/blueocean 镜像并使用以下docker run 命令将其作为Docker中的容器运行 ：12345678910docker run \ -u root \ --rm \ -t \ -d \ -p 8080:8080 \ -p 50000:50000 \ -v jenkins-data:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkinsci/blueocean --rm (可选) jenkinsci/blueocean 关闭时自动删除Docker容器（下图为实例）。如果您需要退出Jenkins，这可以保持整洁。 -d（可选）jenkinsci/blueocean 在后台运行容器（即“分离”模式）并输出容器ID。如果您不指定此选项， 则在终端窗口中输出正在运行的此容器的Docker日志。 -p 8080:8080 映射（例如“发布”）jenkinsci/blueocean 容器的端口8080到主机上的端口8080。 第一个数字代表主机上的端口，而最后一个代表容器的端口。因此，如果您为此选项指定 -p 49000:8080 ，您将通过端口49000访问主机上的Jenkins。 -p 50000:50000（可选）将 jenkinsci/blueocean 容器的端口50000 映射到主机上的端口50000。 如果您在其他机器上设置了一个或多个基于JNLP的Jenkins代理程序，而这些代理程序又与 jenkinsci/blueocean 容器交互（充当“主”Jenkins服务器，或者简称为“Jenkins主”）， 则这是必需的。默认情况下，基于JNLP的Jenkins代理通过TCP端口50000与Jenkins主站进行通信。 您可以通过“ 配置全局安全性” 页面更改Jenkins主服务器上的端口号。如果您要将您的Jenkins主机的JNLP代理端口的TCP端口 值更改为51000（例如），那么您需要重新运行Jenkins（通过此 docker run …​命令）并指定此“发布”选项 -p 52000:51000，其中最后一个值与Jenkins master上的这个更改值相匹配，第一个值是Jenkins主机的主机上的端口号， 通过它，基于JNLP的Jenkins代理与Jenkins主机进行通信 - 例如52000。 -v jenkins-data:/var/jenkins_home（可选，但强烈建议）映射在容器中的/var/jenkins_home 目录到具有名字 jenkins-data 的volume。 如果这个卷不存在，那么这个 docker run 命令会自动为你创建卷。 如果您希望每次重新启动Jenkins（通过此 docker run … 命令）时保持Jenkins状态，则此选项是必需的 。 如果你没有指定这个选项，那么在每次重新启动后，Jenkins将有效地重置为新的实例。注意: 所述的 jenkins-data 卷也可以 docker volume create命令创建： docker volume create jenkins-data 代替映射 /var/jenkins_home 目录转换为Docker卷，还 可以将此目录映射到计算机本地文件系统上的目录。 例如，指定该选项 -v $HOME/jenkins:/var/jenkins_home 会将容器的 /var/jenkins_home 目录映射 到 本地计算机上目录中的 jenkins 子目录， 该$HOME目录通常是 /Users/&lt;your-username&gt;/jenkins 或/home/&lt;your-username&gt;/jenkins。 -v /var/run/docker.sock:/var/run/docker.sock（可选 /var/run/docker.sock 表示Docker守护程序通过其监听的基于Unix的套接字。 该映射允许 jenkinsci/blueocean 容器与Docker守护进程通信， 如果 jenkinsci/blueocean 容器需要实例化其他Docker容器，则该守护进程是必需的。 如果运行声明式管道，其语法包含agent部分用 docker例如， agent { docker { … } } 此选项是必需的。 在Pipeline Syntax 页面上阅读更多关于这个的信息 jenkinsci/blueocean Docker镜像本身。如果此镜像尚未下载，则此 docker run 命令 将自动为您下载镜像。此外，如果自上次运行此命令后发布了此镜像的任何更新， 则再次运行此命令将自动为您下载这些已发布的镜像更新。 注意：这个Docker镜像也可以使用以下 docker pull命令独立下载（或更新） ： docker pull jenkinsci/blueocean 设置 浏览到 IP:8080（或安装时为Jenkins配置的任何端口），并等待 解锁 Jenkins 页面出现。 进入Jenkins容器，/var/jenkins_home/secrets/initialAdminPassword文件下，找到Administrator密码。 之后安装插件，创建管理员用户，等，按照提示，一步一步操作。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清理docker]]></title>
    <url>%2F2019%2F12%2F24%2Fdocker-clean%2F</url>
    <content type="text"><![CDATA[经常使用docker，会发现docker占用资源膨胀的很快，所以，本文介绍如何清理docker占用的系统资源，具体说就是删除那些无用的镜像、容器、网络和数据卷。 查看docker占用的资源 docker container ls：默认只列出正在运行的容器，-a 选项会列出包括停止的所有容器。 docker image ls：列出镜像信息，-a 选项会列出 intermediate 镜像(就是其它镜像依赖的层)。 docker volume ls：列出数据卷。 docker network ls：列出 network。 docker info：显示系统级别的信息，比如容器和镜像的数量等。 通过这些命令查看 docker 使用的资源情况后，相信你已经决定要清理 docker 占用的一些资源了！让我们先从那些未被使用的资源开始。 删除那些未被使用的资源Docker 提供了方便的 docker system prune 命令来删除那些已停止的容器、dangling 镜像、未被容器引用的 network 和构建过程中的 cache： 1docker system prune 安全起见，这个命令默认不会删除那些未被任何容器引用的数据卷，如果需要同时删除这些数据卷，你需要显式的指定 –volumns 参数。比如你可能想要执行下面的命令： 1docker system prune --all --force --volumes 这次不仅会删除数据卷，而且连确认的过程都没有了！注意，使用 --all 参数后会删除所有未被引用的镜像而不仅仅是 dangling 镜像。 dangling images: 其实可以简单的理解为未被任何镜像引用的镜像。比如在你重新构建了镜像后，那些之前构建的且不再被引用的镜像层就变成了 dangling images。 intermediate 镜像: 在本地的镜像更新之后，就会出现 镜像。这表示旧的镜像已经不再被引用了，此时它们就变成了 dangling images。如果使用 -a 参数，你还会发现另外一种类型的 镜像，它们的 repository 和 tag 列都表现为 ，这些镜像被称为 intermediate 镜像(就是其它镜像依赖的层)。 我们还可在不同在子命令下执行 prune，这样删除的就是某类资源：docker container prune # 删除所有退出状态的容器docker volume prune # 删除未被使用的数据卷docker image prune # 删除 dangling 或所有未被使用的镜像 清空docker1docker system prune --all --force --volumns 如果在执行这个命令前系统中所有的容器都已停止，那么这个命令就会移除所有的资源！好，现在让我们想办法停掉系统中的所有容器。 1docker container stop 该命令可以停止一个或多个容器，我们只需要把系统中所有在运行的容器罗列出来就可以了。由于 docker 并不介意我们再次停止一个已经停止了的容器，干脆简单粗暴点，直接列出所有的容器(包括已经停止的)！ 1docker container ls -a -q -a 显示所有的容器 -q 只显示数字形式的容器 ID 然后把这里命令执行的结果作为 docker container stop 命令的参数： 1docker container stop $(docker container ls -a -q) 完整的恢复 docker 环境的命令如下： 1docker container stop $(docker container ls -a -q) &amp;&amp; docker system prune --all --force --volumns 和前面的 prune 命令类似，也可以完全删除某一类资源：删除容器：docker container rm $(docker container ls -a -q)删除镜像：docker image rm $(docker image ls -a -q)删除数据卷：docker volume rm $(docker volume ls -q)删除 network：docker network rm $(docker network ls -q) 创建 shell 别名上面的命令可以完成任务但是却很繁琐，我们可以通过 shell 的别名功能来简化这些命令的执行。 12alias docker-clean-unused=&apos;docker system prune --all --force --volumes&apos;alias docker-clean-all=&apos;docker stop $(docker container ls -a -q) &amp;&amp; docker system prune --all --force --volumes&apos; 把上面的命令写入到用户的 ~/.bashrc 文件中就可以了！]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laradock 搭建php环境]]></title>
    <url>%2F2019%2F12%2F24%2Fdocker-php-env%2F</url>
    <content type="text"><![CDATA[1. 安装docker移除旧版本： 12345678910$ sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安装必要的系统工具： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加软件源信息： 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新 yum 缓存： 1sudo yum makecache fast 安装 Docker-ce： 1sudo yum -y install docker-ce 启动 Docker 后台服务： 1sudo systemctl start docker 安装docker-compose： 123456curl -L https://github.com/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose也可以直接去官网下载相应版本https://github.com/docker/compose/releases然后重命名并修改权限 2. 部署php环境 克隆laradocklaradock 官方文档：http://laradock.io/laradock github：https://github.com/laradock/laradock Already have a PHP project: 在项目里 123git clone https://github.com/Laradock/laradock.git进入laradock:cp env-example .env Don’t have a PHP project yet: 和项目同级目录 12345git clone https://github.com/laradock/laradock.git进入laradock：cp env-example .env修改为项目文件名称：APP_CODE_PATH_HOST=../project-z/ 直接用 docker-compose 运行需要启用的服务：1docker-compose up -d nginx mysql php-fpm 3. laravel 配置文件Laravel 配置文件需要注意的问题是，在 .env 文件中，mysql 和 redis 的地址需填写成这样，而不是 ip 地址形式： 12345678910DB_CONNECTION=mysql DB_HOST=mysql DB_PORT=3306 DB_DATABASE=xxxxDB_USERNAME=root DB_PASSWORD=root REDIS_HOST=redis REDIS_PASSWORD=null REDIS_PORT=6379 4. nginx配置在laradock文件夹，nginx/sites/中配置*.conf文件 12345678910111213141516171819202122232425262728293031323334353637383940server &#123; listen 80 default_server; listen [::]:80 default_server ipv6only=on; # For https # listen 443 ssl default_server; # listen [::]:443 ssl default_server ipv6only=on; # ssl_certificate /etc/nginx/ssl/default.crt; # ssl_certificate_key /etc/nginx/ssl/default.key; server_name xxxxx.com www.xxxxx.com; root /var/www/public; ### 注：root为容器内的路径 index index.php index.html index.htm; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location ~ \.php$ &#123; try_files $uri /index.php =404; fastcgi_pass php-upstream; fastcgi_index index.php; fastcgi_buffers 16 16k; fastcgi_buffer_size 32k; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; #fixes timeouts fastcgi_read_timeout 600; include fastcgi_params; &#125; location ~ /\.ht &#123; deny all; &#125; location /.well-known/acme-challenge/ &#123; root /var/www/letsencrypt/; log_not_found off; &#125;&#125; 重启nginx操作：在laradock文件夹内 1234docker-compose restart nginx或者：docker-compose stop nginxdocker-compose up -d nginx 5. 执行composer执行 composer 等操作，需要进入到 workspace 容器中进行，使用命令： 1docker-compose exec workspace bash 进入到 workspace 容器，就可以进行 compose 命令等操作了。具体使用上的问题请参加 laradock 官方文档，上面都有说明。 6. MySQL8修改验证方式mysql 8.0 将密码验证方式由以前的 mysql_native_password 改为了 caching_sha2_password 。可以进入 mysql 容器 bash，登录 mysql ，将验证方式修改成原来的： 123456789#在laradock文件夹中执行：docker-compose exec mysql bashmysql -uroot -pmysql&gt; grant all PRIVILEGES on *.* to root@&apos;%&apos; WITH GRANT OPTION;mysql&gt; ALTER user &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;root&apos;; // 设置root远程登录mysql&gt; ALTER user &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;root&apos;; // 设置root本地登录mysql&gt; FLUSH PRIVILEGES;mysql&gt; exit; 现在就可以用 root 登录了。为了使新建用户的验证方式默认为 mysql_native_password ，可以修改 my.cnf 文件，在 [mysqld] 部分中添加： 1default_authentication_plugin = mysql_native_password 7. laradock 默认装的是 mysql 最新版本(mysql8)，也可以更换成低版本的 mysql1234567891011121314151617181920212223# 修改 .env 文件MYSQL_VERSION=5.7 # 默认为 latest#停止mysql容器docker-compose stop mysql# 删除旧数据库数据rm -rf ~/.laradock/data/mysql# 重新构建新 mysqldocker-compose build mysql # 重新创建容器docker-compose up -d nginx mysql# 查看现有 mysql 版本docker inspect laradock_mysql_1# 修改MySQL密码mysql&gt; alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;123&apos;;或者mysql&gt; USE mysql;mysql&gt; UPDATE user SET authentication_string=PASSWORD(&quot;NEWPASSWORD&quot;) WHERE User=&apos;root&apos;; 8. 添加Redis配置去修改 redis 的配置的时候，才发现默认安装的时候并没有添加 redis 的配置。所以重装配置下：修改laradock/redis/Dockerfile: 1234567891011121314FROM redis:latestLABEL maintainer=&quot;Mahmoud Zalt &lt;mahmoud@zalt.me&gt;&quot;## For security settings uncomment, make the dir, copy conf, and also start with the conf, to use itRUN mkdir -p /usr/local/etc/redisCOPY redis.conf /usr/local/etc/redis/redis.confVOLUME /dataEXPOSE 6379CMD [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;]#CMD [&quot;redis-server&quot;] 编辑配置文件:默认情况 redis 目录下有 redis.conf 文件，修改以下两点即可 注释 bind 127.0.0.1 protected-mode 改为 no其他配置根据自己情况进行修改。 重装 redis: 切换到 laradock 目录 停止redis docker-compose stop redis 重装 docker-compose build --no-cache redis 启动 docker-compose up -d redis]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设置环境变量PATH 和 查看PATH]]></title>
    <url>%2F2019%2F11%2F14%2Fmac-env-path%2F</url>
    <content type="text"><![CDATA[理论篇Mac系统的环境变量，加载顺序为：/etc/profile /etc/paths ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc /etc/profile和/etc/paths是系统级别的，系统启动就会加载，后面几个是当前用户级的环境变量。 后面3个按照从前往后的顺序读取，如果/.bash_profile文件存在，则后面的几个文件就会被忽略不读了，如果/.bash_profile文件不存在，才会以此类推读取后面的文件。 ~/.bashrc没有上述规则，它是bash shell打开的时候载入的。 PATH的语法如下： 12#中间用冒号隔开export PATH=$PATH:&lt;PATH 1&gt;:&lt;PATH 2&gt;:&lt;PATH 3&gt;:------:&lt;PATH N&gt; 上述文件的科普 /etc/paths （全局建议修改这个文件 ）编辑 paths，将环境变量添加到 paths文件中 ，一行一个路径Hint：输入环境变量时，不用一个一个地输入，只要拖动文件夹到 Terminal 里就可以了。 /etc/profile （建议不修改这个文件 ）全局（公有）配置，不管是哪个用户，登录时都会读取该文件。 /etc/bashrc （一般在这个文件中添加系统级环境变量）全局（公有）配置，bash shell执行时，不管是何种方式，都会读取此文件。 ~/.profile 文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行.并从/etc/profile.d目录的配置文件中搜集shell的设置使用注意：如果你有对/etc/profile有修改的话必须得重启你的修改才会生效，此修改对每个用户都生效。 ~/.bashrc 每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取.使用注意：对所有的使用bash的用户修改某个配置并在以后打开的bash都生效的话可以修改这个文件，修改这个文件不用重启，重新打开一个bash即可生效。 /.bash_profile 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取.（每个用户都有一个.bashrc文件，在用户目录下）使用注意：需要需要重启才会生效，/etc/profile对所有用户生效，/.bash_profile只对当前用户生效。 source ~/.bash_profile 或者 ~/.profile 环境信息生效 操作篇全局设置 创建一个文件 1sudo touch /etc/paths.d/mysql 用 vim 打开这个文件（如果是以 open -t 的方式打开，则不允许编辑） 1sudo vim /etc/paths.d/mysql 编辑该文件，键入路径并保存（关闭该 Terminal 窗口并重新打开一个，就能使用 mysql 命令了） 1/Applications/MAMP/Library/bin source 相应的文件 生效配置环境 该mac的mysql环境变量配置方法如下：创建软连接至/usr/local/bin环境变量目录sudo ln -s /Applications/MAMP/Library/bin/mysql /usr/local/bin/mysql 注： Mac的这个bin目录，是一个已经包含在环境变量里的目录，程序放在里面或者链接到里面就可以在终端里直接执行。 Mac的usr/bin目录是不允许增删文件的，可以通过向usr/local/bin增删文件来实现在终端里直接运行，往后者里面增删文件只要有管理员权限就可以了。 单个环境变量设置 vim ~/.bash_profile （任意一个文件中添加用户级环境变量） 12# 第一个是PHP地址；第二个是nginx地址export PATH=&quot;/Applications/MAMP/bin/php/php7.3.1/bin:/Applications/MAMP/Library/sbin:$PATH&quot; source ~/.bash_profile 生效 查看PATH1echo $PATH]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>path</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SSHFS 将远程文件挂载到本地]]></title>
    <url>%2F2019%2F11%2F14%2Fmac-sshfs-to-local%2F</url>
    <content type="text"><![CDATA[SSHFS允许您使用SFTP安装远程文件系统。 大多数SSH服务器默认支持并启用此SFTP访问，因此SSHFS使用起来非常简单，服务器端无需执行任何操作。 在MacOS中使用SSHFS需要FUSE的支持 用于 macOS 的 FUSE 允许您通过第三方文件系统扩展 macOS 的本地文件处理功能。 它是 MacFUSE 的继任者，已被许多产品用作软件构建块，但不再维护; 安装 下载安装从 官网下载最新版的 FUSE for macOS 和 SSHFS 直接安装。下载速度较慢，以存放至百度云备用 HomeBrew安装 (安装太慢，不推荐) 12$ brew cask install osxfuse$ brew cask install sshfs 使用新建本地挂载点 1$ mkdir local-file 挂载 1$ sshfs user@hostname:/absolute/path/to/document local-file 远程的地址最好使用绝对路径。此时打开该文件夹就可以访问远程文件了。 卸载挂载文件 1$ umount local-file]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>sshfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置https 和 HTTP2]]></title>
    <url>%2F2019%2F11%2F14%2Flinux-https-http2%2F</url>
    <content type="text"><![CDATA[配置ssl证书 证书说明：这里使用的证书是阿里云个人一年免费的SSL证书，只需要在阿里云上申请即可获得。 web服务器说明：这里采用的web服务器是Nginx服务器。 服务器操作系统说明：这里使用的是Centos 7.x系统。 终端登陆工具与FTP工具说明：这里使用的是Xshell与Xftp工具。 下载证书登陆到阿里云控制台，今天证书安全下载界面，选择Nginx/Tengine，下载证书，并解压到桌面。 上传证书到服务器 登陆到服务器，并进入到Nginx目录: 创建证书存放目录: 使用Xftp将证书上传至新建的目录下: 配置Nginx使其支持SSL证书 进入nginx下的conf.d目录，创建一个新的.conf文件，命名为ssl.域名.conf(命名可任意，但需以.conf结尾)。 为新建的.conf文件添加如下代码： 1234567891011121314151617181920212223242526272829303132server &#123; listen 443; # 修改为你的域名 server_name 域名.com www.域名.com; ssl on; # root目录，即为你网站的存放目录 root /mnt/www/域名.com/public_html/wordpress/; index index.html index.htm index.php; # 将下面两行修改为SSL证书存放路径 ssl_certificate /etc/nginx/ssl/域名.com/214190949470644.pem; ssl_certificate_key /etc/nginx/ssl/域名.com/214190949470644.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; # 以下为Nginx的基本配置 location / &#123; try_files $uri $uri/ /index.php?$query_string; &#125; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125;&#125; 测试下配置的正确性，成功后重启下Nginx，再打开浏览器测试HTTPS是否能正常访问。 另外说明：可以看到目前conf.d目录里有3个以.conf结尾的配置文件，basic.conf为基本的解析配置文件；域名.conf为不使用SSL证书的http配置文件；ssl.域名.com为新增加的使用SSL证书的HTTPS配置文件。因此，在目前未配置301重定向的情况下，打开浏览器测试网站的时候，可以发现网站即可正常访问http,也可以正常访问https。 为Nginx配置301重定向说明：在上面说了，目前网站的状态应该是http和https都可以正常访问。现在则为Nginx配置一下301重定向，这样当访问网站的时候就会自动定向到https,而不会在通过http访问网站了。 进入Nginx配置目录，打开http的配置文件 编辑域名.conf配置文件 123456server &#123; listen 80; # 将“域名”改为你自己的域名 server_name 域名.com www.域名.com; return 301 https://$host$request_uri;&#125; 注意：这里编辑的是域名.conf，而不是ssl.域名.conf！！！ 重启Nginx，打开浏览器测试1systemctl restart nginx 配置至此，网站已经只会再通过https访问了，但是仍然还不会使用http2.0协议. 配置HTTP2查看网站协议打开浏览器，将审查元素打开，点击Network选项卡，将Protocol调出来，查看传输协议。目前显示的为http/1.1，传输协议。 查看Nginx版本，查看OpenSSL版本目前显示的版本是nginx/1.10.2，OpenSSL 1.0.1e-fips，因为之前安装Nginx时，使用的时系统默认的源，然而Centos7自带的Nginx版本并不够新，想要支持使用http2.0协议，OpenSS必须升级到2.0版本以上才可以。因此要对Nginx重新编译。 编译安装Nginx和openssl 安装编译过程中需要使用的工具 1yum install wget curl perl gcc pcre-devel zlib-devel make -y 下载Nginx源和openssl源 12345678910//下载openssl新版的源和Nginx新版源wget https://www.openssl.org/source/openssl-1.0.2l.tar.gz http://nginx.org/download/nginx-1.11.10.tar.gz//解压两个压缩包tar zxvf nginx-1.11.10.tar.gztar zxvf openssl-1.0.2l.tar.gz//重命名nginx和opensslmv nginx-1.11.10/ nginxmv openssl-1.0.2l/ openssl 编译nginx 首先卸载原先版本的额nginx 1yum remove nginx -y 配置编译nginx 123456789101112131415161718192021222324//进入nginx和openssl所在目录。cd ~//将nginx和openssl移动到/usr/local/src文件夹mv nginx/ openssl/ /usr/local/src///进入/etc/local/src/nginx目录下cd /usr/local/src/nginx//配置nginx./configure --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_auth_request_module --with-threads --with-stream --with-stream_ssl_module --with-http_slice_module --with-mail --with-mail_ssl_module --with-file-aio --with-http_v2_module --with-stream_realip_module --with-openssl=/usr/local/src/openssl//使用make命令编译一下,时间较长make//编译完成后执行下make insatllmake install//为新编译的nginx添加用户，创建配置目录useradd nginx &amp;&amp; mkdir /etc/nginx/conf.d//创建nginx缓存目录，并设置一些权限mkdir /var/cache/nginx &amp;&amp; chown nginx:root /var/cache/nginx//删除用不着的文件rm -rf /usr/local/src/nginx &amp;&amp; rm -rf /usr/local/src/openssl &amp;&amp; rm -rf /var/cache/yum 继续配置nginx，并启动它 1234567891011121314151617181920212223//配置nginx服务文件vim /usr/lib/systemd/system/nginx.service//为nginx.service添加配置代码[Unit]Description=nginx - high performance web serverDocumentation=http://nginx.org/en/docs/After=network-online.target remote-fs.target nss-lookup.targetWants=network-online.target[Service]Type=forkingPIDFile=/run/nginx.pidExecStartPre=/usr/sbin/nginx -t -c /etc/nginx/nginx.confExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.confExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPID[Install]WantedBy=multi-user.target//启动下nginx，再设置开机启动systemctl start nginxsystemctl enable nginxsystemctl status nginx 编辑nginx.conf文件 1234567891011//进入nginx目录cd /etc/nginx///为nginx.conf添加代码vim nginx.conf//在nginx.conf中的gzip on代码下面一行添加如下代码include /etc/nginx/conf.d/*.conf;//重启nginxsystemctl restart nginx 配置http2.0协议12345678910//编辑ssl.域名.conf文件vim ssl.域名.conf//在第一行listen配置项中添加 ssl http2server &#123;listen 443 ssl http2;.....见第一篇中的.conf配置文件//重启nginxsystemctl restart nginx 测试至此，http2.0协议配置完成，打开浏览器查看传输协议。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10+Ubuntu17.04双系统安装]]></title>
    <url>%2F2019%2F11%2F14%2Flinux-two-system%2F</url>
    <content type="text"><![CDATA[本教程默认已安装win10，即是在win10正常使用基础上进行的 本教程自动忽略虚拟机和wubi安装，隔靴搔痒而已，毋庸置疑最好的方式还是u盘安装 本教程同样适用于Win10+Ubuntu16.04LTS，亲测一样成功 本教程全部图片来自网络（自己太懒并没有截图，只为讲述教程进行中的画面，因此图仅供参考） 准备Ubuntu系统的的ISO、UltraISO、EasyBCD、U盘 安装数据备份创建磁盘分区 按住Win + X，选择“磁盘管理” 选择剩余空间较大的可分配磁盘，右键并选择“压缩卷”，这里选择压缩E盘50G左右的空间 点击“压缩”之后，E盘后部出现黑色的50G“未分配空间” 至此，磁盘分区过程完成 禁用快速启动(可选但是建议)按住Win + X(请记住这个万能的组合)，选择“电源选项”，依次执行：“选择电源按钮的功能” -&gt; “更改当前不可用的设置” -&gt; 取消选择”启用快速启动” 注： “快速启动”是Windows 8时代引进的新特性，建议关闭该特性的原因是，“快速启动”会影响Grub开机引导过程，可能出现无法载入Ubuntu的状况，最后选择“保存修改”。 制作Ubuntu的启动U盘（用U盘安装过操作系统的童鞋可以跳过这一步） 备份待写入的U盘并将其插入电脑，进入UltraISO，打开镜像文件（即你已经下载好的ubuntu ISO镜像文件） 启动&gt;写入硬盘映像 按默认值写入 完成硬盘映像写入，别拔U盘 U盘安装Ubuntu重启，并按进入bios的快捷键(电脑不同型号快捷键不同，我的联想F2），进入系统bios后设置优先u盘启动，设置后电脑自动重启并进入ubuntu安装界面。 选择“试用Ubuntu Kylin” 进入ubuntu主界面然后双击打开ubuntu安装文件,完成默认设置 注：如果网络和空间匀速，可以选择“安装中下载更新”和“安装这个第三方软件”（可以不选择，我建议不选择，费时间也没啥用） U盘安装Ubuntu本教程最重要的的一步，选择“其他选项” 单击“创建新分区表”，点击的“+”创建4个主要的基础分区（这里之前未分配的50G就是给ubuntu系统的50G），按以下参数设置4个主要的基础分区： 大小 分区 位置 格式 地址 10G 主分区 空间起始位置 Ext4日志文件系统 / 4G 逻辑分区 空间起始位置 交换空间 /swap 200MB 逻辑分区 空间起始位置 Ext4日志文件系统 /boot 剩余的空间 逻辑分区 空间起始位置 Ext4日志文件系统 /home 当然这里还可创建自己的其他分区如/123分区，只要设置为逻辑分区、空间起始位置、Ext4日志文件系统即可，新手强烈建议忽略此步，按上面设置即可 安装启动引导设备的参数选择：与/boot所在的编号一致。设置好后安装即可，之后的选项（所在地点、键盘布局、电脑名称、开机密码等）正常进行直到安装完毕，大功告成。 重启系统，进入Win10完成最后的引导设置。 EasyBCD引导Ubuntu 重启在win10下进入EasyBCD，选择“添加新条目”，选择Linux/BSD操作系统，在“驱动器”栏目选择接近200M（与boot的那个接近）的Linux分区，点添加条目 完成条目添加后，重启电脑，会发现Win10和Ubuntu的双系统已经完成安装 大功告成，祝玩得开心 后记：用Windows引导Ubuntu最大的好处就是，当不再需要Ubuntu的时候，直接在Windows磁盘管理中将其所在所有分区删除，然后将EasyBCD中对应条目删除即可。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>win</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 中添加一个新用户并授权]]></title>
    <url>%2F2019%2F11%2F14%2Flinux-centos-add-new-user%2F</url>
    <content type="text"><![CDATA[创建新用户创建一个用户名为：linuxidc 1[root@localhost ~]# adduser linuxidc 为这个用户初始化密码，linux会判断密码复杂度，不过可以强行忽略： 1[root@localhost ~]# passwd linuxidc 授权个人用户的权限只可以在本home下有完整权限，其他目录要看别人授权。而经常需要root用户的权限，这时候sudo可以化身为root来操作。我记得我曾经sudo创建了文件，然后发现自己并没有读写权限，因为查看权限是root创建的。 新创建的用户并不能使用sudo命令，需要给他添加授权。 sudo命令的授权管理是在sudoers文件里的。可以看看sudoers： 12[root@localhost ~]# whereis sudoerssudoers: /etc/sudoers /etc/sudoers.d /usr/libexec/sudoers.so /usr/share/man/man5/sudoers.5.gz 找到这个文件位置之后再查看权限： 12[root@localhost ~]# ls -l /etc/sudoers-r--r----- 1 root root 4251 9月 25 15:08 /etc/sudoers 是的，只有只读的权限，如果想要修改的话，需要先添加w权限： 12[root@localhost ~]# chmod -v u+w /etc/sudoersmode of &quot;/etc/sudoers&quot; changed from 0440 (r--r-----) to 0640 (rw-r-----) 然后就可以添加内容了，在下面的一行下追加新增的用户： 12345[root@localhost ~]# vim /etc/sudoers## Allow root to run any commands anywherroot ALL=(ALL) ALLlinuxidc ALL=(ALL) ALL #这个是新增的用户 wq保存退出，这时候要记得将写权限收回： 12[root@localhost ~]# chmod -v u-w /etc/sudoersmode of &quot;/etc/sudoers&quot; changed from 0640 (rw-r-----) to 0440 (r--r-----) 这时候使用新用户登录，使用sudo： 1234567[linuxidc@localhost ~]$ sudo cat /etc/passwd[sudo] password for linuxidc:We trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things:#1) Respect the privacy of others.#2) Think before you type.#3) With great power comes great responsibility. 第一次使用会提示你，你已经化身超人，身负责任。而且需要输入密码才可以下一步。如果不想需要输入密码怎么办，将最后一个 ALL 修改成 NOPASSWD: ALL 。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux文件权限]]></title>
    <url>%2F2019%2F11%2F14%2Flinux-file-jurisdiction%2F</url>
    <content type="text"><![CDATA[1. 常用权限 444 r–r–r– ： 所有用户都只有读权限 600 rw——- ： 文件所有者具有读、写权限，其他用户没有权限 644 rw-r–r– ： 文件所有者具有读写权限，同组用户具有读权限，其他用户具有读权限 666 rw-rw-rw- ：文件所有者，同组用户，其他用户都具有读写权限，没有执行权限 700 rwx—— ： 文件所有者具有读写执行权限，同组用户其他用户均没有任何权限 744 rwxr–r– ： 文件所有者具有读写执行权限，同组用户和其他用户只有读权限 755 rwxr-xr-x ： 文件所有者具有读、写、执行权限，同组用户和其他用户具有读、执行权限 777 rwxrwxrwx ： 全部用户都用全权限 2. 权限解释从左至右，1-3位数字代表文件所有者的权限，4-6位数字代表同组用户的权限，7-9数字代表其他用户的权限。 具体的权限是由数字来表示的，读取的权限等于4，用r表示；写入的权限等于2，用w表示；执行的权限等于1，用x表示。 通过4、2、1的组合，得到以下几种权限：0（没有权限）；4（读取权限）；5（4+1 | 读取+执行）；6（4+2 | 读取+写入）；7（4+2+1 | 读取+写入+执行）。 以755为例：1-3位7等于4+2+1，rwx，所有者具有读取、写入、执行权限；4-6位5等于4+1+0，r-x，同组用户具有读取、执行权限但没有写入权限；7-9位5，同上，也是r-x，其他用户具有读取、执行权限但没有写入权限。 3. 语法示例将文件 file1.txt 设为所有人皆可读取 : 123chmod ugo+r file1.txt或者chmod a+r file1.txt u 表示该文件的拥有者(User)，g 表示与该文件的拥有者属于同一个群体(Group)者，o 表示其他以外的人(Other)，a 表示这三者皆是。 +表示增加权限、- 表示取消权限、= 表示唯一设定权限。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的artisan命令]]></title>
    <url>%2F2019%2F11%2F14%2Flaravel-artisan%2F</url>
    <content type="text"><![CDATA[全局篇 查看artisan命令 12php artisanphp artisan list 查看某个帮助命令 1php artisan help make:model 查看laravel版本 1php artisan --version 使用 PHP 内置的开发服务器启动应用 1php artisan serve 生成一个随机的 key，并自动更新到 app/config/app.php 的 key 键值对（刚安装好需要做这一步） 1php artisan key:generate 开启Auth用户功能（开启后需要执行迁移才生效） 1php artisan make:auth 开启维护模式和关闭维护模式（显示503） 12php artisan downphp artisan up 进入tinker工具 1php artisan tinker 列出所有的路由 1php artisan route:list 生成路由缓存以及移除缓存路由文件 12php artisan route:cachephp artisan route:clear 功能篇 创建控制器 1php artisan make:controller StudentController 创建Rest风格资源控制器（带有index、create、store、edit、update、destroy、show方法） 1php artisan make:controller PhotoController --resource 创建模型 1php artisan make:model Student 创建新建表的迁移和修改表的迁移 12php artisan make:migration create_users_table --create=students //创建students表php artisan make:migration add_votes_to_users_table --table=students//给students表增加votes字段 执行迁移 1php artisan migrate 创建模型的时候同时生成新建表的迁移 1php artisan make:model Student -m 回滚上一次的迁移 1php artisan migrate:rollback 回滚所有迁移 1php artisan migrate:reset 创建填充 1php artisan make:seeder StudentTableSeeder 执行单个填充 1php artisan db:seed --class=StudentTableSeeder 执行所有填充 1php artisan db:seed 创建中间件（app/Http/Middleware下） 1php artisan make:middleware Activity 创建队列（数据库）的表迁移（需要执行迁移才生效） 1php artisan queue:table 创建队列类（app/jobs下）： 1php artisan make:job SendEmail 创建请求类（app/Http/Requests下） 1php artisan make:request CreateArticleRequest]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel Queue]]></title>
    <url>%2F2019%2F11%2F14%2Flaravel-queue%2F</url>
    <content type="text"><![CDATA[使用队列原因 异步 重试 使用队列场景 耗时比较久的，比如上传一个文件后进行一些格式的转化等。 需要保证送达率的，比如发送短信，因为要调用别人的 api，总会有几率失败，那么为了保证送达，重试就必不可少了。 tips 在开发环境我们想测试的时候，可以把 Queue driver 设置成为 sync ，这样队列就变成了同步执行，方便调试队列里面的任务。 Job 里面的 handle 方法是可以注入别的 class 的，就像在 Controller action 里面也可以注入一样。 什么时候使用 queue:listen 什么时候使用 queue:work ？答：Laravel 5.3 的文档已经不写 queue:listen 这个指令怎么用了，所以你可以看出来可能官方已经不怎么建议使用 queue:listen 了，但是在本地调试的时候要使用 queue:listen ，因为 queue:work 在启动后，代码修改， queue:work 不会再 Load 上下文，但是 queue:listen 仍然会重新 Load 新代码。其余情况全部使用 queue:work 吧，因为效率更高。 命令讲解命令： 1php artisan queue:work --daemon --quiet --queue=default --delay=3 --sleep=3 --tries=3 –daemon总体来说，在 supervisor 中一般要加这个 option，可以节省 CPU 使用。 –quiet不输出任何内容 –delay=3一个任务失败后，延迟 多长时间 后再重试，单位是秒。这个值的设定我个人建议不要太短，因为一个任务失败（比如网络原因），重试时间太短可能会出现连续失败的情况。 –sleep=3去 Redis 中拿任务的时候，发现没有任务，休息 多长时间 ，单位是秒。这个值的设定要看你的任务是否紧急，如果是那种非常紧急的任务，不能等待太长时间。 –tries=3定义 失败任务最多重试次数 。这个值的设定根据任务的重要程度来确定，一般 3 次比较适合。 注意Redis 里面一个任务默认最多执行60秒，如果一个任务60秒没有执行完毕，会继续放回到队列中，循环执行，那酸爽…]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laravel创建工具类]]></title>
    <url>%2F2019%2F11%2F14%2Flaravel-common-class%2F</url>
    <content type="text"><![CDATA[以Common工具类为例： 首先先介绍这个类的用法：在一般控制器中只要 use Common; 然后在方法里面就能调用到Common类里面的方法了，如Common::getSite();直接能调用到这个方法，一般这种都是比较常用的方法才放到工具类中，这样大家写的方法都能轻易的调用了。 接下来就是如何创建这个工具类：在app文件夹下面，创建一个服务文件夹名字叫做Services，然后在Services文件夹中创建一个CommonUnit.php里面的内容为： 123456789&lt;?phpnamespace App\Services;/*** 通用工具服务类*/class CommonUtils&#123; //写一些通用方法&#125; 如何才能使这个类生效能在控制器中use Common就能调用到里面的方法呢：在config配置文件中打开app.php 在’providers’数组中添加：App\Providers\CommonServiceProvider::class 在’aliases’数组中添加：&#39;Common&#39; =&gt; App\Facades\Common::class 在app文件夹下面创建Facades文件夹：里面创建一个静态类：文件名称为Common.php，里面的内容为： 12345678&lt;?phpnamespace App\Facades;use Illuminate\Support\Facades\Facade;class Common extends Facade&#123; protected static function getFacadeAccessor()&#123; return 'CommonService'; &#125;&#125; 绑定功能到IOC容器:在app文件夹下面的Providers文件夹下面创建一个供应商文件，名字为：CommonServiceProvider.php里面的内容为： 12345678910111213141516&lt;?phpnamespace App\Providers;use Illuminate\Support\ServiceProvider;class CommonServiceProvider extends ServiceProvider&#123;/*** Register the application services.** @return void*/public function register()&#123; $this-&gt;app-&gt;singleton('CommonService', function () &#123; return new \App\Services\CommonUtils(); &#125;);&#125;&#125; 这样就大工告成啦！]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laravel核心概念]]></title>
    <url>%2F2019%2F11%2F14%2Flaravel-core%2F</url>
    <content type="text"><![CDATA[自动依赖注入 什么是依赖注入：通过类型提示的方式向函数传递参数。 实例1首先，定义一个类: 12/routes/web.phpclass Bar &#123;&#125; 假如我们在其他地方要使用到 Bar 提供的功能（服务），怎么办，直接传入参数即可： 1234/routes/web.phpRoute::get('bar', function(Bar $bar) &#123; dd($bar);&#125;); 访问 /bar，显示 $bar 的实例: 1Bar &#123;#272&#125; 也就是说，我们不需要先对其进行实例！如果学过 PHP 的面向对象，都知道，正常做法是这样: 123class Bar &#123;&#125;$bar = new Bar();dd($bar); 实例2可以看一个稍微复杂的例子： 123456789101112class Baz &#123;&#125;class Bar&#123; public $baz; public function __construct(Baz $baz) &#123; $this-&gt;baz = $baz; &#125;&#125;$baz = new Baz();$bar = new Bar($baz);dd($bar); 为了在 Bar 中能够使用 Baz 的功能，我们需要实例化一个 Baz，然后在实例化 Bar 的时候传入 Baz 实例。在 Laravel 中，不仅仅可以自动注入 Bar，也可以自动注入 Baz: 12345678910111213/routes/web.phpclass Baz &#123;&#125;class Bar&#123; public $baz; public function __construct(Baz $baz) &#123; $this-&gt;baz = $baz; &#125;&#125;Route::get('bar', function(Bar $bar) &#123; dd($bar-&gt;baz);&#125;); 显示结果: 1Baz &#123;#276&#125; 小结通过上述两个例子，可以看出，在 Laravel 中，我们要在类或者函数中使用其他类体用的服务，只需要通过类型提示的方式传递参数，而 Laravel 会自动帮我们去寻找响对应的依赖。 那么，Laravel 是如何完成这项工作的呢？答案就是通过服务容器。 服务容器什么是服务容器服务容器，很好理解，就是装着各种服务实例的特殊类。可以通过「去餐馆吃饭」来进行类比： 吃饭 - 使用服务，即调用该服务的地方 饭 - 服务 盘子 - 装饭的容器，即服务容器 服务员 - 服务提供者，负责装饭、上饭 实现 饭：定义Rice类： 12345678910/app/Rice.php&lt;?phpnamespace App;class Rice&#123; public function food() &#123; return '香喷喷的白米饭'; &#125;&#125; 把饭装盘子：在容器中定义了名为 rice 的变量（你也可以起其他名字，比如 rice_container），绑定了 Food 的实例： 123app()-&gt;bind('rice', function ()&#123; return new \App\Rice();&#125;); 也可以写成: 1app()-&gt;bind('rice',\App\Rice::class); 现在，吃饭了，通过 make 方法提供吃饭的服务： 1234Route::get('eat', function() &#123; return app()-&gt;make('rice')-&gt;food(); // 或者 return resolve('rice')-&gt;food()；&#125;); make 方法传入我们刚才定义的变量名即可调用该服务。访问 /eat，返回 香喷喷的白米饭。 为了方便起见，我们在路由文件中直接实现了该过程，相当于自给自足。但是服务通常由服务提供者来管理的。因此，我们可以让 AppServiceProvider 这个服务员来管理该服务： 123456/app/Providers/AppServiceProvider.phpnamespace App\Providers;public function register()&#123; $this-&gt;app-&gt;bind('rice_container',Rice::class);&#125; 更为常见的是，我们自己创建一个服务员： 1$ php artisan make:provider RiceServiceProvider 注册: 1234567/app/Providers/RiceServiceProvider.php&lt;?phpuse App\Rice;public function register()&#123; $this-&gt;app-&gt;bind('rice',Rice::class);&#125; 这里定义了 register() 方法，但是还需要调用该方法才能真正绑定服务到容器，因此，需要将其添加到 providers 数组中： 1234/config/app.php'providers' =&gt; [ App\Providers\RiceServiceProvider::class,], 这一步有何作用呢？Laravel 在启动的时候会访问该文件，然后调用里面的所有服务提供者的 register() 方法，这样我们的服务就被绑定到容器中了。 小结通过上述的例子，基本上可以理解服务容器和服务提供者的使用。当然了，我们更为常见的还是使用类型提示来传递参数： 1234use App\Rice;Route::get('eat', function(Rice $rice) &#123; return $rice-&gt;food();&#125;); 在本例中，使用自动依赖注入即可。不需要在用 bind 来手动绑定以及 make 来调用服务。那么，为什么还需要 bind 和 make 呢？ make 比较好理解，我们有一些场合 Laravel 不能提供自动解析，那么这时候手动使用 make 解析就可以了，而 bind 的学问就稍微大了点，后面将会详细说明。 门面门面是什么，我们回到刚才的「吃饭」的例子: 123Route::get('eat', function(Rice $rice) &#123; return $rice-&gt;food();&#125;); 在 Laravel，通常还可以这么写: 123Route::get('eat', function() &#123; return Rice::food();&#125;); 或者 123Route::get('eat', function() &#123; return rice()-&gt;food();&#125;); 那么，Laravel 是如何实现的呢？答案是通过门面。 门面方法实现先来实现 Rice::food()，只需要一步： 1234567891011/app/RiceFacade.php&lt;?phpnamespace App;use Illuminate\Support\Facades\Facade;class RiceFacade extends Facade&#123; protected static function getFacadeAccessor() &#123; return 'rice'; &#125;&#125; 现在，RiceFacade 就代理了 Rice 类了，这就是门面的本质了。我们就可以直接使用： 123Route::get('eat', function() &#123; dd(\App\RiceFacade::food());&#125;); 因为 \App\RiceFacade 比较冗长，我们可以用 php 提供的 class_alias 方法起个别名吧： 123456/app/Providers/RiceServiceProvider.phppublic function register()&#123; $this-&gt;app-&gt;bind('rice',\App\Rice::class); class_alias(\App\RiceFacade::class, 'Rice');&#125; 这样做的话，就实现了一开始的用法： 123Route::get('eat', function() &#123; return Rice::food();&#125;); 看上去就好像直接调用了 Rice 类，实际上，调用的是 RiceFacade 类来代理，因此，个人觉得Facade 翻译成假象比较合适。最后，为了便于给代理类命名，Laravel 提供了统一命名别名的地方： 1234/config/app.php'aliases' =&gt; [ 'Rice' =&gt; \App\RiceFacade::class,], 门面实现过程分析首先： 1Rice::food(); 因为 Rice 是别名，所以实际上执行的是: 1\App\RiceFacade::food() 但是我们的 RiceFacade 类里面并没有定义静态方法 food 啊？怎么办呢？直接抛出异常吗？不是，在 PHP 里，如果访问了不可访问的静态方法，会先调用 __callstatic,所以执行的是: 1\App\RiceFacade::__callStatic() 虽然我们在 RiceFacade 中没有定义，但是它的父类 Facade 已经定义好了： 123456789101112/vendor/laravel/framework/src/Illuminate/Support/Facades/Facade.phppublic static function __callStatic($method, $args)&#123;// 实例化 Rice &#123;#270&#125;$instance = static::getFacadeRoot();// 实例化失败，抛出异常if (! $instance) &#123; throw new RuntimeException('A facade root has not been set.');&#125;// 调用该实例的方法return $instance-&gt;$method(...$args);&#125; 主要工作就是第一步实例化: 12345public static function getFacadeRoot()&#123; return static::resolveFacadeInstance(static::getFacadeAccessor()); // 本例中：static::resolveFacadeInstance('rice')&#125; 进一步查看 resolveFacadeInstance() 方法： 123456789101112protected static function resolveFacadeInstance($name)&#123; // rice 是字符串，因此跳过该步骤 if (is_object($name)) &#123; return $name; &#125; // 是否设置了 `rice` 实例 if (isset(static::$resolvedInstance[$name])) &#123; return static::$resolvedInstance[$name]; &#125; return static::$resolvedInstance[$name] = static::$app[$name];&#125; 第一步比较好理解，如果我们之前在 RiceFacade 这样写： 1234protected static function getFacadeAccessor()&#123; return new \App\Rice;&#125; 那么就直接返回 Rice 实例了，这也是一种实现方式。主要难点在于最后这行： 1return static::$resolvedInstance[$name] = static::$app[$name]; 看上去像是在访问 $app数组，实际上是使用 数组方式来访问对象，PHP 提供了这种访问方式接口，而 Laravel 实现了该接口。也就是说，$app 属性其实就是对 Laravel 容器的引用，因此这里实际上就是访问容器上名为 rice 的对象。而我们之前学习容器的时候，已经将 rice 绑定了 Rice 类： 12345public function register()&#123; $this-&gt;app-&gt;bind('rice',\App\Rice::class); // class_alias(\App\RiceFacade::class, 'Rice');&#125; 所以，其实就是返回该类的实例了。懂得了服务容器和服务提供者，理解门面也就不难了。 辅助方法实现辅助方法的实现，更简单了。不就是把 app-&gt;make(‘rice’) 封装起来嘛： 123456789/vendor/laravel/framework/src/Illuminate/Foundation/helpers.phpif (! function_exists('rice')) &#123; function rice() &#123; return app()-&gt;make('rice'); // 等价于 return app('rice'); // 等价于 return app()['rice']; &#125;&#125; 然后我们就可以使用了: 123Route::get('eat', function() &#123; dd(rice()-&gt;food());&#125;); 小结Laravel 提供的三种访问类的方式： 依赖注入：通过类型提示的方式实现自动依赖注入 门面：通过代理来访问类 辅助方法：通过方法的方式来访问类本质上，这三种方式都是借助于服务容器和服务提供者来实现。那么，服务容器本身有什么好处呢？我们接下来着重介绍下。 IOC不好的实现我们来看另外一个例子（为了方便测试，该例子都写在路由文件中），假设有三种类型的插座：USB、双孔、三孔插座，分别提供插入充电的服务： 123456789101112131415161718class UsbsocketService&#123; public function insert($deviceName)&#123; return $deviceName." 正在插入 USB 充电"; &#125;&#125;class DoubleSocketService&#123; public function insert($deviceName)&#123; return $deviceName." 正在插入双孔插座充电"; &#125;&#125;class ThreeSocketService&#123; public function insert($deviceName)&#123; return $deviceName." 正在插入三孔插座充电"; &#125;&#125; 设备要使用插座的服务来充电： 1234567891011class Device &#123; protected $socketType; // 插座类型 public function __construct() &#123; $this-&gt;socketType = new UsbSocketService(); &#125; public function power($deviceName) &#123; return $this-&gt;socketType-&gt;insert($deviceName); &#125;&#125; 现在有一台手机要进行充电: 1234Route::get('/charge',function()&#123; $device = new Device(); return $device-&gt;power("手机");&#125;); 因为 Laravel 提供了自动依赖注入功能，因此可以写成： 123Route::get('/charge/&#123;device&#125;',function(Device $device)&#123; return $device-&gt;power("手机");&#125;); 访问 /charge/phone，页面显示 phone 正在插入 USB 充电。假如，现在有一台电脑要充电，用的是三孔插座，那么我们就需要去修改 Device 类: 1$this-&gt;socketType = new ThreeSocketService(); 这真是糟糕的设计，设备类对插座服务类产生了依赖。更换设备类型时，经常就要去修改类的内部结构。 好的实现为了解决上面的问题，可以参考「IOC」思路：即将依赖转移到外部。来看看具体怎么做。首先定义插座类型接口： 123interface SocketType &#123; public function insert($deviceName);&#125; 让每一种插座都实现该接口： 123456789101112131415161718class UsbsocketService implements SocketType&#123; public function insert($deviceName)&#123; return $deviceName." 正在插入 USB 充电"; &#125;&#125;class DoubleSocketService implements SocketType&#123; public function insert($deviceName)&#123; return $deviceName." 正在插入双孔插座充电"; &#125;&#125;class ThreeSocketService implements SocketType&#123; public function insert($deviceName)&#123; return $deviceName." 正在插入三孔插座充电"; &#125;&#125; 最后，设备中传入接口类型而非具体的类： 1234567891011class Device &#123; protected $socketType; // 插座类型 public function __construct(SocketType $socketType) // 传入接口 &#123; $this-&gt;socketType = $socketType; &#125; public function power($deviceName) &#123; return $this-&gt;socketType-&gt;insert($deviceName); &#125;&#125; 实例化的时候再决定使用哪种插座类型，这样依赖就转移到了外部： 12345Route::get('/charge',function()&#123; $socketType = new ThreeSocketService(); $device = new Device($socketType); echo $device-&gt;power("电脑");&#125;); 我们现在可以再不修改类结构的情况下，方便的更换插座来满足不同设备的充电需求: 12345Route::get('/charge',function()&#123; $socketType = new DoubleSocketService(); $device = new Device($socketType); echo $device-&gt;power("台灯");&#125;); 自动依赖注入的失效上面举的例子，我们通过 Laravel 的自动依赖注入可以进一步简化： 123Route::get('/charge',function(Device $device)&#123; echo $device-&gt;power("电脑");&#125;); 这里的类型提示有两个，一个是 Device $device，一个是 Device 类内部构造函数传入的 SocketType $sockType。第一个没有问题，之前也试过。但是第二个 SocketType 是接口，而 Laravel 会将其当成类试图去匹配 SocketType 的类并将其实例化，因此访问 /charge 时候就会报错: 1Target [SocketType] is not instantiable while building [Device]. 错误原因很明显，Laravel 没法自动绑定接口。因此，我们就需要之前的 bind 方法来手动绑定接口啦： 1234app()-&gt;bind('SocketType',ThreeSocketService::class);Route::get('/charge',function(Device $device)&#123; echo $device-&gt;power("电脑");&#125;); 现在，如果要更换设备，我们只需要改变绑定的值就可以了: 1234app()-&gt;bind('SocketType',DoubleSocketService::class);Route::get('/charge',function(Device $device)&#123; echo $device-&gt;power("台灯");&#125;); 也就是说，我们将依赖转移到了外部之后，进一步由第三方容器来管理，这就是 IOC。 契约契约，不是什么新奇的概念。其实就是上一个例子中，我们定义的接口: 123interface SocketType &#123; public function insert($deviceName);&#125; 通过契约，我们就可以保持松耦合了: 1234public function __construct(SocketType $socketType) // 传入接口而非具体的插座类型&#123; $this-&gt;socketType = $socketType;&#125; 然后服务容器再根据需要去绑定哪种服务即可: 123app()-&gt;bind('SocketType',UsbSocketService::class);app()-&gt;bind('SocketType',DoubleSocketService::class);app()-&gt;bind('SocketType',ThreeSocketService::class)]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laravel 跨域]]></title>
    <url>%2F2019%2F11%2F11%2Flaravel-cross-domain%2F</url>
    <content type="text"><![CDATA[跨域请求出于安全性的原因，浏览器会限制 Script 中的跨域请求。由于 XMLHttpRequest 遵循同源策略，所有使用 XMLHttpRequest 构造 HTTP 请求的应用只能访问自己的域名，如果需要构造跨域的请求，那么开发者需要配合浏览器做出一些允许跨域的配置。 W3C 应用工作组推荐了一种跨资源共享的机制，这种机制让 Web 应用服务器能支持跨站访问控制，从而使得安全的进行跨站数据传输成为可能，该机制通过几种方式来对原有模式进行了扩展： 响应的头部应该追加 Access-Control-Allow-Orign，用来表明哪些请求源被允许访问资源内容 浏览器会对请求源和响应中的值进行匹配验证 对于跨域的请求，浏览器会预发送一个非简单方式的请求，来判断给定资源是否准备接受跨域资源访问 服务端应用通过检查请求头部的 Orign 来判定请求是否跨域。 跨源资源共享标准跨源资源共享标准通过新增一系列 HTTP 头，让服务器能声明哪些来源可以通过浏览器访问该服务器上的资源。另外，对哪些会对服务器数据造成破坏性响应的 HTTP 请求方法（特别是 GET 以外的 HTTP 方法，或者搭配某些 MIME 类型的 POST 请求），标准强烈要求浏览器必须先以 OPTIONS 请求方式发送一个预请求（preflight request），从而获取知服务器端对跨源请求所支持 HTTP 方法。在确认服务器允许跨源请求的情况下，以实际的 HTTP 请求方法发送那个真正的请求。服务器端也可以通知客户端，是不是需要随同请求一起发送信用信息（包括 Cookies 和 HTTP 认证相关数据）。 响应头Response Header Access-Control-Allow-Origin : 指明哪些请求源被允许访问资源，值可以为 “*”，”null”，或者单个源地址。 Access-Control-Allow-Credentials : 指明当请求中省略 creadentials 标识时响应是否暴露。对于预请求来说，它表明实际的请求中可以包含用户凭证。 Access-Control-Expose-Headers : 指明哪些头信息可以安全的暴露给 CORS API 规范的 API。 Access-Control-Max-Age : 指明预请求可以在预请求缓存中存放多久。 Access-Control-Allow-Methods : 对于预请求来说，哪些请求方式可以用于实际的请求。 Access-Control-Allow-Headers : 对于预请求来说，指明了哪些头信息可以用于实际的请求中。 Origin : 指明预请求或者跨域请求的来源。 Access-Control-Request-Method : 对于预请求来说，指明哪些预请求中的请求方式可以被用在实际的请求中。 Access-Control-Request-Headers : 指明预请求中的哪些头信息可以用于实际的请求中。 请求头Request Header Origin : 表明发送请求或预请求的来源。 Access-Control-Request-Method : 在发送预请求时带该请求头，表明实际的请求将使用的请求方式。 Access-Control-Request-Headers : 在发送预请求时带有该请求头，表明实际的请求将携带的请求头。 中间件12345678910111213141516171819202122232425&lt;?php namespace App\Http\Middleware;use Closure;use Response;class EnableCrossRequestMiddleware &#123; /** * Handle an incoming request. * * @param \Illuminate\Http\Request $request * @param \Closure $next * @return mixed */ public function handle($request, Closure $next) &#123; $response = $next($request); $response-&gt;header(&apos;Access-Control-Allow-Origin&apos;, config(&apos;app.allow&apos;)); $response-&gt;header(&apos;Access-Control-Allow-Headers&apos;, &apos;Origin, Content-Type, Cookie, Accept&apos;); $response-&gt;header(&apos;Access-Control-Allow-Methods&apos;, &apos;GET, POST, PATCH, PUT, OPTIONS&apos;); $response-&gt;header(&apos;Access-Control-Allow-Credentials&apos;, &apos;true&apos;); return $response; &#125;&#125; 其中有以下需要注意的地方： 对于跨域访问并需要伴随认证信息的请求(需要携带cookie的)，需要在 XMLHttpRequest(axios中) 实例中指定 withCredentials 为 true。 这个中间件你可以根据自己的需求进行构建，如果需要在请求中伴随认证信息（包含 cookie，session）那么你就需要指定 Access-Control-Allow-Credentials 为 true, 因为对于预请求来说如果你未指定该响应头，那么浏览器会直接忽略该响应。 在响应中指定 Access-Control-Allow-Credentials 为 true 时，Access-Control-Allow-Origin 不能指定为 * 后置中间件只有在正常响应时才会被追加响应头，而如果出现异常，这时响应是不会经过中间件的。 注册这个 middleware 到 kernel 中. 分别在 protected $middleware 数组中和 protected $routeMiddleware 数组中，添加我们刚才创建的那个文件class名 和 使用 cors 这个别名. 本地开发过程中，必须在protected $middleware中添加跨域的中间件才能实现本地跨域。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP高并发支撑]]></title>
    <url>%2F2019%2F11%2F11%2Fphp-high-concurrence%2F</url>
    <content type="text"><![CDATA[简单的架构 系统集群化部署添加负载均衡层，将请求均匀打到系统层。系统层采用集群化部署多台机器，扛住初步的并发压力。 数据库分库分表 + 读写分离并发量继续增长时，我们就需要 focus 在数据库层面：分库分表、读写分离。 缓存集群引入不要盲目进行数据库扩容，数据库服务器成本昂贵，且本身就不是用来承载高并发的针对写少读多的请求，引入缓存集群，用缓存集群抗住大量的读请求 引入消息中间件集群消息中间件本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用他来支撑部分允许异步化的高并发写入是没问题的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让Google搜索到搭建在Github Pages上的博客]]></title>
    <url>%2F2019%2F10%2F11%2Fgoogle-search-console%2F</url>
    <content type="text"><![CDATA[使用Hexo博客框架和GitHub结合搭建博客是一种很不错的选择，但是如何能让博客被Google到呢？ 查看是否被收录首先查看是否已被Google收录，在Google中搜索：site:https://liwen-git.github.io/如果未查询到则继续往下看。 搜索资源提交进入Google Search Console登录之后，提交自己的博客网址： 选取HTML标记来进行验证，使用推荐方法会被sudo hexo clean命令清除： 将Search Console给的meta标签的信息添加到主题的目录下head.swig文件中，这里使用的是Next主题,其他主题也是类似的，在Hexo/themes/next/layout/_partials/head/head.swig文件中原有meta标签后面添加刚才复制的meta标签。 这时点击验证是无法通过的，需要将你的修改后的Hexo博客更新并部署到Github Pages上之后才可以验证， 12sudo hexo gsudo hexo d 验证后会提示成功，点击”继续“，先不要关闭这个页面，后面还要用。 添加站点地图站点地图(Site Map)是用来注明网站结构的文件，我们希望搜索引擎的爬虫了解我们的网站结构，以便于高效爬取内容，快速建立索引。 安装插件首先为Hexo安装hexo-generator-sitemap插件，在Hexo博客目录下运行： 1npm install hexo-generator-sitemap --save 重新编译配置Hexo的_config.yml文件，添加如下字段: 12sitemap: path: sitemap.xml 然后重新生成博客文件，运行 123sudo hexo cleansudo hexo gsudo hexo d 此时应该可以在public目录下看到sitemap.xml文件了。 添加/测试站点地图回到之前提交搜索资源的页面，在左边侧边栏找到“站点地图”,添加新的站点地图，将https://liwen-git.github.io/sitemap.xml提交并刷新，就可以看到博客的网站结构了。 如果没有什么问题的话，到这里就结束了，但是现在用Google还不能立即查到博客的内容，要等到搜索引擎下一次更新检索时才会有显示。 若站点地图无法获取如果出现了上图的情况，可能是站点地图生成有问题，可以使用XML-Sitemaps重新生成站点地图，然后下载，替换blog/public中的sitemap.xml文件。 若站点地图报错：不允许此网址可能是站点地图sitemap.xml中的所有网址是以yousite.com开头的，所以站点地图报错 解决：在blog/_config.yml中修改url为你自己的地址之后重新编译上传，重新生成sitemap.xml，重新提交即可。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>google</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homebrew切换镜像源]]></title>
    <url>%2F2019%2F09%2F24%2Fhomebrew-mirrors%2F</url>
    <content type="text"><![CDATA[切换中科大镜像源： 替换brew.git123cd /usr/local/Homebrewgit remote set-url origin https://mirrors.ustc.edu.cn/brew.git 切换回官方源： https://github.com/Homebrew/brew 替换homebrew-core.git12345cd /usr/local/Homebrew/Library/Taps/homebrew/homebrew-coregit remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.gitbrew update 切换官方源： https://github.com/Homebrew/homebrew-core 替换Homebrew Bottles源123echo &apos;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&apos; &gt;&gt; ~/.bash_profilesource ~/.bash_profile 切换回官方： 删除~/.bash_profile中的HOMEBREW_BOTTLE_DOMAIN源即可]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Laravel-ide-helper]]></title>
    <url>%2F2019%2F09%2F24%2Flaravel-ide-helper%2F</url>
    <content type="text"><![CDATA[安装安装命令： 12# 如果只想在开发环境安装请加上 --devcomposer require --dev barryvdh/laravel-ide-helper 在 「config/app.php」的 「providers」数组中加入 1Barryvdh\LaravelIdeHelper\IdeHelperServiceProvider::class, 如果你的 Laravel 版本小于 5.5 的话，请注册服务提供者，否则请忽略 如果你只在开发环境中安装「larave-ide-helper」，那么可以在「app/Providers/AppServiceProvider.php」的「register」方法中写入下面代码： 1234567public function register()&#123; if ($this-&gt;app-&gt;environment() !== &apos;production&apos;) &#123; $this-&gt;app-&gt;register(\Barryvdh\LaravelIdeHelper\IdeHelperServiceProvider::class); &#125; // ...&#125; 导出配置文件,即：config/ide-helper.php（如果默认配置就满足需求了，也可以忽略这一步） 1php artisan vendor:publish --provider=&quot;Barryvdh\LaravelIdeHelper\IdeHelperServiceProvider&quot; --tag=config 好了，接下去可以愉快的使用了 自动为 Laravel 的 Facades 生成注释在命令行下运行 1php artisan ide-helper:generate 注: 如果存在文件 「bootstrap/compiled.php」 需要先删除， 可以在生成文当前运行 php artisan clear-compiled。 自动为模型生成注释 多个模型：直接 php artisan ide-helper:models，当然也可以 php artisan ide-helper:models -W 单个模型：这个不能按照 github 上的 readme 来，坑爹。必须指明具体的类全名：php artisan ide-helper:models &quot;App\Http\Models\User&quot;。 为所有模型生成注释 php artisan ide-helper:models, 这时会出现询问： 1Do you want to overwrite the existing model files? Choose no to write to _ide_helper_models.php instead? (Yes/No): (yes/no) [no]: 输入 yes 则会直接在模型文件中写入注释，否则会生成「_ide_helper_models.php」文件。建议选择 yes，这样在跟踪文件的时候不会跳转到「_ide_helper_models.php」文件，不过这么做最好对模型文件做个备份，至少在生成注释之前用 git 控制一下版本，以防万一。 提示： 为模型生成字段信息必须在数据库中存在相应的数据表，不要生成 migration 还没运行 migrate 的时候就生成注释，这样是得不到字段信息的。 自动为链式操作注释这是什么意思呢？举个例子，在 migration 文件中经常可以看见这样的代码： 1$table-&gt;string(&apos;email&apos;)-&gt;unique(); 这时候就算调用过了 php artisan ide-helper:generate，在调用像 -&gt;unique() 这样的链式操作的时候也无法实现代码提示，这时候需要将配置文件「如果导出的话」&#39;include_fluent&#39; =&gt; false 修改为 &#39;include_fluent&#39; =&gt; true，重新运行 php artisan ide-helper:generate。试试效果吧！ 生成 .phpStorm.meta.php可以生成一个PhpStorm meta 文件去支持工厂模式. 对于 Laravel, 这意味着我们可以让 PhpStorm 理解我们从 IoC 容器中解决了什么类型的对象。例如：事件将返回一个「Illuminate\Events\Dispatcher」对象，利用 meta 文件您可以调用 app(‘events’) 并且它将自动完成 Dispatcher 的方法。 12345678app(&apos;events&apos;)-&gt;fire();\App::make(&apos;events&apos;)-&gt;fire();/** @var \Illuminate\Foundation\Application $app */$app-&gt;make(&apos;events&apos;)-&gt;fire();// When the key is not found, it uses the argument as class nameapp(&apos;App\SomeClass&apos;); 提示：您可能需要重启 Phpstorm 使 .phpStorm.meta.php 文件生效。 自动运行 generate想在依赖包更新是自动更新注释，可以在 composer.json 文件中做如下配置： 1234567&quot;scripts&quot;:&#123; &quot;post-update-cmd&quot;: [ &quot;Illuminate\\Foundation\\ComposerScripts::postUpdate&quot;, &quot;php artisan ide-helper:generate&quot;, &quot;php artisan ide-helper:meta&quot; ]&#125; 提示：如果只在 dev 环境下部署 ide helper 还是不要这么做了，防止在生产环境中报错导致不必要的麻烦。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TortoiseGit 和 Git 配置使用同一私钥]]></title>
    <url>%2F2019%2F09%2F24%2Ftortoisegit-key%2F</url>
    <content type="text"><![CDATA[tortoisegit 和 git 私钥格式 tortoisegit 默认使用putty格式的私钥（id_rsa.ppk）： git 默认使用openssh格式的私钥 (id_ras)： 首先通过ssh-keygen命令生产通用的id_ras.pub公钥 和 id_rsa的git私钥1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 然后可以在用户主目录里找到.ssh目录，里面有 id_rsa 和 id_rsa.pub 两个文件，这两个就是 SSH Key 的秘钥对，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 使用puttyGen将git的openssh格式秘钥转化为putty格式 运行PuTTYGen，在Conversions菜单中点击Import key，选择ssh-keygen生成的私钥文件所在位置，比如id_rsa文件。 点击Save private key按钮，将其保存为.ppk文件。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitLab-ce搭建]]></title>
    <url>%2F2019%2F09%2F24%2Fgitlab-ce%2F</url>
    <content type="text"><![CDATA[安装并配置必要的依赖关系123sudo yum install -y curl policycoreutils-python openssh-server croniesudo lokkit -s http -s ssh 安装Postfix以发送通知电子邮件 123sudo yum install postfixsudo service postfix startsudo chkconfig postfix on 添加gitLab仓库到yum源，并安装123curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bashsudo EXTERNAL_URL=&quot;http://gitlab.example.com&quot; yum -y install gitlab-ce EXTERNAL_URL是设置用什么域名访问你的gitlab，此时也可以直接yum install gitlab-ce。安装完成后再修改配置文件/etc/gitlab/gitlab.rb 运行配置命令1sudo gitlab-ctl reconfigure 这样就可以访问你的gitLab了。 修改nginx端口（使用gitLab内置nginx） 修改nginx端口 1234567vim /etc/gitlab/gitlab.rbnginx[&apos;listen_port&apos;] = 82 #默认值即80端口 nginx[&apos;listen_port&apos;] = nilvim /var/opt/gitlab/nginx/conf/gitlab-http.conflisten *:82; #默认值listen *:80; 修改unicorn端口(可以不修改) 1234567vim /etc/gitlab/gitlab.rbunicorn[&apos;port&apos;] = 8082 #原值unicorn[&apos;port&apos;] = 8080vim /var/opt/gitlab/gitlab-rails/etc/unicorn.rblisten &quot;127.0.0.1:8082&quot;, :tcp_nopush =&gt; true #原值listen &quot;127.0.0.1:8080&quot;, :tcp_nopush =&gt; true 保存配置并重启 123sudo gitlab-ctl reconfiguresudo gitlab-ctl restartsudo gitlab-ctl status 访问 ip:82 成功。 gitLab服务命令 说明 常用命令 重新加载配置， 每次修改/etc/gitlab/gitlab.rb文件之后执行 sudo gitlab-ctl reconfigure 启动 sudo gitlab-ctl start 停止 sudo gitlab-ctl stop 重启 sudo gitlab-ctl restart 查看状态 sudo gitlab-ctl status 查看所有日志 sudo gitlab-ctl tail 查看 nginx 访问日志 sudo gitlab-ctl tail nginx/gitlab_acces.log 查看 postgresql 日志 sudo gitlab-ctl tail postgresql 检查gitLab状态 gitlab-rake gitlab:check 检查环境和配置是否正确 gitlab-rake gitlab:env:info 清除缓存 gitlab-rake cache:clear 相关文件位置 内容 位置 日志 /var/log/gitlab gitlab_url /opt/gitlab/embedded/service/gitlab-shell/config.yml nginx配置 /var/opt/gitlab/nginx/conf/gitlab-http.conf gitlab主配置文件 /etc/gitlab/gitlab.rb ssh路径url配置文件 /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml gitLab修改ssh默认端口 vim /etc/gitlab/gitlab.rb找到：gitlab_rails[‘gitlab_shell_ssh_port’] = 22 修改为：【你服务器ssh登录的端口】 重新编译：gitlab-ctl stopgitlab-ctl reconfiguregitlab-ctl start 疑难杂症 问题：访问报500错误原因：运行gitlab-rake gitlab:check，发现gitlab-shell self-check failed；再运行sudo gitlab-ctl restart，发现redis出现timeout；解决：找不到原因，暂时方法是 ps -ef | grep runsv 找到redis 的父级进程，kill -9 xxxx 全部杀掉后会自动拉起。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[composer autoload]]></title>
    <url>%2F2019%2F09%2F19%2Fcomposer-autoload%2F</url>
    <content type="text"><![CDATA[对于类库的自动加载，Composer 生成了一个 vendor/autoload.php 文件。引入这个文件，就能得到一个免费的自动加载支持。 本文主要是介绍如何利用 Composer 自带的自动加载机制，加载本地自定义的包（即不是来自于 packagist）。 使用在 composer.json 文件中的 autoload 字段中添加自己的 autoloader。 框架结构1234567891011121314151617First/ |---examples/ |---get.php |---src/ |---Curl.php |---vendor/ |---composer/ |---autoload.php |---composer.json |---classmap |---lib |---src |---ext |---common | |---functions |---system |---functions 介绍PSR-4自动加载方式12345678&#123; &quot;autoload&quot;: &#123; &quot;psr-4&quot;: &#123; &quot;First\\&quot;: &quot;src/&quot;, &quot;Temp\\&quot;: &quot;lib/&quot; &#125; &#125;&#125; 上面的代码采用 PSR-4 规范，该规范包含了 PHP 最新的自动加载标准，它要求必须使用 namespace （命名空间）的方式。 First\ 表示命名空间，必须以 \ 结尾，避免相似的命名空间导致冲突，若包含子命名空间，可以这样表示：First\Second\。 src/ 表示命名空间所在目录为与 Composer 的 vendor 目录同级的 src 目录，如上图框架结构所示。 如果需要在多个目录下搜索相同的命名前缀，可以用一个数组提供： 1234567&#123; &quot;autoload&quot;: &#123; &quot;psr-4&quot;: &#123; &quot;First\\&quot;: [&quot;src/&quot;, &quot;lib/&quot;] &#125; &#125;&#125; 修改完 composer.json 的 autoload 字段后需要更新一下 Composer 的自动加载类： 1composer dump-autoload 对应 Curl.php 的命名空间如下表示： 1234567&lt;?phpnamespace First;class Curl&#123;&#125; 引用 Curl.php 的方式如下： 12345678&lt;?phprequire &apos;../vendor/autoload.php&apos;;use First\Curl;$curl = new Curl();. . .. . . classmap模式懒加载，扫描目录下的所有类文件，支持递归扫描， 生成对应的类名=&gt;路径的映射，当载入需要的类时直接取出路径，速度最快composer.json的autoload中添加： 1234// classmap 扫描目录下的所有类文件 生成对应的类名=&gt;路径的映射&quot;classmap&quot;: [ &quot;classmap/lib/src/&quot;] files模式自动载入的文件，主要用来载入一些没办法懒加载的公共函数composer.json的autoload中添加： 123456// 扫描目录下的所有文件生成 hash =&gt; 路径的映射 运行时实时加载// 主要用来载入工具函数&quot;files&quot;: [ &quot;ext/common/functions.php&quot;, &quot;ext/system/functions.php&quot;]]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>composer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[composer镜像]]></title>
    <url>%2F2019%2F09%2F19%2Fcomposer-images%2F</url>
    <content type="text"><![CDATA[启用镜像服务的方式有两种：系统全局配置 ：即将配置信息添加到composer的全局配置文件config.json中。单个项目配置 ：将配置信息添加到某个项目的composer.json文件中 修改composer 的全局配置文件打开命令行（windows用户）或控制台（Linux、Mac用户）并执行如下命令： 1234--- phpcomposer ---composer config -g repo.packagist composer https://packagist.phpcomposer.com--- aliyun 推荐 ---composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ 修改当前项目的composer.json配置文件：进入项目根目录（也就是composer.json文件所在目录），执行如下命令： 1composer config repo.packagist composer https://packagist.phpcomposer.com 上述命令将会在当前项目中的composer.json文件的末尾自动添加镜像的配置信息（你自己也可以手动添加）： 123456&quot;repositories&quot;: &#123; &quot;packagist&quot;: &#123; &quot;type&quot;: &quot;composer&quot;, &quot;url&quot; : &quot;https://packagist.phpcomposer.com&quot; &#125;&#125; 查看composer镜像地址 1composer config -gl 取消配置 1composer config -g --unset repos.packagist]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>composer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[composer简介]]></title>
    <url>%2F2019%2F09%2F19%2Fcomposer%2F</url>
    <content type="text"><![CDATA[PHP 用来管理依赖（dependency）关系的工具。你可以在自己的项目中声明所依赖的外部工具库（libraries），Composer 会帮你安装这些依赖的库文件。 简单解释 composer install - 如有 composer.lock 文件，直接安装，否则从 composer.json 安装最新扩展包和依赖； composer update - 从 composer.json 安装最新扩展包和依赖； composer update vendor/package - 从 composer.json 或者对应包的配置，并更新到最新； composer require new/package - 添加安装 new/package , 可以指定版本，如： composer require new/package ~2.5。 介绍几个日常生产流程 新项目流程 运行 composer install ，安装扩展包并生成 composer.lock ； 提交 composer.lock 到代码版本控制器中，如：git; 项目协作者安装现有项目 克隆项目后，根目录下直接运行 composer install 从 composer.lock 中安装 指定版本 的扩展包以及其依赖； 此流程适用于生产环境代码的部署。 为项目添加新扩展包 使用 composer require vendor/package 添加扩展包； 提交更新后的 composer.json 和 composer.lock 到代码版本控制器中，如：git; 关于 composer.lock 文件 composer.lock 文件里保存着对每一个代码依赖的版本记录（见下图），提交到版本控制器中，并配合 composer install 使用，保证了团队所有协作者开发环境、线上生产环境中运行的代码版本的一致性。 关于扩展包的安装方法那么，准备添加一个扩展包，install, update, require 三个命令都可以用来安装扩展包，选择哪一个才是正确的呢？答案是：使用 composer require 命令 另外，在手动修改 composer.json 添加扩展包后， composer update new/package 进行指定扩展包更新的方式，也可以正确的安装，不过不建议使用这种方法，因为，一旦你忘记敲定后面的扩展包名，就会进入万劫不复的状态，别给自己留坑呀。 上面的概念不论对新手或者老手来说，都比较混淆，主要记住这个概念： 原有项目新添加扩展的，都使用 composer require new/package 这种方式来安装。 更新指定扩展到指定版本可以指定版本号： 1composer require &quot;foo/bar:1.0.0&quot; composer其他 composer 自身升级：composer self-update composer 回滚：composer self-update –rollback composer中require 和 require-dev的区别：前者用于声明项目发布版本的依赖包，后者用于声明项目开发或测试中依赖的包。 composer版本号 前置~和^符号的区别~和^的意思很接近，在x.y的情况下是一样的都是代表x.y &lt;= 版本号 &lt; (x+1).0，但是在版本号是x.y.z的情况下有区别，举个例子吧： ~1.2.3 代表 1.2.3 &lt;= 版本号 &lt; 1.3.0 ^1.2.3 代表 1.2.3 &lt;= 版本号 &lt; 2.0.0]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>composer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[govendor]]></title>
    <url>%2F2019%2F09%2F18%2Fgovendor%2F</url>
    <content type="text"><![CDATA[安装go get -u github.com/kardianos/govendor 初始化在项目根目录下执行以下命令进行vendor初始化：govendor init 项目根目录下即会自动生成 vendor 目录和 vendor.json 文件 常用命令 将 已被引用 且在 $GOPATH 下的所有包复制到vendor目录govendor add +external 仅从 $GOPATH 中复制指定包govendor add gopkg.in/yaml.v2 列出代码中所有被引用到的包及其状态govendor list 从远程仓库添加或更新某个包(不会在 $GOPATH 也存一份)govendor fetch golang.org/x/net/context 安装指定版本的包 123govendor fetch golang.org/x/net/context@a4bbce9fcae005b22ae5443f6af064d80a6f5a55govendor fetch golang.org/x/net/context@v1 # Get latest v1.*.* tag or branch.govendor fetch golang.org/x/net/context@=v1 # Get the tag or branch named &quot;v1&quot;. 删除vendor中已有 但是代码中未使用的包govendor remove +unused]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>govendor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisor 维护 golang 进程]]></title>
    <url>%2F2019%2F09%2F18%2Fgo-supervisor%2F</url>
    <content type="text"><![CDATA[代码准备工作在代码目录执行go build或者go install来生成可执行文件 注意：如果使用go install生成在bin目录下的可执行文件，需要注意代码中的日志目录问题 安装supervisor官网地址：http://supervisord.org/index.html 12sudo yum install python-setuptoolssudo easy_install supervisor 或者 sudo pip install supervisor 安装成功后，生成配置文件 1sudo echo_supervisord_conf &gt; /etc/supervisord.conf 添加配置文件新建一个文件夹专门放置.conf文件 在/etc/下新建supervisor_conf_file文件夹，并在该文件加下新建gin_api.conf： 12345678910111213141516[program:gin_api]user=rootcommand=/home/go/src/gin_api/gin_api #go可执行文件路劲autostart=trueautorestart=truestartsecs=10stdout_logfile=/root/supervisor_log/gin_api.log #标准输出log，得去相应的目录下新建logstdout_logfile_maxbytes=1MBstdout_logfile_backups=10stdout_capture_maxbytes=1MBstderr_logfile=/root/supervisor_log/gin_api_err.log #错误输出log，得去相应的目录下新建logstderr_logfile_maxbytes=1MBstderr_logfile_backups=10stderr_capture_maxbytes=1MBstopsignal=INT[supervisord] 说明： 12345command：表示运行的命令，我这是填写的我demo安装包的原则路径。autostart：表示是否跟随supervisor一起启动。autorestart：如果该程序挂了，是否重新启动。stdout_logfile：终端标准输出重定向文件。stderr_logfile：终端错误输出重定向文件。 修改配置文件编辑 /etc/supervisord.conf，将文件最下面的 12;[include];files = relative/directory/*.ini 修改为： 12[include]files = /etc/supervisor_conf_file/*.conf 启动supervisord1sudo /usr/bin/supervisord -c /etc/supervisord.conf 若报如下错误： 1Error: Another program is already listening on a port that one of our HTTP servers is configured to use. Shut this program down first before starting supervisord. 解决办法： 12find / -name supervisor.sockunlink /xxx/supervisor.sock 之后再次执行启动命令。 执行命令查看gin_api服务是否启动成功： 1sudo supervisorctl status 输出： 1gin_api RUNNING pid 7648, uptime 0:09:57 ps: 123456789101112[root@accapp /home/go/src/gin_api]# supervisorctl gin_api RUNNING pid 7648, uptime 0:02:39supervisor&gt; helpdefault commands (type help &lt;topic&gt;):=====================================add exit open reload restart start tail avail fg pid remove shutdown status update clear maintail quit reread signal stop versionsupervisor&gt; exit[root@accapp /home/go/src/gin_api]# 相关命令 停止supervisor(子进程也会被停止) 1supervisorctl shutdown 把 supervisor 相关的进程都杀掉 1kill -9 $(ps -ef|grep supervisor | awk &apos;&#123;print $2&#125;&apos;) 解决unix:///tmp/supervisor.sock no such file的问题原因：tmp目录中的文件被Linux自动清除了 新建目录和修改权限 12345sudo mkdir -p /var/supervisor_tmp/runsudo mkdir -p /var/supervisor_tmp/logsudo chmod 777 /var/supervisor_tmp/runsudo chmod 777 /var/supervisor_tmp/log 修改/etc/supervisor.conf配置文件把所有的/tmp路径修改掉：/tmp/supervisor.sock 改成 /var/supervisor_tmp/run/supervisor.sock/tmp/supervisord.log 改成 /var/supervisor_tmp/log/supervisor.log/tmp/supervisord.pid 改成 /var/supervisor_tmp/run/supervisor.pid 重启杀掉supervisor进程和子进程，再启动supervisor]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[provide 和 inject]]></title>
    <url>%2F2019%2F09%2F18%2Fprovide-and-inject%2F</url>
    <content type="text"><![CDATA[官网解释：provider/inject provider/inject：简单的来说就是在父组件中通过provider来提供变量，然后在子组件中通过inject来注入变量。 需要注意的是这里不论子组件有多深，只要调用了inject那么就可以注入provider中的数据。而不是局限于只能从当前父组件的prop属性来获取数据。 示例： first：定义一个parent component, 在这里我们在父组件中provide for这个变量。 12345678910111213141516171819&lt;template&gt; &lt;div&gt; &lt;childOne&gt;&lt;/childOne&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import childOne from &apos;../components/test/ChildOne&apos; export default &#123; name: &quot;Parent&quot;, provide() &#123; return &#123; for: &quot;demo&quot; &#125; &#125;, components:&#123; childOne &#125; &#125; second 定义一个子组件 12345678910111213141516171819202122&lt;template&gt; &lt;div&gt; &#123;&#123;demo&#125;&#125; &lt;childtwo&gt;&lt;/childtwo&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import childtwo from &apos;./ChildTwo&apos; export default &#123; name: &quot;childOne&quot;, inject: [&apos;for&apos;], data() &#123; return &#123; demo: this.for &#125; &#125;, components: &#123; childtwo &#125; &#125;&lt;/script&gt; third 定义另一个子组件 1234567891011121314151617&lt;template&gt; &lt;div&gt; &#123;&#123;demo&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: &quot;&quot;, inject: [&apos;for&apos;], data() &#123; return &#123; demo: this.for &#125; &#125; &#125;&lt;/script&gt; 在2个子组件中我们使用jnject注入了provide提供的变量for，并将它提供给了data属性。 运行结果是 demo demo 从上面这个例子可以看出，只要在父组件中调用了，那么在这个父组件生效的生命周期内，所有的子组件都可以调用inject来注入父组件中的值。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keep-alive的作用]]></title>
    <url>%2F2019%2F09%2F18%2Fkeep-alive%2F</url>
    <content type="text"><![CDATA[问题描述在vue项目中,难免会有列表页面或者搜索结果列表页面,点击某个结果之后,返回回来时,如果不对结果页面进行缓存,那么返回列表页面的时候会回到初始状态,但是我们想要的结果是返回时这个页面还是之前搜索的结果列表,这时候就需要用到vue的keep-alive技术了.本人遇到的问题是element切换tab的时候，页面不会缓存，所以需要使用keep-alive。 keep-alive 简介keep-alive 是 Vue 内置的一个组件，可以使被包含的组件保留状态，或避免重新渲染。 用法也很简单： 12345&lt;keep-alive&gt; &lt;component&gt; &lt;!-- 该组件将被缓存！ --&gt; &lt;/component&gt;&lt;/keep-alive&gt; props include - 字符串或正则表达，只有匹配的组件会被缓存 exclude - 字符串或正则表达式，任何匹配的组件都不会被缓存 1234567// 组件 aexport default &#123; name: &apos;a&apos;, data () &#123; return &#123;&#125; &#125;&#125; 12345&lt;keep-alive include=&quot;a&quot;&gt; &lt;component&gt; &lt;!-- name 为 a 的组件将被缓存！ --&gt; &lt;/component&gt;&lt;/keep-alive&gt;可以保留它的状态或避免重新渲染 12345&lt;keep-alive exclude=&quot;a&quot;&gt; &lt;component&gt; &lt;!-- 除了 name 为 a 的组件都将被缓存！ --&gt; &lt;/component&gt;&lt;/keep-alive&gt;可以保留它的状态或避免重新渲染 配合vue-router共同使用但实际项目中,常需要配合vue-router共同使用. router-view 也是一个组件，如果直接被包在 keep-alive 里面，所有路径匹配到的视图组件都会被缓存： 12345&lt;keep-alive&gt; &lt;router-view&gt; &lt;!-- 所有路径匹配到的视图组件都会被缓存！ --&gt; &lt;/router-view&gt;&lt;/keep-alive&gt; 如果只想 router-view 里面某个组件被缓存，怎么办？ 增加 router.meta 属性 123456789101112131415161718// routes 配置export default [ &#123; path: &apos;/&apos;, name: &apos;home&apos;, component: Home, meta: &#123; keepAlive: true // 需要被缓存 &#125; &#125;, &#123; path: &apos;/:id&apos;, name: &apos;edit&apos;, component: Edit, meta: &#123; keepAlive: false // 不需要被缓存 &#125; &#125;] 12345678&lt;keep-alive&gt; &lt;router-view v-if=&quot;$route.meta.keepAlive&quot;&gt; &lt;!-- 这里是会被缓存的视图组件，比如 Home！ --&gt; &lt;/router-view&gt;&lt;/keep-alive&gt;&lt;router-view v-if=&quot;!$route.meta.keepAlive&quot;&gt; &lt;!-- 这里是不被缓存的视图组件，比如 Edit！ --&gt;&lt;/router-view&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[laravel篇]]></title>
    <url>%2F2019%2F08%2F08%2Flaravel-question%2F</url>
    <content type="text"><![CDATA[1. 简述laravel的生命周期 导入composer自动加载功能，加载框架类库 引入laravel应用程序实例App 启动容器 注册http处理器 注册console处理器 注册异常处理器 启动http处理器，接收request请求 以管道的设计模式，执行部分（全局）中间件 路由解析调度 实例化当前控制器 执行web中间件 执行控制器中间件 执行控制器操作 返回response 结束框架 Laravel采用了单一的入口模式，应用的所有请求入口都是public/index.php文件。 注册类文件自动加载器：laravel通过composer进行依赖管理，无需开发者手动导入各种类文件，而由自动加载器自行导入。 创建服务容器：从bootstrap/app.php文件中取得laravel应用实例$app（服务容器） 创建HTTP/Console内核：传入的请求会被发送给HTTP内核或者console内核进行处理 载入服务提供者至容器：在内核引导启动的过程中最重要的动作之一就是载入服务提供者到你的应用，服务提供者负责引导启动框架的全部各种组件，例如数据库、队列、验证器以及路由组件 分发请求：一旦应用完成引导和所有服务提供者都注册完成，Request 将会移交给路由进行分发。路由将分发请求给一个路由或控制器，同时运行路由指定的中间件 2. 服务提供者是什么？ 服务提供者是所有laravel应用程序引导启动的中心，laravel的核心服务器、注册服务容器绑定、事件监听、中间件、路由注册以及我们的应用程序都是由服务提供者引导启动的。 3. IoC容器是什么？ IoC（Inversion of Control）译为 「控制反转」，也被叫做「依赖注入」(DI)。什么是「控制反转」？对象 A 功能依赖于对象 B，但是控制权由对象 A 来控制，控制权被颠倒，所以叫做「控制反转」，而「依赖注入」是实现 IoC 的方法，就是由 IoC 容器在运行期间，动态地将某种依赖关系注入到对象之中。 其作用简单来讲就是利用依赖关系注入的方式，把复杂的应用程序分解为互相合作的对象，从而降低解决问题的复杂度，实现应用程序代码的低耦合、高扩展。 Laravel 中的服务容器是用于管理类的依赖和执行依赖注入的工具。 4. Facades 是什么？ Facades（一种设计模式，通常翻译为外观模式）提供了一个”static”（静态）接口去访问注册到 IoC 容器中的类。提供了简单、易记的语法，而无需记住必须手动注入或配置的长长的类名。此外，由于对 PHP 动态方法的独特用法，也使测试起来非常容易。 5. Contract 是什么？ Contract（契约）是 laravel 定义框架提供的核心服务的接口。Contract 和 Facades 并没有本质意义上的区别，其作用就是使接口低耦合、更简单。 6. 谈谈 Laravel 和 YII 框架的区别 在 YII 框架中的路由是通过书写 Controller、Action 间接定义路由，而 Laravel 中是在 route 路由文件中直接定义路由入口 Laravel 提供 ORM 对象关系映射，使读写数据库的操作更加简单 Laravel 提供更多的 Artisan 命令和脚手架开发 Laravel 的 Composer 扩展包比 Yii 框架更多，开发更加高效 7. 谈谈 Laravel 和 TP5 框架的区别 提交数据的方式：laravel在提交表单的时候需要在表单中加入{csrc_field}来防止跨域攻击；TP不会。 路由：laravel必须先定义，再使用；TP在配置文件中开启路由。 中间件：laravel中间件，就是http请求到达之前经过的层，通过中间件我们可以验证用户是否登录等一些通用操作。 操作数据库的方式：都可以使用实例化（建立相对应的模型类）和DB::table来操作数据库。使用原生查询时不太一样，laravel使用Db::操作(‘原生sql’)，TP使用Db::query(‘原生sql’)。 Laravel升级十分简易，而TP大版本的升级要重构代码。 条件判断语句书写方式的差异： laravel框架里 if else判断语句和foreach语句 书写时必须以@if开头 以@endif结尾,如果没有则报语法错误,@foreach @endforeach同理；而TP框架则和PHP语法规则使用方式一致直接ifesle语句判断和foreach循环遍历。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>laravel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx和php-fpm结合]]></title>
    <url>%2F2019%2F08%2F08%2Fnginx-and-php-fpm%2F</url>
    <content type="text"><![CDATA[Nginx不只有处理http请求的功能，还能做反向代理。 Nginx通过反向代理功能将动态请求转向后端Php-fpm。 在 Linux 上，nginx 与 php-fpm 的通信有 tcp socket 和 unix socket 两种方式。 tcp socket 的优点是可以跨服务器，当 nginx 和 php-fpm 不在同一台机器上时，只能使用这种方式。 Unix socket 又叫 IPC(inter-process communication 进程间通信) socket，用于实现同一主机上的进程间通信，这种方式需要在 nginx配置文件中填写 php-fpm 的 socket 文件位置。 两种方式的数据传输过程如下图所示： 二者的不同： 由于 Unix socket 不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程。所以其效率比 tcp socket 的方式要高，可减少不必要的 tcp 开销。不过，unix socket 高并发时不稳定，连接数爆发时，会产生大量的长时缓存，在没有面向连接协议的支撑下，大数据包可能会直接出错不返回异常。而 tcp 这样的面向连接的协议，可以更好的保证通信的正确性和完整性。 下面我们来配置一个全新的Nginx+Php-fpm 配置nginx.conf文件进入nginx目录下，编辑nginx.conf文件。如图，在nginx.conf最后一行，添加include文件 添加对应的server进入上面的include的路径，添加一个serverunix socket 方式 修改fastcgi_pass如下fastcgi_pass unix:/usr/run/php-fpm.sock 下面我们解释下配置项的含义 123456789101112131415161718server &#123; listen 80; #监听80端口，接收http请求 server_name www.example.com; #就是网站地址 root /usr/local/etc/nginx/www/huxintong_admin; # 准备存放代码工程的路径 #路由到网站根目录www.example.com时候的处理 location / &#123; index index.php; #跳转到www.example.com/index.php autoindex on; &#125; #当请求网站下php文件的时候，反向代理到php-fpm location ~ \.php$ &#123; include /usr/local/etc/nginx/fastcgi.conf; #加载nginx的fastcgi模块 fastcgi_intercept_errors on; fastcgi_pass 127.0.0.1:9000; #nginx fastcgi进程监听的IP地址和端口 # fasrcgi_pass /usr/run/php-fpm.sock #unix socket 连接方式 &#125;&#125; 下面我们启用php的php-fpm来处理这个请求打开php-fpm.conf文件，我们看到如下配置：unix socket 方式 修改php-fpm.conf如下listen = /usr/run/php-fpm.sock 即：php-fpm模块监听127.0.0.1:9000端口 或者 php-fpm.sock文件，等待请求到来去处理。 注意：在使用 unix socket 方式连接时，由于 socket 文件本质上是一个文件，存在权限控制的问题，所以需要注意 nginx 进程的权限与 php-fpm 的权限问题，不然会提示无权限访问。（在各自的配置文件里设置用户）]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac + Hexo + GitHub + Next 搭建博客]]></title>
    <url>%2F2019%2F07%2F09%2Fmac-hexo%2F</url>
    <content type="text"><![CDATA[1. 安装node.js 和 gitmac上使用brew安装node 和 git测试安装是否成功： 12345node -vnpm -v # 同时可以配置下npm镜像：npm config set registry https://registry.npm.taobao.org# 配置后可通过下面方式来验证是否成功 npm config get registry 或 npm info expressgit --versoin 2. 安装Hexo安装时注意权限问题，加上sudo，其中-g表示全局安装 1sudo npm install -g hexo-cli npm全局安装的包的存储路径是/usr/local/lib/node_modules/ 3. 博客初始化创建博客的文件夹，并进入 12sudo mkdir blogcd blog 初始化博客 1sudo hexo init 安装依赖 12## 安装时 node-pre-gyp 报错，执行如下命令可以解决sudo npm install --unsafe-perm 执行下述命令生成本地网页文件并开启服务器，然后通过http://localhost:4000查看本地博客 12sudo hexo gsudo hexo s 或者 sudo hexo s -p 4000 4. 上传github在github中新建仓库，名称必须为 user.github.io，如：Liwen-Git.github.io 配置hexo的_config.yml文件 12cd blogsudo vim _config.yml 在文档的最后部分，将deploy配置如下 1234deploy: type: git repository: https://github.com/Liwen-Git/Liwen-Git.github.io.git branch: master 注意type、repository、branch后均有空格。通过如下命令在blog下生成静态文件并上传到服务器 1234sudo hexo g# 出错执行 sudo npm install hexo --savesudo hexo d# 出错执行 sudo npm install hexo-deployer-git --save 执行hexo d 时会提示输入GitHub账号用户名和密码，执行成功之后通过 https://liwen-git.github.io/ 访问博客 5. 更换Next主题推荐使用hexo-theme-next主题在blog目录下执行： 1sudo git clone https://github.com/theme-next/hexo-theme-next.git themes/next 修改blog目录下_config.yml里的theme名称为：next其他的，如title: 李子园、language: zh-CN、都可以自己配置 执行如下命令（每次部署文章的步骤） 12sudo hexo g //生成缓存和静态文件sudo hexo d //重新部署到服务器 当本地博客部署到服务器后，网页端无变化时可以采用下述命令 1sudo hexo clean //清楚缓存文件(db.json)和已生成的静态文件(public) 6. 配置next主题修改next主题的配置文件_config.yml主题为：Gemini（打开注释） 修改next主题配置文件，在menu处，打开tags和categories的注释 创建tag页面1sudo hexo new page &quot;tags&quot; 然后再blog/sources中会多了一个tags文件夹，修改其中的index.md文件，type修改为tags 12345---title: tagsdate: 2019-07-08 23:15:25type: &quot;tags&quot;--- 创建categories页面1sudo hexo new page &quot;categories&quot; 然后再blog/sources中会多了一个categories文件夹，修改其中的index.md文件，type修改为categories 12345---title: categoriesdate: 2019-07-08 23:15:25type: &quot;categories&quot;--- 7. 安装搜索功能 Local Search在next的_config.yml文件中修改Local Search的enable: true在根目录下执行以下命令： 12sudo npm install hexo-generator-search --savesudo npm install hexo-generator-searchdb --save 在根目录的_config.yml文件中添加 12345search: path: search.xml field: post format: html limit: 10000 8. 新建文章命令： 1sudo hexo new post 文件名可以不是文章名 给文章添加属性 12345678910---title: Mac + Hexo + GitHub + Next 搭建博客date: 2019-07-08 12:12:57categories: - mactags:- hexo- next- 表单验证--- 站点首页不显示文章全文，文章摘要设置这里我们可以通过在文章使用&lt;!-- more --&gt;标志来精确控制文章的摘要预览]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2019%2F07%2F08%2Fphp-design-patterns%2F</url>
    <content type="text"><![CDATA[策略模式策略模式是对象的行为模式，用意是对一组算法的封装。动态的选择需要的算法并使用。 策略模式指的是程序中涉及决策控制的一种模式。策略模式功能非常强大，因为这个设计模式本身的核心思想就是面向对象编程的多形性思想。 策略模式的三个角色： 抽象策略角色 具体策略角色 环境角色（对抽象策略角色的引用） 实现步骤： 定义抽象角色类（定义好各个实现的共同抽象方法） 定义具体策略类（具体实现父类的共同方法） 定义环境角色类（私有化申明抽象角色变量，重载构造方法，执行抽象方法） 就在编程领域外，有许多例子是关于策略模式的。例如： 如果我需要在早晨从家里出发去上班，我可以有几个策略考虑：我可以乘坐地铁，乘坐公交车，走路或其它的途径。每个策略可以得到相同的结果，但是使用了不同的资源。 策略模式的代码实例： 1234567891011121314151617181920212223242526&lt;?php // 抽象策略类 abstract class baseAgent &#123; abstract function PrintPage(); &#125; // 用于客户端是IE时调用的类（环境角色） class ieAgent extends baseAgent &#123; function PrintPage() &#123; return 'IE'; &#125; &#125; // 用于客户端不是IE时调用的类（环境角色） class otherAgent extends baseAgent &#123; function PrintPage() &#123; return 'not IE'; &#125; &#125; // 具体策略角色 class Browser &#123; public function call($object) &#123; return $object-&gt;PrintPage(); &#125; &#125; $bro = new Browser(); echo $bro-&gt;call(new ieAgent()); 工厂模式工厂模式是我们最常用的实例化对象模式，是用工厂方法代替new操作的一种模式。 使用工厂模式的好处是，如果你想要更改所实例化的类名等，则只需更改该工厂方法内容即可，不需逐一寻找代码中具体实例化的地方（new处）修改了。为系统结构提供灵活的动态扩展机制，减少了耦合。 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?php // 简单工厂模式（静态工厂方法模式） // Interface people 人类 interface people &#123; public function say(); &#125; // Class man 继承people的男人类 class man implements people &#123; // 具体实现people的say方法 public function say() &#123; echo '我是男人&lt;br&gt;'; &#125; &#125; // Class women 继承people的女人类 class women implements people &#123; // 具体实现people的say方法 public function say() &#123; echo '我是女人&lt;br&gt;'; &#125; &#125; // Class SimpleFactory 工厂类 class SimpleFactory &#123; // 简单工厂里的静态方法-用于创建男人对象 static function createMan() &#123; return new man(); &#125; // 简单工厂里的静态方法-用于创建女人对象 static function createWomen() &#123; return new women(); &#125; &#125; // 具体调用 $man = SimpleFactoty::createMan(); $man-&gt;say(); $woman = SimpleFactoty::createWomen(); $woman-&gt;say(); 单例模式单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例。 单例模式是一种常见的设计模式，在计算机系统中，线程池、缓存、日志对象、对话框、打印机、数据库操作、显卡的驱动程序常被设计成单例。 单例模式分3种：懒汉式单例、饿汉式单例、登记式单例。 单例模式有以下3个特点： 只能有一个实例 必须自行创建这个实例 必须给其他对象提供这一实例 那么为什么要使用PHP单例模式？ PHP一个主要应用场合就是应用程序与数据库打交道的场景，在一个应用中会存在大量的数据库操作，针对数据库句柄连接数据库的行为，使用单例模式可以避免大量的new操作。因为每一次new操作都会消耗系统和内存的资源。 12345678910111213141516171819202122232425class Single &#123; private $name;//声明一个私有的实例变量 private function __construct()&#123; //声明私有构造方法为了防止外部代码使用new来创建对象。 &#125; static public $instance;//声明一个静态变量（保存在类中唯一的一个实例） static public function getinstance()&#123; //声明一个getinstance()静态方法，用于检测是否有实例对象 if(!self::$instance) &#123; self::$instance = new self(); &#125; return self::$instance; &#125; public function setname($n)&#123; $this-&gt;name = $n; &#125; public function getname()&#123; return $this-&gt;name; &#125;&#125;$oa = Single::getinstance();$ob = Single::getinstance();$oa-&gt;setname('hello world');$ob-&gt;setname('good morning');echo $oa-&gt;getname();//good morningecho $ob-&gt;getname();//good morning 注册模式注册模式，解决全局共享和交换对象。已经创建好的对象，挂在到某个全局可以使用的数组上，在需要使用的时候，直接从该数组上获取即可。将对象注册到全局的树上。任何地方直接去访问。 1234567891011121314&lt;?phpclass Register &#123; protected static $objects; //将对象注册到全局的树上 function set($alias, $object) &#123; self::$objects[$alias]=$object;//将对象放到树上 &#125; static function get($name) &#123; return self::$objects[$name];//获取某个注册到树上的对象 &#125; function _unset($alias) &#123; unset(self::$objects[$alias]);//移除某个注册到树上的对象 &#125;&#125; 适配器模式将各种截然不同的函数接口封装成统一的API。 PHP中的数据库操作有MySQL,MySQLi,PDO三种，可以用适配器模式统一成一致，使不同的数据库操作，统一成一样的API。类似的场景还有cache适配器，可以将memcache,redis,file,apc等不同的缓存函数，统一成一致。 首先定义一个接口(有几个方法，以及相应的参数)。然后，有几种不同的情况，就写几个类实现该接口。将完成相似功能的函数，统一成一致的方法。 12345678接口 IDatabase&lt;?php namespace IMooc; interface IDatabase &#123; function connect($host, $user, $passwd, $dbname); function query($sql); function close(); &#125; 12345678910111213141516171819MySQL&lt;?php namespace IMooc\Database; use IMooc\IDatabase; class MySql implements IDatabase &#123; protected $conn; function connect($host, $user, $passwd, $dbname) &#123; $conn = mysql_connect($host, $user, $passwd); mysql_select_db($dbname); $this-&gt;conn = $conn; &#125; function query($sql) &#123; $res = mysql_query($sql, $this-&gt;conn); return $res; &#125; function close() &#123; mysql_close($this-&gt;conn); &#125; &#125; 1234567891011121314151617MySQLi&lt;?php namespace IMooc\Database; use IMooc\IDatabase; class MySQLi implements IDatabase&#123; protected $conn; function connect($host, $user, $passwd, $dbname)&#123; $conn = mysqli_connect($host, $user, $passwd, $dbname); $this-&gt;conn = $conn; &#125; function query($sql)&#123; return mysqli_query($this-&gt;conn, $sql); &#125; function close()&#123; mysqli_close($this-&gt;conn); &#125; &#125; 观察者模式 观察者模式(Observer)，当一个对象状态发生变化时，依赖它的对象全部会收到通知，并自动更新。 场景:一个事件发生后，要执行一连串更新操作。传统的编程方式，就是在事件的代码之后直接加入处理的逻辑。当更新的逻辑增多之后，代码会变得难以维护。这种方式是耦合的，侵入式的，增加新的逻辑需要修改事件的主体代码。 观察者模式实现了低耦合，非侵入式的通知与更新机制。 定义一个事件触发抽象类： 12345678910111213EventGenerator.php&lt;?php abstract class EventGenerator&#123; private $observers = array(); function addObserver(Observer $observer)&#123; $this-&gt;observers[]=$observer; &#125; function notify()&#123; foreach ($this-&gt;observers as $observer)&#123; $observer-&gt;update(); &#125; &#125; &#125; 定义一个观察者接口 123456Observer.php&lt;?php //一个实现了EventGenerator抽象类的类，用于具体定义某个发生的事件 interface Observer &#123; function update(); // 这里就是在事件发生后要执行的逻辑 &#125; 实现 1234567891011121314151617181920212223class Event extends EventGenerator&#123; function triger()&#123; echo "Event&lt;br&gt;"; &#125;&#125;class Observer1 implements Observer&#123; function update()&#123; echo "逻辑1 &lt;br/&gt;"; &#125;&#125;class Observer2 implements Observer&#123; function update()&#123; echo "逻辑2 &lt;br/&gt;"; &#125;&#125;$event = new Event();$event-&gt;addObserver(new Observer1());$event-&gt;addObserver(new Observer2());$event-&gt;triger();$event-&gt;notify();]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fmt格式 “占位符”]]></title>
    <url>%2F2019%2F07%2F08%2Fgo-fmt%2F</url>
    <content type="text"><![CDATA[golang 的fmt 包实现了格式化I/O函数，类似于C的 printf 和 scanf。 123456# 定义示例类型和变量type Human struct &#123; Name string&#125;var people = Human&#123;Name: &quot;zhangsan&quot;&#125; 普通占位符 占位符 说明 举例 输出 %v 相应值的默认格式 Printf(“%v”, people) {zhangsan} %+v 打印结构体时，会添加字段名 Printf(“%+v”, people) {Name:zhangsan} %#v 相应值的Go语法表示 Printf(“#v”, people) main.Human{Name:”zhangsan”} %T 相应值的类型的Go语法表示 Printf(“%T”, people) main.Human %% 字面上的百分号，并非值的占位符 Printf(“%%”) % 布尔占位符 占位符 说明 举例 输出 %t true 或 false Printf(“%t”, true) true 整数占位符 占位符 说明 举例 输出 %b 二进制表示 Printf(“%b”, 5) 101 %c 相应Unicode码点所表示的字符 Printf(“%c”, 0x4E2D) 中 %d 十进制表示 Printf(“%d”, 0x12) 18 %o 八进制表示 Printf(“%d”, 10) 12 %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(“%q”, 0x4E2D) ‘中’ %x 十六进制表示，字母形式为小写 a-f Printf(“%x”, 13) d %X 十六进制表示，字母形式为大写 A-F Printf(“%x”, 13) D %U Unicode格式：U+1234，等同于 “U+%04X” Printf(“%U”, 0x4E2D) U+4E2D 浮点数和复数的组成部分（实部和虚部） 占位符 说明 举例 输出 %e 科学计数法，例如 -1234.456e+78 Printf(“%e”, 10.2) 1.020000e+01 %E 科学计数法，例如 -1234.456E+78 Printf(“%e”, 10.2) 1.020000E+01 %f 有小数点而无指数，例如 123.456 Printf(“%f”, 10.2) 10.200000 %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出 Printf(“%g”, 10.20) 10.2 %G 根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0）输出 Printf(“%G”, 10.20+2i) (10.2+2i) 字符串与字节切片 占位符 说明 举例 输出 %s 输出字符串表示（string类型或[]byte) Printf(“%s”, []byte(“Go语言”)) Go语言 %q 双引号围绕的字符串，由Go语法安全地转义 Printf(“%q”, “Go语言”) “Go语言” %x 十六进制，小写字母，每字节两个字符 Printf(“%x”, “golang”) 676f6c616e67 %X 十六进制，大写字母，每字节两个字符 Printf(“%X”, “golang”) 676F6C616E67 指针 占位符 说明 举例 输出 %p 十六进制表示，前缀 0x Printf(“%p”, &amp;people) 0x4f57f0]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>占位符</tag>
      </tags>
  </entry>
</search>
